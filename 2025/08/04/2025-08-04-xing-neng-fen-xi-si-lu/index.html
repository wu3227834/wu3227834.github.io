<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><meta property="og:description" content="这里是小布丁的私有小屋"><meta property="og:type" content="website"><meta name="keywords" content="性能瓶颈, TPS 曲线, 响应时间拆分, 线程递增策略, 分析决策树,"><meta name="description" content="介绍了瓶颈的精准判断、线程递增的策略、性能衰减的过程、响应时间的拆分、构建分析决策树以及场景的比对，这几个环节，是性能分析过程中非常重要的环节"><link rel="shortcut icon" href="/img/favicon.ico"><title>性能分析思路</title><link rel="stylesheet" href="/css/aircloud.css"><link rel="stylesheet" href="/css/gitment.css"><link rel="stylesheet" href="/css/prism.css"><link href="//at.alicdn.com/t/font_620856_28hi1hpxx24.css" rel="stylesheet" type="text/css"><script></script><script defer src="https://cloud.umami.is/script.js" data-website-id="bad0a741-25cb-4dd6-bbcf-f5710aeb243c"></script><script type="text/javascript">((e,t,s,n,a,c)=>{e[s]=e[s]||function(){(e[s].q=e[s].q||[]).push(arguments)},(a=t.createElement(n)).async=1,a.src="https://www.clarity.ms/tag/sgs6id3d37",(c=t.getElementsByTagName(n)[0]).parentNode.insertBefore(a,c)})(window,document,"clarity","script")</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Pudding 日常" type="application/atom+xml"></head><body><div class="site-nav-toggle" id="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div><div class="index-about"><i>a week is 2% of the year</i></div><div class="index-container"><div class="index-left"><div class="nav" id="nav"><div class="avatar-name"><div class="avatar"><img src="/img/avatar.png"></div><div class="name"><i>Pudding</i></div></div><div class="contents" id="nav-content"><ul><li><a href="/"><i class="iconfont icon-shouye1"></i> <span>主页</span></a></li><li><a href="/tags"><i class="iconfont icon-biaoqian1"></i> <span>标签</span></a></li><li><a href="/archive"><i class="iconfont icon-guidang2"></i> <span>存档</span></a></li><li><a href="/about/"><i class="iconfont icon-guanyu2"></i> <span>关于</span></a></li><li><a id="search"><i class="iconfont icon-sousuo1"></i> <span>搜索</span></a></li></ul></div><div id="toc" class="toc-article"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%93%B6%E9%A2%88%E7%9A%84%E7%B2%BE%E7%A1%AE%E5%88%A4%E6%96%AD"><span class="toc-text">瓶颈的精确判断</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#TPS-%E6%9B%B2%E7%BA%BF"><span class="toc-text">TPS 曲线</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E7%9A%84%E6%9B%B2%E7%BA%BF"><span class="toc-text">响应时间的曲线</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E7%A8%8B%E9%80%92%E5%A2%9E%E7%9A%84%E7%AD%96%E7%95%A5"><span class="toc-text">线程递增的策略</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%A7%E8%83%BD%E8%A1%B0%E5%87%8F%E7%9A%84%E8%BF%87%E7%A8%8B"><span class="toc-text">性能衰减的过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E7%9A%84%E6%8B%86%E5%88%86"><span class="toc-text">响应时间的拆分</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E5%88%86%E6%9E%90%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-text">构建分析决策树</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF%E7%9A%84%E6%AF%94%E5%AF%B9"><span class="toc-text">场景的比对</span></a></li></ol></div></div><div class="search-field" id="search-field"><div class="search-bg" id="search-bg"></div><div class="search-container"><div class="search-input"><span id="esc-search"><i class="icon-fanhui iconfont"></i></span> <input id="search-input"> <span id="begin-search">搜索</span></div><div class="search-result-container" id="search-result-container"></div></div></div><div class="index-about-mobile"><i>a week is 2% of the year</i></div></div><div class="index-middle"><div class="post-container"><div class="post-title">性能分析思路</div><div class="post-meta"><span class="attr">发布于：<span>2025-08-04</span></span> <span class="attr">标签：/ <a class="tag" href="/tags/#Linux" title="Linux">Linux</a> <span>/</span> <a class="tag" href="/tags/#极客时间" title="极客时间">极客时间</a> <span>/</span> <a class="tag" href="/tags/#性能测试" title="性能测试">性能测试</a> <span>/</span> </span><span class="attr">访问：<span id="busuanzi_value_page_pv"></span></span></div><div class="post-content no-indent"><p>我还年轻的时候，经常听一些大会或者演讲。有些人说，思路逻辑非常重要。我那时就想，你肯定是瞎忽悠的，因为我怎么就没听懂你说的思路呢？而现在轮到自己来写或者讲一些东西的时候，才发现他们说得对，而我之所以不理解，也是有原因的。性能分析思路和具体实现之间，有一道鸿沟，那就是操作的能力。之前我为什么听不懂那些人的思路，其实是因为我没有操作的功底。而有了操作的功底之后，还有一个大的鸿沟要越过去，那就是从操作到对监控计数器的理解。这一步可以说让很多性能测试人员都望而却步了。但是这还不算完，这一步迈过去之后，还有一个跳跃，就是相关性分析和证据链分析的过程。</p><p>如此一来，就会得到一张性能测试分析的能力阶梯视图，如下：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image.png" alt="性能分析能力阶梯视图"></p><ol><li>工具操作：包括压力工具、监控工具、剖析工具、调试工具</li><li>数值理解：包括上面工具中所有输出的数据</li><li><strong>趋势分析、相关性分析、证据链分析</strong>：就是了解了工具产生的数值之后，还要把它们的逻辑关系明白。这才是性能测试分析中最重要的一环</li><li>最后才是调优：有了第 3 步之后，调优的方案策略就有很多种了，具体选择取决于调优成本和产生的效果</li></ol><p>那么怎么把这些内容都融会贯通呢？下面我们就来说说性能测试分析的几个重要环节。</p><p>应该说，从我十几年的性能工作中，上面讲的这些内容是我觉得最有价值的内容了。在今天的文章中，我们将对它做一次系统的说明。我先把性能分析思路大纲列在这里：</p><ol><li>瓶颈的精确判断</li><li>线程递增的策略</li><li>性能衰退的过程</li><li>响应时间的拆分</li><li>构建分析决策树</li><li>场景的比对</li></ol><h2 id="瓶颈的精确判断"><a href="#瓶颈的精确判断" class="headerlink" title="瓶颈的精确判断"></a>瓶颈的精确判断</h2><h3 id="TPS-曲线"><a href="#TPS-曲线" class="headerlink" title="TPS 曲线"></a>TPS 曲线</h3><p>对性能瓶颈做出判断是性能分析的第一步，有了问题才能分析调优。之前有很多人在描述性能测试的过程中，说要找到性能测试中曲线上的“拐点”。我也明确说，大部分系统其实没有明确的拐点的。举例来说，TPS 的试图如下：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image2.png" alt="TPS图 1"></p><p>显然，这是一个阶梯式增加的场景，非常好。但是拐点在哪呢？有人说，显然在 1200TPS左右的时候。也有人说了，显然是到 1500TPS 才是拐点呀。但是也有人说，这都已经能到2000TPS 了，显然 2000TPS 是拐点。</p><p>我们再来看一下这张图对应的响应时间视图：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image2.png" alt="响应时间图 1"></p><p>是不是有人要说响应时间为 4.5ms 时是拐点了？其实这些对拐点的判断，都是不合理的。如果我们对 TPS 的增加控制得更为精确的话，那么这个 TPS 的增加是是有一个有清晰的弧度，而不是有一个非常清晰的拐点。</p><p>但是至少我们可以有一个非常明确的判断，那就是瓶颈在第二个压力阶梯上已经出现了。因为响应时间增加了，TPS 增加得却没有那么多，到第三个阶梯时，显然增加的 TPS 更少了，响应时间也在不断地增加，所以，性能瓶颈在加剧，越往后就越明显。</p><p>那么我们的判断就是：</p><ol><li>有瓶颈！</li><li>瓶颈和压力有关</li><li>压力呈阶梯，并且增长幅度在衰减</li></ol><p>如果你觉得上面的瓶颈还算清晰的话，那么我们再来看一张图：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image4.png" alt="TPS图 2"></p><p>在这个 TPS 的曲线中，你还能判断出拐点在哪吗？</p><p>显然是判断不出来拐点的，但是我们根据图得出以下几个结论：</p><ol><li>有瓶颈！</li><li>瓶颈和压力有关</li><li>压力也是阶梯的，但是并没有明确的拐点</li></ol><p>我们再来看一个 TPS 图：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image5.png" alt="TPS图 3"></p><p>看到这张图，是不是明显感觉系统有瓶颈呢？那么瓶颈是不是和压力大小有关呢？</p><p>这种比较有规律的问题，显然不是压力大小的原因。为什么呢？因为 TPS 周期性地出现降低，并且最大的 TPS 也都恢复到了差不多的水位上。所以，即使是压力降低，也最多降低最大的 TPS 水位，会让问题出现得更晚一点，但是不会不出现。</p><p>综合以上，如果画一个示意图的话，TPS 的衰减过程大概会如下所示：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image6.png" alt="示意图"></p><ol><li>随着用户数的增加，响应时间也在缓慢增加</li><li>TPS 前期一直都在增加，但是增加的幅度在变换，直至变平</li></ol><p>在这样的曲线图中，我们是看不到明确的观点的。但是我们能做的清晰的判断就是：有瓶颈！</p><p>所以对 TPS 曲线来说，它可以明确告诉我们的就是：</p><ol><li>有没有瓶颈：其实准确来说所有的系统都有性能瓶颈，只看我们在哪个量级上做性能测试了</li><li>瓶颈和压力有没有关系：TPS 随着压力的变化而变化，那就是有关系。不管压力增不增加，TPS 都会出现曲线趋势问题，那就是无关</li></ol><p>这时你可能会问，为什么不看响应时间就武断地下此结论呢？其实响应时间用来判断业务有多快的，而 TPS 才是用来判断容量有多大的。</p><h3 id="响应时间的曲线"><a href="#响应时间的曲线" class="headerlink" title="响应时间的曲线"></a>响应时间的曲线</h3><p>我们还是来看看响应时间，下面看一张响应时间图：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image7.png" alt="响应时间图"></p><p>它对应的线程图是：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image8.png" alt="线程图"></p><p>多明显的问题，随着线程的增多，响应时间也在增加，是吧。再来看它们对应的 TPS 图：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image9.png" alt="TPS图"></p><p>到第 40 个线程时，TPS 基本上达到上限，为 2500 左右。响应时间随着线程数的增加而增加了，系统的瓶颈显而易见地出现了。</p><p>但是，如果只让你看 TPS 曲线，你是不是也会有同样的判断？那就是：有瓶颈！并且和压力有关？所以说，其实 TPS 就可以告诉我们系统有没有瓶颈了，而响应时间是用来判断业务有多块的。</p><p>后面我们还会提到响应时间会是性能分析调优地重要分析对象。</p><h2 id="线程递增的策略"><a href="#线程递增的策略" class="headerlink" title="线程递增的策略"></a>线程递增的策略</h2><p>讲完响应时间之后，我们再来看下线程递增。在见识了很多性能测试人员做的场景之后，必须得承认，有些场景地问题太多了。</p><p>首先，我们来看两个场景地执行对比。</p><p>场景 1 的线程图：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image10.png" alt="线程图 1"></p><p>场景 1 的 TPS 图：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image11.png" alt="TPS图 1"></p><p>场景 1 的响应时间图：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image12.png" alt="响应时间图 1"></p><p>场景 2 的线程图：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image13.png" alt="线程图 2"></p><p>场景 2 的 TPS 图：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image14.png" alt="TPS图 2"></p><p>场景 2 的响应时间图：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image15.png" alt="响应时间图 2"></p><p>这两个场景的比对如下：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image16.png" alt="比对图"></p><table><thead><tr><th>对比项</th><th>场景 1</th><th>场景 2</th></tr></thead><tbody><tr><td>线程数</td><td>一次性加到500</td><td>10线程递增，并且递增中也是有梯度的</td></tr><tr><td>TPS</td><td>最大值达到400</td><td>最大值达到400，但递增过程中有抖动</td></tr><tr><td>响应时间</td><td>在600ms~660ms之间</td><td>在20ms~150ms之间</td></tr><tr><td>错误率</td><td>无</td><td>无</td></tr><tr><td>粒度</td><td>以分钟为粒度</td><td>以2秒为粒度</td></tr></tbody></table><p>有了这些对比数据之后，你是不是觉得哪里似乎是有问题的？</p><p>对的！</p><p>TPS 都是达到 400，但两个场景中线程递增的策略不同。产生的响应时间完全不同。虽然都没有报错，但是第一种场景是完全不符合真实的业务场景的。这是为什么呢？</p><p>在场景的执行过程中，首先，响应时间是从低到高的，而在场景 1 中不是这样。其次，线程应该是递增的，而场景 1 并没有这样做（这里或许有人会想到秒杀的场景，认为场景 1 符合秒杀的业务设定，这个问题我们稍后提及）。最后，在两个场景中，TPS 的上限都达到了 400 TPS。但是你可以看到，在场景 2 中，只要 40 线程即可达到，但场景 1 中居然用到了 500 线程，显然压力过大，所以响应时间才那么长。</p><p>其实在生产环境中，像场景 1 这样的情形是不会出现的。如果它出现了，那就是你作为性能测试的责任，因为你没有给出生成环境中应该如何控制流量的参数配置说明。</p><p>同时，我们从上面的场景对比中可以看到，<strong>对一个系统来说，如果仅在改变压力策略（其他的条件比如环境、数据、软硬件配置等都不变）的情况下，系统的最大 TPS 上限是固定的。</strong></p><p>场景 2 使用了递增的策略，在每个阶梯递增的过程中，出现了抖动，这就明显是系统设置的不合理导致的。设置不合理，有两种可能性：</p><ol><li>资源的动态分配不合理，向后端线程池、内存、缓存等等</li><li>数据没有预热</li></ol><p>我们再回到之前说的秒杀场景。说到秒杀场景，有人觉得用大线程并发是合理的，其实这属于认知上的错误。因为即使线程数增加得再多，对已经达到 TPS 上限的系统来说，除了会增加响应时间之外，并无其他作用。所以他们描述系统的容量是用系统当前能处理的业务量（你用 TPS 也好，RPS 也好，HPS 也好，它们都是用来描述服务端的处理能力的），而不是压力工具中的线程数。</p><p>那么，对于场景中线程（有些工具中叫虚拟用户）递增的策略，我们要做到以下几点：</p><ol><li>场景中的现场递增一定是连续的，并且在递增的过程中也是有梯度的。</li><li>场景中的线程递增一定要和 TPC 的递增有比例关系，而不是突然达到最上限。</li><li>上面两点针对的是常规的性能场景。对于秒杀类的场景，我们前期一定要做好了系统预热的工作的，在预热后，线程突增产生的压力，也是在可处理范围的。这是，我们可以设计线程徒增的场景来看系统瞬间的处理能力。如果不能模拟出秒杀的徒增，就是不合理的场景。</li></ol><p>这里给出我做性能场景递增的经验值：</p><table><thead><tr><th>响应时间</th><th>递增幅度</th></tr></thead><tbody><tr><td>0-50ms</td><td>1</td></tr><tr><td>50-100ms</td><td>1-3</td></tr><tr><td>100-200ms</td><td>3-5</td></tr><tr><td>200-500ms</td><td>5-10</td></tr></tbody></table><p>当然这里也不会放在哪个系统中合适的递增幅度，你还是要根据实际的测试过程来做相应的判断。</p><h2 id="性能衰减的过程"><a href="#性能衰减的过程" class="headerlink" title="性能衰减的过程"></a>性能衰减的过程</h2><p>有瓶颈的判断能力，也有了线程递增的意识，那么下面在场景执行，我们就要有判断性能衰减的能力了吧。来，我们先看一个压力过程中产生的结果图。</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image17.png" alt="压力结果图"></p><p>在递增的压力过程中，随着用户数的增加。我们可以做几次计算。</p><p>第一次计算，在线程达到 24 时，TPS 为 1810.6，也就是每线程每秒发出 75.44 个请求。</p><p>第二次计算，在线程达到 72 时，TPS 为 4375.1，也就是每线程每秒发出 60.77 个请求。</p><p>第三次计算，在线程达到 137 时，TPS 为 5034，也就是每线程每秒发出 36.74 个请求。</p><p>通过这三次计算，我们是不是可以看到，每线程每秒发出的请求数在变少，但是整体 TPS 是在增加的。</p><p>我们很多做性能测试的人，基本上，只看 TPS 和响应时间的时候，在上面这个示例中，肯定会一直往上加用户。虽然响应时间在增加，但是增加得也不多嘛。</p><p>但实际上，通过我们的计算可以知道，性能是在不断地衰减的。我们来看一张统计图：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image18.png" alt="统计图"></p><p>通过红线德大致比对可以知道，当每线程每秒的请求数降到 55 左右的时候，TPS 就达到上线了，大概在 5000 左右，再接着往上增加线程已经没有用了，响应时间开始往上增加了。</p><p>这就是性能衰减的过程（题外话，再上图中，其实还有一个问题，就是在红线前面，性能在上升的过程中有几次抖动，这个抖动到后面变大了，也变频繁了，如果这是必然出现的抖动，那也是配置问题）</p><p>为什么要这么细致地描述性能衰退的过程呢？</p><p>其实我就是想告诉你，<strong>只要每线程每秒的 TPS 开始变少，就意味着性能瓶颈已经出现了。但是瓶颈出现之后，并不是说服务器的处理能力（这里我们用 TPS 来描述）会下降，应该说 TPS 仍然会上升，在性能不断衰退的过程中，TPS 就会达到上限。</strong></p><p>这也是前面说的，性能瓶颈其实在最大 TPS 之前早就已经出现了。</p><p>那么我们是不是应该在性能衰减到最大 TPS 时就停止场景呢？这个不一定的哦。</p><p>因为停不停场景，取决于我们的场景目标，如果我们只是为了得到最大 TPS，那确实可以停止场景了。但是，如果我们要扩大化性能瓶颈，也就是说为了瓶颈更为明显，就完全不需要停止场景，只要不报错，就接着往上压，一直压到我们能要说的下一个话题 ———— 响应时间变长，需要拆分。</p><h2 id="响应时间的拆分"><a href="#响应时间的拆分" class="headerlink" title="响应时间的拆分"></a>响应时间的拆分</h2><p>在性能分析中，响应时间的差分通常是一个分析起点。因为在性能场景中，不管是什么原因，只要系统达到了瓶颈，再接着增加压力，肯定会导致响应时间的上升，直至达到超时为止。</p><p>在判断了瓶颈之后，我们需要找到问题出现在什么地方。在压力工具上看到的响应时间，都是经过了后端的每一个系统的。</p><p>那么，当响应时间变长，我们就要知道，它在哪个阶段时间变长了，来看下面这个图：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image19.png" alt="压力测试逻辑图"></p><p>这应该是最简单的一个压力测试逻辑图。一个应用，一个 DB，结果也拆分出了 8 个时间段，这还是在我没有加上压力工具自己所消耗的时间的情况下。但是在真实的场景中，基本上不是这样的。如果是内网，那基本上都是连在一个交换机上，所以通常是这样的：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image20.png" alt="拓扑图1"></p><p>在这样的拓扑中，我们仍然可以拆出来 t1 到 t8 的时间。只是实际动手的时候，思路一定要清晰，时间拆分是从哪里到哪里，要画出来，不能混乱。</p><p>我们有很多手段可以进行时间的拆分，当然要看我们的应用支持哪一种。如果我们是这样的架构，拆分时间应该是比较清楚的。</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image21.png" alt="拓扑图2"></p><p>首先我们需要查看 Nginx 上的时间。日志里就可以通过配置$request_time $upstream_response_time得到日志如下信息：</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">14.131.17.129</span> - - <span class="string">[09/Dec/2019:08:08:09 +0000]</span> <span class="string">&quot;<span class="keyword">GET</span> / HTTP/1.1&quot;</span> <span class="number">200</span> <span class="number">25317</span> <span class="number">0</span>.<span class="number">028</span> <span class="number">0</span>.<span class="number">028</span></span><br></pre></td></tr></table></figure><p>最后两列中，前面是请求时间的 28ms，后面是后端响应时间的 28ms。同时，我们再到 Tomcat 上去看时间。</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">172.18.0.1</span> - - <span class="string">[09/Dec/2019:08:08:09 +0000]</span> <span class="string">&quot;<span class="keyword">GET</span> / HTTP/1.1&quot;</span> <span class="number">200</span> <span class="number">25317</span> <span class="number">28</span> <span class="number">27</span> http-nio-<span class="number">8080</span>-exec-<span class="number">1</span></span><br></pre></td></tr></table></figure><p>请求时间消耗了 28ms，响应时间消耗了 27ms。接着再来看一下前端的时间消耗。</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image22.png" alt="前端耗时图"></p><p>从这里可以看到，从发出请求到接收到第一个字节，即 TTFB 是 55.01ms，内容下载用了 11.75ms。从这就可以看得出 Nginx 基本上没消耗时间，因为它和 Tomcat 上的请求响应时间非常接近。</p><p>那么网络上的消耗时间怎么样呢？我看到有很多人用 TTFB 来描述网络的时间。先来说明一下，TTFB 中显然包括了后端一系列处理和网络传输的时间。如下图所示。</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image23.png" alt="TTFB 图1"></p><p>下面的红色点是指要接收的内容。上面的红色线就是 TTFB。如果接收完了呢？就是这个状态。</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image24.png" alt="TTFB 图2"></p><p>所以，我觉得用 TTFB 描述网络的健康状态并不合理。如果用 Content Download 来描述会更为合理。比如我们上面的这个例子中，那就是 11.75ms 下载了 25317 Bytes 的内容。</p><p>Tomcat 上基本上是消耗了处理的所有时间，当然这中间也包括了 MySQL 花费的时间。而前端看到的其他时间就消耗在了网络中。</p><p>在这个例子中，主要说明了响应时间怎么一步步拆。当然，如果你是下面这种情况的话，再一个个拆就比较辛苦了，需要换另一种方式。</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image25.png" alt="拓扑图3"></p><p>你肯定想知道每个系统消耗了多长时间，那么我们就需要链路监控工具来拆分时间了。比如像这样来拆分：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image26.png" alt="拆分图"></p><p>从 User 开始，每个服务之间的调用时间，都需要看看时间消耗的监控。这就是时间拆分的一种方式。其实不管我们用什么样的工具来监控，最终我们想要得到的无非是每个环节消耗了多长时间。用日志也好，用链路监控也好，甚至抓包都可以。当我们拆分到了某个环节之后，就有了下一步的动作：构建分析决策树。</p><h2 id="构建分析决策树"><a href="#构建分析决策树" class="headerlink" title="构建分析决策树"></a>构建分析决策树</h2><p>分析决策树，对性能测试分析人员实在太重要了，是性能分析中不可或缺的一环。<strong>它是对架构的梳理，是对系统的梳理，是对问题的梳理，是对查找证据链过程的梳理，是对分析思路的梳理。它起的是纵观全局，高屋建瓴的指导作用。</strong></p><p>性能做到了艺术的层级之后，分析决策树就是提炼出来的，可以触及旁通的方法论。而我要在这里跟你讲的，就是这样的方法论。应该说，所有的技术行业在面对自己的问题时，都需要分析决策树。再广而推之，所有的问题都要有分析决策树来协助。</p><p>通过上面的几个步骤，我们就会知道时间消耗在了哪个节点上。那么之后呢？又当如何？总要找到根本的原因才可以把，我画了如下的分析决策图：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image27.png" alt="分析决策图"></p><p>从压力工具中，只需知道 TPS、响应时间和错误率三条曲线，就可以明确判断瓶颈是否存在。再通过分段分层策略，结合监控平台、日志平台，或者其他实时分析平台，知道架构中哪个环节有问题，然后再根据更细化的架构图一一拆解下去。</p><p>我在这里，以数据库分析和操作系统分析举一下例子。首先我们看一下数据库分析决策树，比如针对 RDBMS 中的 MySQL，我们就可以画一下如下的决策树：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image28.png" alt="mysql分析决策图"></p><p>由于这里面的内容实在过多，无法一次性展现在这里。我举几个具体的例子给你说明一下。</p><p>MySQL 中的索引统计信息有配置值，有状态值。我们要根据具体的结果来判断是否需要增加 key_buffer_size 值的大小。比如这种就无所谓了。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">Buffer</span> used     <span class="number">3</span>.<span class="number">00</span>k of   <span class="number">8</span>.<span class="number">00</span>M  %Used:   <span class="number">0</span>.<span class="number">0004</span></span><br></pre></td></tr></table></figure><p>从上面的数据可以看到，key buffer size 就用到了 4%，显然不用增加。</p><p>再比如，我们看到这样的数据：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">   <span class="attribute">__Tables_______________________</span></span><br><span class="line"><span class="attribute">Open</span>             <span class="number">2000</span> of <span class="number">2000</span>    %Cache: <span class="number">100</span>.<span class="number">00</span></span><br><span class="line"><span class="attribute">Opened</span>         <span class="number">15</span>.<span class="number">99</span>M     <span class="number">4</span>.<span class="number">1</span>/s</span><br></pre></td></tr></table></figure><p>这就明显有问题了。配置值为 2000 的 Open Table Cache，已经被占满了。显然这里需要分析。但是，看到状态值达到配置值并不意味着我们需要赶紧加大配置值，而是要分析是否合理，再做相应的处理。比如说上面这个，Table 确实打开得多，但是如果我们再对应看下这一条。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">Slow</span> <span class="number">2</span> s        <span class="number">6</span>.<span class="number">21</span>M     <span class="number">1</span>.<span class="number">6</span>/s</span><br></pre></td></tr></table></figure><p>你是不是觉得应该先去处理慢 SQL 的问题了？</p><p>关于数据库的我们就不举更多的例子了。在这里只是为了告诉你，在分析决策树的创建过程中，有非常多的相互依赖关系。</p><p>然后我们再来看一下操作系统分析决策树，我在这里需要强调一下，操作系统的分析决策树，不可以绕过。</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image29.png" alt="操作系统分析决策图"></p><p>如果你想到操作系统架构图就头大，那么这时候应该觉得有了希望。那就是我觉得操作系统上的问题判断是比较清晰的，所以基于此决策树，每个人都可以做到对操作系统中性能问题的证据链查找。</p><p>但是！对嘛，总得有个但是。</p><p>对操作系统的理解是个必然的前提。我看过很多人写的操作系统性能分析方面的书籍或资料，发现大部分人把描述计数器的数值当成性能分析。怎么理解这句话呢？比如说</p><p>“CPU 使用率在 TPS 上升的过程中，从 10% 增加到 95%，超过了预期值。” “内存使用率达到 99%，所以是瓶颈点。” “I/O 使用率达到 100%。” 等等。</p><p>像这样的描述，在我的性能团队中，一定会被骂回去重写。我要这些描述有什么用？我要的是为什么达到了这样的值，原因在哪？怎么解决？</p><p>就像分析决策树中所描述的那样，性能工程师要做的是一步步地细化分析，给出最终的原因。</p><p>有人说，如果按这个路子，似乎操作系统的分析并不复杂嘛。大概三五个命令就可以跳到代码层了。是的，对于操作来说，确实不多，但是对于判断来说，那就复杂了。举个例子来说明一下：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image30.png" alt="TOP图"></p><p>看到这样的图，你是不是有种手足无措的感觉？中断能占 40%，sy CPU 也能占 40%。这系统还用干业务的事吗？全干自己的事去了，可见操作系统有问题！你是不是要做这个判断了？</p><p>而实际情况是，这个主机上只有一个网卡队列，而请求量又比较大。</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image31.png" alt="网卡队列图"></p><p>所以要解决的是网卡队列的问题，至于怎么解决，那手段就多了。可以换个服务器，可以多加几个队列，可以多接几个节点…</p><p>以上只是给出几个性能分析过程中常见的决策树示例。在后续的分析过程实例中，我们将秉承着这种分析思路，一步步地走到瓶颈的面前。</p><h2 id="场景的比对"><a href="#场景的比对" class="headerlink" title="场景的比对"></a>场景的比对</h2><p>为什么要写这一部分呢？因为我看到很多人对瓶颈的判断，并不那么精确，所以想写一下场景对比的建议。其实简单来说，就一句话：当你觉得系统中哪个环节不行的话，又没能力分析她，你可以直接做该环节的增加。举例来说，我们现在有一个如下的架构：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image32.png" alt="架构图"></p><p>可以得到这样的结果：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image33.png" alt="结果图"></p><p>从 TPS 曲线中，我们明显看到系统是有瓶颈的，但是并不知道在哪里。鉴于系统架构如此简单，我们索性直接再某环节上加上一台服务器，变成这样：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image34.png" alt="架构图"></p><p>然后得到如下数据：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image35.png" alt="结果图"></p><p>哟，没好使！</p><p>怎么办？再接着加其他节点，我加了更多的 JMeter 机器。</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image36.png" alt="架构图"></p><p>再来看下结果：</p><p><img src="/img/2025-08-04-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/image37.png" alt="结果图"></p><p>真巧，TPS 增加了！</p><p>看到了吧，这就是我说的场景比对。</p><p>当我们不知道系统中哪个环节存在性能瓶颈时，对架构并不复杂的系统来说，可以使用这样的手段，来做替换法，以快速定位问题。</p><p>总结<br>在这一篇中，我说到了瓶颈的精准判断、线程递增的策略、性能衰减的过程、响应时间的拆分、构建分析决策树以及场景的比对，这几个环节，是性能分析过程中非常重要的环节。</p><p>从我的经验上来说，这一篇文章可能是我工作十几年的精华所在了。而这里的每一个环节，又有非常多的细分，特别是构建分析决策树这一块，它需要太多的架构知识、系统知识、数据库知识等等。鉴于本文只是想起到一个提纲挈领的作用，所以无法展开描述，希望在后续的篇幅中，我们尽量细致拆解。</p><br><div id="comment-container"></div><div id="disqus_thread"></div><div id="lv-container"></div><div class="giscus"></div></div></div></div></div><footer class="footer"><ul class="list-inline text-center"><li><a target="_blank" href="https://github.com/wu3227834" rel="external nofollow noreferrer"><span class="fa-stack fa-lg"><i class="iconfont icon-github"></i></span></a></li></ul><p><span id="busuanzi_container_site_pv"><span id="busuanzi_value_site_pv"></span>PV </span><span id="busuanzi_container_site_uv"><span id="busuanzi_value_site_uv"></span>UV </span>Created By <a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io/">Hexo</a> Theme <a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p></footer><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.js"></script><script type="text/javascript" src="https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script><script type="text/javascript" src="/js/clipboard.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });</script><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body><script>window.hexo_search_path="search.json",window.hexo_root="/",window.isPost=!0</script><script src="/js/index.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="/js/jquery.min.js"></script><script src="/js/prism.js"></script><script src="https://giscus.app/client.js" data-repo="wu3227834/wu3227834.github.io" data-repo-id="R_kgDOIh8vuA" data-category="General" data-category-id="DIC_kwDOIh8vuM4CpDjz" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="preferred_color_scheme" data-lang="zh-CN" crossorigin="anonymous" async></script></html><script src="/js/fancybox/jquery.fancybox.min.js" key="fancybox_js"></script><script src="/js/fancybox/wrapImage.js" key="wrap_image_js"></script><link rel="stylesheet" href="/js/fancybox/jquery.fancybox.min.css" key="fancybox_css">
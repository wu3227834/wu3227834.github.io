[{"title":"性能分析思路","url":"/2025/08/04/2025-08-04-xing-neng-fen-xi-si-lu/","content":"\n我还年轻的时候，经常听一些大会或者演讲。有些人说，思路逻辑非常重要。我那时就想，你肯定是瞎忽悠的，因为我怎么就没听懂你说的思路呢？而现在轮到自己来写或者讲一些东西的时候，才发现他们说得对，而我之所以不理解，也是有原因的。性能分析思路和具体实现之间，有一道鸿沟，那就是操作的能力。之前我为什么听不懂那些人的思路，其实是因为我没有操作的功底。而有了操作的功底之后，还有一个大的鸿沟要越过去，那就是从操作到对监控计数器的理解。这一步可以说让很多性能测试人员都望而却步了。但是这还不算完，这一步迈过去之后，还有一个跳跃，就是相关性分析和证据链分析的过程。\n\n如此一来，就会得到一张性能测试分析的能力阶梯视图，如下：\n\n![性能分析能力阶梯视图](/img/2025-08-04-性能分析思路/image.png)\n\n1. 工具操作：包括压力工具、监控工具、剖析工具、调试工具\n2. 数值理解：包括上面工具中所有输出的数据\n3. **趋势分析、相关性分析、证据链分析**：就是了解了工具产生的数值之后，还要把它们的逻辑关系明白。这才是性能测试分析中最重要的一环\n4. 最后才是调优：有了第 3 步之后，调优的方案策略就有很多种了，具体选择取决于调优成本和产生的效果\n\n那么怎么把这些内容都融会贯通呢？下面我们就来说说性能测试分析的几个重要环节。\n\n应该说，从我十几年的性能工作中，上面讲的这些内容是我觉得最有价值的内容了。在今天的文章中，我们将对它做一次系统的说明。我先把性能分析思路大纲列在这里：\n\n1. 瓶颈的精确判断\n2. 线程递增的策略\n3. 性能衰退的过程\n4. 响应时间的拆分\n5. 构建分析决策树\n6. 场景的比对\n\n## 瓶颈的精确判断\n\n### TPS 曲线\n\n对性能瓶颈做出判断是性能分析的第一步，有了问题才能分析调优。之前有很多人在描述性能测试的过程中，说要找到性能测试中曲线上的“拐点”。我也明确说，大部分系统其实没有明确的拐点的。举例来说，TPS 的试图如下：\n\n![TPS图 1](/img/2025-08-04-性能分析思路/image2.png)\n\n显然，这是一个阶梯式增加的场景，非常好。但是拐点在哪呢？有人说，显然在 1200TPS左右的时候。也有人说了，显然是到 1500TPS 才是拐点呀。但是也有人说，这都已经能到2000TPS 了，显然 2000TPS 是拐点。\n\n我们再来看一下这张图对应的响应时间视图：\n\n![响应时间图 1](/img/2025-08-04-性能分析思路/image2.png)\n\n是不是有人要说响应时间为 4.5ms 时是拐点了？其实这些对拐点的判断，都是不合理的。如果我们对 TPS 的增加控制得更为精确的话，那么这个 TPS 的增加是是有一个有清晰的弧度，而不是有一个非常清晰的拐点。\n\n但是至少我们可以有一个非常明确的判断，那就是瓶颈在第二个压力阶梯上已经出现了。因为响应时间增加了，TPS 增加得却没有那么多，到第三个阶梯时，显然增加的 TPS 更少了，响应时间也在不断地增加，所以，性能瓶颈在加剧，越往后就越明显。\n\n那么我们的判断就是：\n\n1. 有瓶颈！\n2. 瓶颈和压力有关\n3. 压力呈阶梯，并且增长幅度在衰减\n\n如果你觉得上面的瓶颈还算清晰的话，那么我们再来看一张图：\n\n![TPS图 2](/img/2025-08-04-性能分析思路/image4.png)\n\n在这个 TPS 的曲线中，你还能判断出拐点在哪吗？\n\n显然是判断不出来拐点的，但是我们根据图得出以下几个结论：\n\n1. 有瓶颈！\n2. 瓶颈和压力有关\n3. 压力也是阶梯的，但是并没有明确的拐点\n\n我们再来看一个 TPS 图：\n\n![TPS图 3](/img/2025-08-04-性能分析思路/image5.png)\n\n看到这张图，是不是明显感觉系统有瓶颈呢？那么瓶颈是不是和压力大小有关呢？\n\n这种比较有规律的问题，显然不是压力大小的原因。为什么呢？因为 TPS 周期性地出现降低，并且最大的 TPS 也都恢复到了差不多的水位上。所以，即使是压力降低，也最多降低最大的 TPS 水位，会让问题出现得更晚一点，但是不会不出现。\n\n综合以上，如果画一个示意图的话，TPS 的衰减过程大概会如下所示：\n\n![示意图](/img/2025-08-04-性能分析思路/image6.png)\n\n1. 随着用户数的增加，响应时间也在缓慢增加\n2. TPS 前期一直都在增加，但是增加的幅度在变换，直至变平\n\n在这样的曲线图中，我们是看不到明确的观点的。但是我们能做的清晰的判断就是：有瓶颈！\n\n所以对 TPS 曲线来说，它可以明确告诉我们的就是：\n\n1. 有没有瓶颈：其实准确来说所有的系统都有性能瓶颈，只看我们在哪个量级上做性能测试了\n2. 瓶颈和压力有没有关系：TPS 随着压力的变化而变化，那就是有关系。不管压力增不增加，TPS 都会出现曲线趋势问题，那就是无关\n\n这时你可能会问，为什么不看响应时间就武断地下此结论呢？其实响应时间用来判断业务有多快的，而 TPS 才是用来判断容量有多大的。\n\n### 响应时间的曲线\n\n我们还是来看看响应时间，下面看一张响应时间图：\n\n![响应时间图](/img/2025-08-04-性能分析思路/image7.png)\n\n它对应的线程图是：\n\n![线程图](/img/2025-08-04-性能分析思路/image8.png)\n\n多明显的问题，随着线程的增多，响应时间也在增加，是吧。再来看它们对应的 TPS 图：\n\n![TPS图](/img/2025-08-04-性能分析思路/image9.png)\n\n到第 40 个线程时，TPS 基本上达到上限，为 2500 左右。响应时间随着线程数的增加而增加了，系统的瓶颈显而易见地出现了。\n\n但是，如果只让你看 TPS 曲线，你是不是也会有同样的判断？那就是：有瓶颈！并且和压力有关？所以说，其实 TPS 就可以告诉我们系统有没有瓶颈了，而响应时间是用来判断业务有多块的。\n\n后面我们还会提到响应时间会是性能分析调优地重要分析对象。\n\n## 线程递增的策略\n\n讲完响应时间之后，我们再来看下线程递增。在见识了很多性能测试人员做的场景之后，必须得承认，有些场景地问题太多了。\n\n首先，我们来看两个场景地执行对比。\n\n场景 1 的线程图：\n\n![线程图 1](/img/2025-08-04-性能分析思路/image10.png)\n\n场景 1 的 TPS 图：\n\n![TPS图 1](/img/2025-08-04-性能分析思路/image11.png)\n\n场景 1 的响应时间图：\n\n![响应时间图 1](/img/2025-08-04-性能分析思路/image12.png)\n\n场景 2 的线程图：\n\n![线程图 2](/img/2025-08-04-性能分析思路/image13.png)\n\n场景 2 的 TPS 图：\n\n![TPS图 2](/img/2025-08-04-性能分析思路/image14.png)\n\n场景 2 的响应时间图：\n\n![响应时间图 2](/img/2025-08-04-性能分析思路/image15.png)\n\n这两个场景的比对如下：\n\n![比对图](/img/2025-08-04-性能分析思路/image16.png)\n\n|对比项|场景 1|场景 2|\n|--|--|--|\n|线程数|一次性加到500|10线程递增，并且递增中也是有梯度的|\n|TPS|最大值达到400|最大值达到400，但递增过程中有抖动|\n|响应时间|在600ms~660ms之间|在20ms~150ms之间|\n|错误率|无|无|\n|粒度|以分钟为粒度|以2秒为粒度|\n\n有了这些对比数据之后，你是不是觉得哪里似乎是有问题的？\n\n对的！\n\nTPS 都是达到 400，但两个场景中线程递增的策略不同。产生的响应时间完全不同。虽然都没有报错，但是第一种场景是完全不符合真实的业务场景的。这是为什么呢？\n\n在场景的执行过程中，首先，响应时间是从低到高的，而在场景 1 中不是这样。其次，线程应该是递增的，而场景 1 并没有这样做（这里或许有人会想到秒杀的场景，认为场景 1 符合秒杀的业务设定，这个问题我们稍后提及）。最后，在两个场景中，TPS 的上限都达到了 400 TPS。但是你可以看到，在场景 2 中，只要 40 线程即可达到，但场景 1 中居然用到了 500 线程，显然压力过大，所以响应时间才那么长。\n\n其实在生产环境中，","tags":["Linux","极客时间","性能测试"]},{"title":"如何用perf工具分析Java程序","url":"/2025/07/21/2025-07-21-ru-he-yong-perf-gong-ju-fen-xi-java-cheng-xu/","content":"\n## 如何分析容器内的进程\n\n![perf record](/img/2025-07-21-如何用perf工具分析Java程序/image.png)\n\n当使用 perf 工具时，看到 16 进制地址而不是函数名，通常是因为缺少符号信息（symbol information）或调试信息，导致 perf 无法将地址解析为对应的函数名或源代码行。比较常见的场景是分析容器内的子进程，因为容器应用依赖的库都在镜像里面。\n\n针对容器的情况，总结了一下四种解决方法。\n\n**第一种方法，再容器外构建相同路径的依赖库。**这种方法从原理上可行，但是并不推荐，一方面是因为找出这些依赖库比较麻烦，更重要的是，构建这些路径，会污染容器主机环境\n\n**第二种方法，在容器内部运行 perf。**不过，这需要容器运行在特权模式下，但实际的应用程序往往只以普通容器的方式运行。所以，容器内部一般没有权限执行 perf 分析。\n\n比方说，如何你在普通容器内运行 perf record，你将会看到下面这个错误提示：\n\n```shell\n[root@efbd40d93ebf /]# perf record -g -p 1\n\nperf_event_open(…, PERF_FLAG_FD_CLOEXEC) failed with unexpected error 1 (Operation not permitted)\n\nperf_event_open(…, 0) failed unexpectedly with error 1 (Operation not permitted)\n\nError:\n\nNo permission to enable cycles event.\nYou may not have permission to collect stats.\nConsider tweaking /proc/sys/kernel/perf_event_paranoid,\nwhich controls use of the performance events system by\nunprivileged users (without CAP_SYS_ADMIN).\nThe current value is -1:\n-1: Allow use of (almost) all events by all users\n\n Ignore mlock limit after perf_event_mlock_kb without CAP_IPC_LOCK\n\n>= 0: Disallow ftrace function tracepoint by users without CAP_SYS_ADMIN\n\n Disallow raw tracepoint access by users without CAP_SYS_ADMIN\n\n>= 1: Disallow CPU event access by users without CAP_SYS_ADMIN\n\n>= 2: Disallow kernel profiling by users without CAP_SYS_ADMIN\nTo make this setting permanent, edit /etc/sysctl.conf too, e.g.:\nkernel.perf_event_paranoid = -1\n```\n\n从<a href=\"https://docs.docker.com/engine/security/seccomp/\">docker seccomp</a>文档中可以看出，由于安全问题，系统调用 “perf*” 和 “ptrace” 默认被禁止。当然，其实你可以通过配置 /proc/sys/kernel/perf_event_paranoid（比如改成 -1），来允许非特权用户执行 perf 事件分析；不过还是那句话，为了安全起见，这种方式不太推荐。\n\n**第三种方法，指定符号路径为容器文件系统的路径。**\n\n举个例子：我们要分析一个在 Nginx 容器中运行的 worker 进程，可以执行一下命令\n\n```shell\n# 获取 worker 在宿主机上的进程号\nPID = $(docker inspect --format '{{.State.Pid}}' mynginx)\n\n# 宿主机上创建临时目录作为挂载点\nmkdir /tmp/foo\n\n# 使用 bindfs 进行挂载 (需要 root 权限)\nbindfs /proc/$PID/root /tmp/foo\n\n# 使用 perf record 记录性能数据\nperf record -p $PID -g -- sleep 15\n\n# 使用 perf report 分析数据并指定符号路径\nperf report --symfs /tmp/foo\n\n# 卸载 bindfs 挂载\numount /tmp/foo/\n```\n\n不过要注意，bindfs 这个工具需要你额外安装。bindfs 的基本功能是实现目录绑定（类似于 mount --bind）。\n\n**第四种方法，在容器外吧分析记录保存下来，再去容器里查看结果。**这样，库和符号的路径也就都对了。比如，你可以这么做。先运行 `perf record -g -p <pid>`，执行一会儿（比如 15 秒）后，按 Ctrl+C 停止。\n\n然后，把生成的 perf.data 文件，拷贝到容器里边来分析，不过，这里也需要注意 perf 工具的版本问题\n\n```shell\ndocker cp perf.data mynginx:/tmp \ndocker exec -i -t mynginx bash\n\ncd /tmp/ \nyum install perf\nperf report\n```\n\n当你按照前面这几种方法操作后，你就可以在容器内部看到：\n\n![perf report](/img/2025-07-21-如何用perf工具分析Java程序/image2.png)\n\n## 为何看不到原生的Java的调用栈\n\n分析 Java 应用时，perf 工具面临一个根本挑战：Java 代码并非直接在 CPU 上执行原生机器码，而是运行在一个名为 JVM（Java 虚拟机）的托管环境中：\n\n  - JIT 编译的抽象层：JVM 会在运行时通过即时编译（JIT）技术将热点的 Java 字节码动态编译成高效的机器码。这个过程意味着 perf 采样到的是这些动态生成的、无明确符号（函数名）的机器码地址\n  - 非标准调用栈：perf 默认只能识别操作系统层面的函数调用，因此它能看到 JVM 自身的函数（如 JavaMain），但是无法理解 JVM 内部的、属于 Java 应用程序的调用关系\n\n为了让 perf 发挥最用，必须建立一座桥梁，将 JVM 内的函数调用信息与 perf 的系统级采样数据关联起来。可以采用以下方案解决：\n\n步骤一：保留帧指针（Preserve Frame Pointer），这是确保调用栈能被正常回溯的基础\n\n  - 操作：在启动 Java 应用时，添加 JVM 参数 `-XX:-PreserveFramePointer`\n  - 原理：处于性能优化，JIT 编译器默认会省略帧指针，这会释放一个寄存器提供其他用途。然后，perf 等多数性能分析工具依赖帧指针来遍历和回溯函数调用栈。启动此选项可以强制 JVM 保留该信息，从而生成完整、可追溯的调用栈。\n\n步骤二：生成 Java 符合映射表\n\n此步骤的目的是将 perf 看到的内存地址翻译成可读的 Java 函数名\n\n  - 工具：使用 <a href=\"https://github.com/jvm-profiling-tools/perf-map-agent\">perf-map-agent</a>，这是一个专门为此设计的开源工具\n  - 原理：perf-map-agent 会作为一个 Java Agent 附加到目标 JVM 进程上，查询 JIT 编译后的机器码地址与原始 Java 方法名的对应关系，并将其写入一个 perf 能够识别的映射文件（通常是 /tmp/perf-<pid>.map）。perf 在生成报告时会自动检测并使用此文件。\n\n步骤三：使用 perf 采样与分析\n\n完成上述准备后，就可以使用标准的 perf 命令进行性能分析。例如：\n\n```shell\nsudo perf record -F 99 -p <pid> -g -- sleep 30 \n# -F 99：以 99Hz 的频率采样\n# -g：记录调用图（Call Graph）\n\n# 分析采样数据\nsudo perf report\n```\n\n**拓展**：目前有现成的工具解决上述问题，<a href=\"https://github.com/async-profiler/async-profiler\">async-profiler</a>，是一个专为 Java 设计的低开销、高精度的性能分析器，它集成了 perf 的功能并做了大量优化，是目前 Java 性能分析的优选工具。\n","tags":["Linux","性能测试"]},{"title":"Linux性能调优：网络","url":"/2025/06/17/2025-06-17-linux-tracing-network/","content":"\n## Linux网络性能指标\n\n### 性能指标\n\n- 带宽，表示链路的**最大传输速率**，单位通常为 b/s（比特/秒）\n- 吞吐量，表示单位时间内成功传输的数据量，单位通常为 b/s（比特/秒）或者 B/s(字节/秒)。**吞吐量受带宽限制**，而吞吐量/带宽，也就是该网络的使用率\n- 延时，表示从网络请求发出后，一直到收到远端响应，所需要的时间延迟。在不同场景中，这一指标可能会有不同的涵义。比如，它可以表示，建立连接需要的时间（比如 TCP 握手延时），或一个数据包往返所需的时间（比如 RTT）\n- PSS，是 Packet Per Second（包/秒）的缩写，表示以**网络包为单位的传输速率**。PSS 通常用来评估**网络的转发能力**，比如硬件交换机，通常可以达到线性转发（即 PPS 可以达到或者接近理论最大值）。而基于 Linux 服务器的转发，则容易受网络包大小的影响\n\n另外，**网络的可用性**（网络能否正常通信）、**并发连接数**（TCP 连接数量）、**丢包率**（丢包百分比）、**重传率**（重新传输的网络包比例）等也是常用的性能指标。\n\n### 网络配置\n\n使用命令 ifconfig 或者 ip 查看\n\n```\n$ ifconfig eth1\neth1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 9.134.194.74  netmask 255.255.248.0  broadcast 9.134.199.255\n        ether 52:54:00:82:12:e8  txqueuelen 1000  (Ethernet)\n        RX packets 70297502  bytes 34143392231 (31.7 GiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 78816203  bytes 45528648722 (42.4 GiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n$ ip -s  addr show dev eth1\n2: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP qlen 1000\n    link/ether 52:54:00:82:12:e8 brd ff:ff:ff:ff:ff:ff\n    inet 9.134.194.74/21 brd 9.134.199.255 scope global eth1\n       valid_lft forever preferred_lft forever\n    RX: bytes  packets  errors  dropped overrun mcast   \n    34143407013 70297654 0       0       0       0       \n    TX: bytes  packets  errors  dropped carrier collsns \n    45528723929 78816328 0       0       0       0  \n```\n\n第一，网络接口的状态标志。ifconfig 输出 RUNNING，或者 ip 输出中的 LOWER_UP，都表示物理网络是连通，即网卡已经连接到了交换机或者路由器中。如果你看不到它们，通常表示网线被拔掉了。\n\n第二，MTU 的大小。MTU 默认大小是 1500，根据网络架构的不同（比如是否使用了 VXLAN 等叠加网络），你可能需要调大或者调小 MTU 的数值。\n\n第三，网络接口的 IP 地址、子网以及 MAC 地址。这些地址都是保障网络功能正常工作所必须的，你需要确保配置正确。\n\n第四，网络收发的字节数、包数、错误数以及丢包情况，特别是 TX 和 RX 部分的 errors、dropped、overruns、carrier 以及 collisions 等指标不为 0 时，通常表示出现了网络 I/O 问题。其中：\n\n- errors 表示发生错误的数据包数，比如校验错误、帧同步错误等\n- dropped 表示丢弃的数据包数，即数据包已经收到了 Ring Buffer，但因为内存不足等原因丢包\n- overruns 表示超限数据丢包数，即网络 I/O 速度过快，导致 Ring Buffer 中的数据包来不及处理（队列满）而导致的丢包\n- carrier 表示发生 carrirer 错误的数据报数，比如双工模式不匹配、物理电缆出现问题等\n- collisions 表示碰撞数据包数\n\n### 嵌套字信息\n\n使用 netstat 或 ss 来表示**嵌套字、网络栈、网络接口以及路由表的信息**\n\n```\n$ netstat -nlp | head -n 3\nActive Internet connections (only servers)\nProto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name\ntcp        0      0 127.0.0.1:10248         0.0.0.0:*               LISTEN      624565/kubelet\n\n$ ss -ltnp | head -n 3\nState      Recv-Q Send-Q Local Address:Port               Peer Address:Port\nLISTEN     0      65535  127.0.0.1:10248                    *:*                   users:((\"kubelet\",pid=624565,fd=29))\nLISTEN     0      65535  127.0.0.1:10249                    *:*                   users:((\"kube-proxy\",pid=624952,fd=12))\n```\n\n其中，**接收队列（Recv-Q）和发送队列（Send-Q）**需要关注，它们通常是 0。当你发现它们不是 0 时，说明有网络包的堆积发生\n\n当嵌套字处于连接状态（Established）时，\n\n- Recv-Q 表示嵌套字缓冲还没有被应用程序取走的字节数（即接收队列长度）\n- Send-Q 表示还没有被远端主机确认的字节数（即发送队列长度）\n\n当嵌套字处于监听状态（Listening）时，\n\n- Recv-Q 表示当前全连接队列（accept 队列）长度\n- Send-Q 表示全连接队列的最大长度\n\n### 协议栈统计信息\n\n使用 netstat 或 ss 命令\n\n```\n$ netstat -s\nIp:\n    11236847787 total packets received\n    76906 forwarded\n    0 incoming packets discarded\n    10964584370 incoming packets delivered\n    10948611259 requests sent out\n    448 outgoing packets dropped\n    4 dropped because of missing route\nIcmp:\n    37370022 ICMP messages received\n    158 input ICMP message failed.\n    ICMP input histogram:\n        destination unreachable: 141016\n        echo requests: 20256273\n        echo replies: 16972733\n...\n\n[root@pudding-161 ~]# ss -s\nTotal: 1434 (kernel 1816)\nTCP:   1144 (estab 894, closed 164, orphaned 0, synrecv 0, timewait 158/0), ports 0\n\nTransport Total     IP        IPv6\n*         1816      -         -\nRAW       2         1         1\nUDP       13        7         6\nTCP       980       349       631\nINET      995       357       638\nFRAG      0         0         0\n```\n\n### 网络吞吐 和 PPS\n\n使用 sar 命令，加上 -n 参数，可以查看网络的统计信息，比如网络接口（DEV）、网络接口错误（EDEV）、TCP、UDP、ICMP 等\n\n```\n$ sar -n DEV 1\nLinux 3.10.0-957.el7.x86_64 (xxx)       06/18/2025      _x86_64_        (8 CPU)\n\n07:20:42 PM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s\n07:20:43 PM    dummy0      0.00      0.00      0.00      0.00      0.00      0.00      0.00\n07:20:43 PM      eth0    695.00    663.00   6938.75   3796.65      0.00      0.00      0.00\n07:20:43 PM        lo    112.00    112.00     39.30     39.30      0.00      0.00      0.00\n07:20:43 PM kube-ipvs0      0.00      0.00      0.00      0.00      0.00      0.00      0.00\n```\n\n- rxpck/s 和 txpck/s 分别是接收和发送的 PPS，单位为包/秒\n- rxkB/s 和 txkB/s 分别是接收和发送的吞吐量，单位是 KB/s\n- rxcmp/s 和 txcmp/s 分别是接收和发送的压缩数据包数，单位是包/秒\n\n带宽可以用 ethtool 来查询，它的单位通常是 Gb/s 或者 Mb/s（千兆网卡或者万兆网卡的单位都是 bit）\n\n```\n$ ethtool enp4s0f0 | grep Speed\n        Speed: 1000Mb/s\n```\n\n### 连通性和延时\n\n使用命令 ping，来测试远程主机的连通性和延时（基于 ICMP 协议）\n\n如下，测试本机到 baidu.com 这个地址的连通性和延时\n\n```\n$ ping -c3 baidu.com\nPING baidu.com (182.61.201.211) 56(84) bytes of data.\n64 bytes from 182.61.201.211 (182.61.201.211): icmp_seq=1 ttl=49 time=29.1 ms\n64 bytes from 182.61.201.211 (182.61.201.211): icmp_seq=2 ttl=49 time=27.2 ms\n64 bytes from 182.61.201.211 (182.61.201.211): icmp_seq=3 ttl=49 time=27.8 ms\n\n--- baidu.com ping statistics ---\n3 packets transmitted, 3 received, 0% packet loss, time 2002ms\nrtt min/avg/max/mdev = 27.280/28.097/29.158/0.785 ms\n```\n\nping 的输出，可以分为两部分：\n\n- 每个 ICMP 请求的信息，包括 ICMP 序列号（icmp_seq）、TTL（生存时间，或者跳数）以及往返延时\n- 三次 ICMP 请求的汇总\n\n## C10K和C100K问题\n\n### C10K\n\nC10K 代表同时处理 10000 个请求\n\n从资源上来说，对 2GB 内存和千兆网卡的服务器来说，同时处理 10000 个请求，只要每个请求处理占用不到 200KB（2GB/10000）的内存和 100Kbit（1000Mbit/10000）的网络带宽就可以。\n\n从软件上来看，主要是网络 I/O 模型的问题，在 C10K 之前，Linux 主要是**同步阻塞**的方式，每个请求都分配一个进程或者线程，而 10000 个进程或者线程的调度、上下文切换和内存，都可能成为瓶颈。\n\n需要解决的问题：\n\n- 怎样在一个线程内处理多个请求，也就是要在一个线程内响应多个网络 I/O？\n\n#### I/O 模型优化\n\n异步、非阻塞 I/O 的思路：I/O 多路复用\n\n>两种 I/O 时间通知的方式：水平触发和边缘触发\n>水平触发：只要文件描述符可以非阻塞地执行 I/O，就会触发通知。也就是说，应用程序可以随时检查文件描述符地状态，然后再根据状态，进行 I/O 操作。\n>边缘触发：只有在文件描述符的状态发生改变（也就是 I/O 请求达到）时，才会发送一次通知。这时候，应用程序需要尽可能多地执行 I/O，知道无法继续读写，才可以停止。如果 I/O 没执行完，或者因为某种原因没来得及处理，那么这次通知也就丢失了\n\n- 第一种，使用非阻塞 I/O 和水平触发通知，比如使用 select 或者 poll\n- 第二种，使用非阻塞 I/O 和边缘触发通知，比如 epoll（在 select 和 poll 基础上进行优化）\n- 第三种，使用异步 I/O（Asynchronous I/O，简称为 AIO）\n\n#### 工作模型优化\n\nI/O 多路复用有两种主要的工作模式：\n\n**第一种**：主进程 + 多个 worker 子进程（比如 nginx），主要流程是：\n\n- 主进程执行 bind() + listen() 后，创建多个子进程；\n- 在每个子进程中，都通过 accept() 或 epoll_wait() ，来处理相同的套接字\n\n![示意图](/img/2025-06-17-linux_tracing_network/image.png)\n\n**注意**：accept() 和 epoll_wait() 调用，还存在一个**惊群**的问题（当网络 I/O 事件发生时，多个进程被同时唤醒，但实际上只有一个进程来响应这个事件，其他被唤醒的进程都会重新休眠）\n\n为了避免**惊群问题**，Nginx 在每个 worker 进程中，都会增加一个全局锁（accept_mutex）。这些 worder 进程需要首先竞争到锁，只有竞争到锁的进程，才会加入到 epoll 中，这样就确保只有一个 worker 子进程被唤醒\n\n**第二种**：监听到相同端口的多进程模型，所有的进程都监听相同的端口，有各自的套接字，开启 SO_REUSEPORT 选项（Linux 3.9+ 才支持），由内核负责将请求负载均衡到这些监听进程中去\n\n![示意图](/img/2025-06-17-linux_tracing_network/image2.png)\n\n### C1000K\n\nC1000K 代表同时 100w 个请求\n\n- 从物理资源上来说，100 万个请求需要大量的系统资源\n    - 内存：假设每个请求需要 16KB 内存的化，那么总共就需要大约 15GB 内存\n    - 带宽：假设只有 20% 活跃连接，即使每个连接只需要 1KB/s 的吞吐量，总共需要 200000 * 8 / 1024 / 1024 = 1.6 Gb/s 的吞吐量，千兆网卡已经不能够满足，需要配置万兆网卡\n- 从软件资源上来说，大量的连接也会占用大量的软件资源，比如**文件描述符的数据、连接状态的跟踪（CONNTRACK）、网络协议栈的缓存大小（比如套接字读写缓存、TCP 读写缓存）**等等，也会带来**大量的中断处理**\n\n**优化**：在 I/O 多路复用的基础上，需要多队列网卡、硬中断负载均衡、CPU 绑定、RPS/RFS（软中断负载均衡到多个 CPU 核上），以及将网络包的处理卸载（Offload）到网络设备（如 TSO/GSO、LRO/GRO、VXLAN OFFLOAD）等各种硬件和软件的优化。\n\n### C10M\n\n同时有 1000w 个请求，解决方法是**跳过内核协议栈**，将网络包直接发送到要处理的应用程序\n\n第一种机制：DPDK（Data Plane Development Kit），用户网络的标准，跳过内核协议栈，直接由用户态进程通过轮询的方式来处理网络请求\n\n![示意图](/img/2025-06-17-linux_tracing_network/image3.png)\n\n第二种机制：XDP（eXpress Data Path），Linux 内核提供的一种高性能网络数据路径，它允许网络包，在进入内核协议栈之前，就进行处理\n\n![示意图](/img/2025-06-17-linux_tracing_network/image4.png)\n\n## 怎么评估系统的网络性能\n\n### 各协议层的性能测试\n\n#### 转发性能\n\nhping3 工具，测试网络包的处理能力：<a href=\"https://wangchujiang.com/linux-command/c/hping3.html\"> hping3 手册 </a>\n\n#### TCP/UDP 性能\n\niperf 网络性能测试工具：<a href=\"https://wangchujiang.com/linux-command/c/iperf.html\"> iperf 手册 </a>\n\niperf3 是 iperf 的重写版本，一些常用参数：\n\n|主要参数|参数说明|\n|--|--|\n|-s|服务端专用参数，表示 iperf3 以服务端模式运行|\n|-c|客户端专用参数，表示 iperf3 以客户端模式运行|\n|-i|设置每次报告之间的时间间隔，单位为秒|\n|-p|服务端：指定服务端监听的端口，默认为 5201，同时监听 TCP/UDP。<br> 客户端：指定客户端连接服务端的端口，默认为 5201。如果同时有 -u 参数，表示通过 UDP 发起连接，否则默认使用 TCP 连接|\n|-u|表示使用 UDP 协议发送报文。若不指定该参数则表示使用 TCP 协议|\n|-l|设置读写缓冲区的长度。通常测试包转发性能时建议该值设为 16，测试带宽时建议该值设为 1400|\n|-b|UDP 模式使用的带宽，单位 bit/s|\n|-t|设置传输的总时间。iperf3 在指定时间内，重复发送指定长度数据包的时间，默认值为 10 秒|\n|-A|设置 CPU 亲和性，可以将 iperf3 进程绑定对应编号的逻辑 CPU，避免 iperf3 进程在不同的 CPU 间被调度|\n","tags":["Linux","性能测试"]},{"title":"Linux性能调优：I/O","url":"/2025/06/02/2025-06-02-linux-tracing-io/","content":"\n## 文件系统和磁盘的区别\n\n磁盘是一个存储设备（确切来说是块设备），可以划分为不同的磁盘分区。而在磁盘或者磁盘分区上，还可以在创建文件系统，并挂载到系统的某个目录。这样，系统就可以通过这个挂载目录，来读写文件。\n\n换句话说，磁盘是存储数据的块设备，也是文件系统的载体。所以，文件系统确实还是要通过磁盘，来保证数据的持久化存储。\n\n**Linux 中一切皆文件**。可以通过相同的文件接口，来访问磁盘和文件（比如 open、read、write、close 等）\n\n- 通常说的“文件”，是指普通文件\n- 磁盘和分区，是指块设备文件\n\n在读写普通文件时，I/O 请求会首先经过文件系统，然后由文件系统负责，来与磁盘进行交互。而读写块设备文件时，会跳过文件系统，直接与磁盘交互，也就是所谓的“裸 I/O”。文件系统管理的缓存，是 Cache 的一部分；而裸磁盘的缓存，用的正是 Buffer。\n\n>裸磁盘，也称为原始磁盘，是一种未被任何文件系统（如NTFS、FAT32）格式化或管理的磁盘。换句话说，它是直接与磁盘硬件交互，而不通过操作系统的文件系统层进行访问。\n\n缓存 I/O 与直接 I/O（裸磁盘 I/O ）的对比\n\n|特性|缓存I/O（文件系统）|直接I/O（裸磁盘）|\n|--|--|--|\n|数据流|磁盘 → 内核缓冲区 → 应用程序地址空间|磁盘 → 直接应用程序地址空间|\n|缓存使用|使用文件系统管理的Cache|使用磁盘的Buffer|\n|性能|适合常规文件操作，减少磁盘读写次数|适合高性能场景，如数据库，减少文件系统开销|\n|应用场景|普通文件读写，系统默认方式|虚拟化、数据库优化、低级别磁盘操作|\n|优点|保护系统安全，减少直接磁盘访问风险|降低数据复制开销，提高I/O效率|\n|缺点|数据复制开销高，CPU和内存占用多|需要应用程序管理缓存，可能增加复杂性|\n\n## Linux 文件系统如何工作\n\n### 索引节点和目录项\n\n- 索引节点（inode），和文件一一对应，存储在磁盘中，记录文件的元数据\n- 目录项（dentry），记录文件的名字、索引节点以及其他目录项的关联关系\n\n举例说明，为文件创建的硬链接，会对应不同的目录项，他们都连接到同一个文件，索引节点相同。\n\n磁盘的最小单位是**扇区**，文件系统将连续的扇区组成逻辑块，以逻辑块为最小单位，来读写磁盘数据。常见的逻辑块 4KB，由连续的 8 个扇区组成。\n\n![示意图](/img/2025-06-02-linux_tracing_io/image.png)\n\n磁盘在执行文件系统格式化时，分为三个区域：超级块、索引节点和数据块：\n\n- 超级块：整个文件系统的状态\n- 索引节点区：存储索引节点\n- 数据块区：存储文件数据\n\n### 虚拟文件系统\n\n![示意图](/img/2025-06-02-linux_tracing_io/image2.png)\n\n文件系统分类：\n\n- 基于磁盘的文件系统：常见的 ext4、XFS、OverlayFS 等，都是这类文件系统\n- 基于内存的文件系统：常说的虚拟文件系统，不需要磁盘空间，但是占用内存。比如，/proc 和 /sys\n- 网络文件系统：用于访问其他计算机的文件系统，比如 NFS、SMB、ISCSI 等\n\n**注意**：这些文件系统，要先挂载到 VFS 目录树中的某个子目录（称为**挂载点**），然后才能访问其中的文件。\n\n### 文件系统 I/O\n\n根据是否利用标准库缓存，分为**缓冲 I/O 和非缓冲 I/O**：\n\n- 缓存 I/O：利用标准库缓存，加速文件访问，标准库内部利用系统调用访问文件\n- 非缓存 I/O：直接通过系统调用访问文件，不再经过标准库缓存\n\n**注意**：这里的“缓冲”，是指**标准库内部实现的缓存**，最终还是需要通过系统调用，而系统调用还会通过**页缓存**，来较少磁盘的 I/O 操作\n\n根据是否利用操作系统的**页缓存**，分为**直接 I/O 和非直接 I/O**：\n\n- 直接 I/O：跳过操作系统的页缓存，直接和**文件系统**交互来访问文件\n- 非直接 I/O：先通过页缓存，再通过内核或者额外的系统调用，真正和磁盘交互（O_DIRECT 标志）\n\n根据应用程序是否阻塞自身，分为**阻塞 I/O 和非阻塞 I/O**：\n\n- 阻塞 I/O：是指应用程序执行 I/O 操作后，如果没有获得响应，就会阻塞当前线程\n- 非阻塞 I/O：是指应用程序执行 I/O 操作后，不会阻塞当前的线程，可以继续执行其他的任务，随后再通过**轮询或者事件通知**的形式，获取调用的结果\n\n根据是否等待相应结果，分为**同步 I/O 和异步 I/O**：\n\n- 同步 I/O：应用程序执行 I/O 操作之后，要等到整个 I/O 完成后，才能获得 I/O 响应\n- 异步 I/O：应用程序不用等待 I/O 完成，会继续执行，等到 I/O 执行完成，会以事件的方式通知应用程序\n\n设置 O_SYNC 或者 O_DSYNC，代表同步 I/O。如果是 O_DSYNC，要等到文件数据写入磁盘之后，才能返回，如果是 O_SYNC，是在 O_DSYNC 的基础上，要求文件**元数据**写入磁盘，才返回。\n\n设置 O_ASYNC，代表异步 I/O，系统会再通过 SIGIO 或者 SIFPOLL 通知进程。\n\n### 性能观测\n\n#### 容量\n\ndf 命令查看磁盘空间\n\n```\n$ df -h /dev/vdb\nFilesystem      Size  Used Avail Use% Mounted on\n/dev/vdb        400G   95G  306G  24% /var/lib/docker\n\n# 查看索引节点所占的空间\n$ df -i /dev/vdb\nFilesystem        Inodes  IUsed     IFree IUse% Mounted on\n/dev/vdb       209715200 546727 209168473    1% /var/lib/docker\n```\n\n当索引节点空间不足，但是索引空间充足时，可能是过多小文件导致的。**解决方法**一般是删除这些小文件，或者移动到索引节点充足的其他磁盘区。\n\n#### 缓存\n\n可以使用 free 或者 vmstat，观察页缓存的大小；也可以查看 /proc/meminfo\n\n```\n$ cat /proc/meminfo | grep -E \"SReclaimable|Cached\"\nCached:          3987272 kB\nSwapCached:       109532 kB\nSReclaimable:    4095228 kB\n```\n\n内核使用 slab 机制，管理目录项和索引节点的缓存，/proc/meminfo 给出了整体的 slab 大小，/proc/slabinfo 可以查看每一种 slab 的缓存\n\n```\n[root@pudding-160 ~]# cat /proc/slabinfo | grep -E '^#|dentry|inode'\n# name            <active_objs> <num_objs> <objsize> <objperslab> <pagesperslab> : tunables <limit> <batchcount> <sharedfactor> : slabdata <active_slabs> <num_slabs> <sharedavail>\nfuse_inode           189    189    768   21    4 : tunables    0    0    0 : slabdata      9      9      0\novl_inode          11534  15600    680   24    4 : tunables    0    0    0 : slabdata    650    650      0\nxfs_inode         175054 175372    960   34    8 : tunables    0    0    0 : slabdata   5158   5158      0\nmqueue_inode_cache    288    288    896   36    8 : tunables    0    0    0 : slabdata      8      8      0\nhugetlbfs_inode_cache     52     52    608   26    4 : tunables    0    0    0 : slabdata      2      2      0\nsock_inode_cache    2255   2475    640   25    4 : tunables    0    0    0 : slabdata     99     99      0\nshmem_inode_cache   6783   7056    680   24    4 : tunables    0    0    0 : slabdata    294    294      0\nproc_inode_cache   28816  29688    656   24    4 : tunables    0    0    0 : slabdata   1237   1237      0\ninode_cache        34463  35208    592   27    4 : tunables    0    0    0 : slabdata   1304   1304      0\ndentry            20014134 20014134    192   21    1 : tunables    0    0    0 : slabdata 953054 953054      0\nselinux_inode_security  15708  15708     40  102    1 : tunables    0    0    0 : slabdata    154    154      0\n```\n\n其中 dentry 代表目录项缓存，inode_cache 代表 VFS 索引节点缓存，其他的就是各种文件系统的索引节点缓存。\n\n实际性能分析中，更常使用 slabtop 命令，来找出占用内存最多的缓存类型。\n\n示例如下：可以看到，目录项占用了最多的 Slab 缓存，大约 3.91 G\n\n```\n# 按下c按照缓存大小排序，按下a按照活跃对象数排序 \n$ slabtop\n Active / Total Objects (% used)    : 22757396 / 23018218 (98.9%)\n Active / Total Slabs (% used)      : 1067320 / 1067320 (100.0%)\n Active / Total Caches (% used)     : 72 / 103 (69.9%)\n Active / Total Size (% used)       : 4462258.28K / 4545420.86K (98.2%)\n Minimum / Average / Maximum Object : 0.01K / 0.20K / 8.00K\n\n  OBJS ACTIVE  USE OBJ SIZE  SLABS OBJ/SLAB CACHE SIZE NAME\n21574896 21574735  99%    0.19K 1027376       21   4109504K dentry\n355914 286236  80%    0.10K   9126       39     36504K buffer_head\n223872 205323  91%    0.06K   3498       64     13992K kmalloc-64\n175372 175125  99%    0.94K   5158       34    165056K xfs_inode\n 57600  57529  99%    0.16K   2400       24      9600K xfs_ili\n136528  53170  38%    0.57K   4876       28     78016K radix_tree_node\n...\n```\n\n## Linux 磁盘 I/O 工作原理\n\n### 磁盘\n\n根据存储介质，磁盘分为：\n\n- 机械磁盘，也称为硬盘驱动器（Hard Disk Driver），通常缩写为 HDD。机械磁盘主要有盘片和读写磁头组成，数据就存储在盘片的环状磁道中。在读写数据前，需要移动读写磁头，定位数据所在的磁道，才能访问数据。如果 I/O 请求刚好连续，就不需要磁道寻址，可以获得最佳性能。这就是连续 I/O 的工作原理。与之对应的是随机 I/O，它需要不停地移动磁头，来定位数据位置，读写速度就会比较慢。\n- 固态磁盘（Silid State Disk），通常缩写为 SSD，由固态电子元件组成。固态磁盘不需要磁盘寻址，不管是连续 I/O，还是随机 I/O 的性能，都比机械磁盘要好得多。\n\n无论是机械磁盘，还是固态磁盘，相同磁盘的随机 I/O 都要比连续 I/O 慢得多，原因是：\n\n- 随机 I/O 需要更多的磁头寻道和盘片旋转，它的性能自然要比连续 I/O 慢\n- 对于固态硬盘来说，虽然它的随机性能比机械磁盘好很多，但同样存在“先擦除再写入”的限制。随机读写会导致大量的垃圾回收，所以相对应的，随机 I/O 的性能比起连续 I/O 来，也还差了很多\n- 连续 I/O 还可以通过预读的方式，来减少 I/O 请求的次数，这也是其性能优异的一个原因\n\n最小读写单位：\n\n- 机械硬盘的最小读写单位是扇区，一般是 512 字节\n- 固态硬盘的最小读写单位是页，一般是 4KB 或者 8KB\n\n按照接口，磁盘可分为 IDE（Integrated Drive Electronics）、SCSI（Small Computer System Interface） 、SAS（Serial Attached SCSI） 、SATA（Serial ATA） 、FC（Fibre Channel）等。\n\n磁盘介入服务器时，按照不通的使用方式，会划分为不用的架构：\n\n- 最简单的直接作为独立磁盘设备来使用\n- 将多块磁盘组合成一个逻辑磁盘，构成冗余独立磁盘阵列（RAID），提高数据访问的性能，并增强数据存储的可靠性\n- 最后一种，是将磁盘组合成网络存储集群，再通过 NFS、SMB、ISCSI 等网络存储协议，暴露给服务器使用\n\n在 Linux 中，磁盘是作为一个块设备来管理，以块为单位来读写，支持随机读写。每个块设备赋予两个设备号，分别是主、次设备号，主设备号用在驱动程序中，用来区分设备类型；次设备号用来在多个同类设备编号。\n\n### 通用块层\n\n和 VFS 类似，为了减少不同设备的差异带来的影响，Linux 通过统一的通用块（块 I/O 层），管理不同的块设备。\n\n块设备层是处在文件系统和磁盘驱动中间的一个块设备抽象层，主要功能是：\n\n- 向上为文件系统和应用程序提供访问块设备的标准接口；向下，把各种异构的磁盘块设备抽象为统一的块设备，提供统一框架管理这些设备的驱动程序\n- 通用块层还会给文件系统和应用程序发来 I/O 请求排队，并通过重新排序、请求合并等方式，提高磁盘读写的效率\n\n对 I/O 请求排序的过程就是 I/0 调度，Linux 支持的四种 I/O 调度算法，分别是 NONE、NOOP、CFQ 以及 DeadLine：\n\n- NONE，不适用任何调度，对 I/O 不做任何处理（常用在虚拟机，此时磁盘 I/O 完全由物理机复杂）\n- NOOP，先入先出调度（常用在 SSD）\n- CFQ（Completely Fair Schedule）完全公平调度器，很多 Linux 发行版的默认调度器，它为每个进程维护了一个 I/O 调度队列，按照时间片来均匀分配每个进程的 I/O 请求；还支持优先级调度，适用于大量进程的系统（如桌面、多媒体应用等）\n- DeadLine 调度算法，分别为读、写请求创建了不同的 I/O 队列，可以提高机械磁盘的吞吐量，并确保打到最终期限（deadline）的请求被优化处理，多用在 I/O 压力比较重的场景，比如数据库等\n\n### I/O 栈\n\n![示意图](/img/2025-06-02-linux_tracing_io/image3.png)\n\n根据这张 I/O 栈的全景图，可以看出存储系统 I/O 的工作原理\n\n- 文件系统层，包括虚拟文件系统和其他文件系统的具体实现。它为上层的应用程序，提供标准的文件访问接口；对下会通过快层，来存储和管理磁盘资源\n- 通用块层，包括块设备 I/O 队列和 I/O 调度器。他会对文件系统的 I/O 请求进行排队，再通过重新排序和请求合并，然后才要发给下一级的设备层\n- 设备层，包括存储设备和相应的驱动程序，负责最终物理设备的 I/O 操作\n\n存储系统的 I/O，通常是整个系统最慢的一环。\n\nLinux 通过多种缓存机制来优化 I/O 效率。为了优化文件访问的性能，会使用页缓存、索引节点缓存等多种机制，以减少对下层块设配的直接调用。同样，为了优化块设备，会使用缓冲区，来缓存块设备的数据。\n\n### 磁盘性能指标\n\n使用率、饱和度、IOPS、吞吐量以及响应时间五个指标，是磁盘性能的基本指标\n\n- 使用率，是指磁盘处理 I/O 的时间百分比。过高的使用率（比如超过 80%），通常意味着磁盘 I/O 存在性能瓶颈\n- 饱和度，是指磁盘处理 I/O 的繁忙程度。过高的饱和度，意味着存在严重的性能瓶颈。当饱和度为 100% 时，磁盘无法接受新的 I/O 请求\n- IOPS（Input/Output Per Second），是指每秒的 I/O 请求数\n- 吞吐量，是指每秒 I/O 请求大小\n- 响应时间，是指 I/O 请求从发出到收到响应的间隔时间\n\n注意：\n\n1. 使用率只考虑有没有 I/O，而不考虑 I/O 的大小。换句话说，当使用率是 100% 的时候，磁盘依然有可能接受到新的 I/O 请求\n2. 随即读写多（如数据库、大量小文件）的情况下主要关注 IOPS，而顺序读写（如流媒体）的情况下，主要关注吞吐量\n\n在为应用程序的服务器选型时，要先对磁盘的 I/O 性能进行基准测试，以便可以准确评估，磁盘性能是否可以满足应用程序的需求\n\n### 磁盘 I/O 观测\n\n使用 iostat 观测每块磁盘的使用情况，提供了每个磁盘的使用率、IOPS、吞吐量等各种常见的性能指标，这些指标实际上来自 /proc/diskstats\n\n```\n$ iostat -dx 1\nLinux 3.10.0-1160.76.1.el7.x86_64 (idc16)       2025年06月16日  _x86_64_        (40 CPU)\n\nDevice:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nsda               0.00     0.69    1.56   25.12    62.56   270.97    25.01     0.27   10.01    0.84   10.58   1.18   3.14\nsdd               0.00     0.27    0.17    1.33    10.66    42.08    70.12     0.01    8.48    6.95    8.68   0.26   0.04\nsdc               0.00     0.61    0.27    9.80    13.02   193.43    41.03     0.04    3.52    0.82    3.59   0.06   0.06\nsde               0.00     0.22    0.21    1.38    11.79    43.80    70.07     0.01    8.43    7.23    8.61   0.26   0.04\nsdf               0.00     0.24    0.07    1.29    13.02    18.95    47.09     0.00    3.29   17.06    2.56   0.20   0.03\nsdh               0.00     0.26    0.01    1.32     1.49    19.72    31.78     0.00    1.70    9.23    1.63   0.09   0.01\nsdg               0.00     0.23    0.05    1.30    11.18    21.33    48.10     0.01    4.07   24.12    3.28   0.21   0.03\nsdi               0.00     0.28    0.04    1.67     9.65    19.50    33.96     0.00    1.86   25.33    1.26   0.15   0.03\nsdj               0.00     0.24    0.36    2.35    21.61   247.35   198.58     0.14   51.46    4.47   58.60   0.49   0.13\nsdb               0.00     0.46    1.66    8.00   180.35   210.13    80.81     0.08    8.74    2.84    9.97   0.20   0.19\ndm-0              0.00     0.00    0.85   18.11    38.11   144.32    19.24     0.17    8.82    0.56    9.21   1.14   2.16\ndm-1              0.00     0.00    0.00    0.00     0.00     0.00    49.16     0.00   11.10   11.10    0.00   9.62   0.00\nscd0              0.00     0.00    0.00    0.00     0.00     0.00    80.31     0.00  813.35  813.35    0.00 809.27   0.00\ndm-2              0.00     0.00    0.00    0.21     0.04    16.16   155.78     0.02   99.54    2.63  100.60   1.79   0.04\ndm-3              0.00     0.00    0.68    4.54    22.80    72.63    36.54     0.07   14.35    1.04   16.35   1.31   0.69\ndm-4              0.00     0.00    0.02    2.93     0.38    37.73    25.90     0.03   10.70    4.72   10.73   1.32   0.39\n```\n\n各个指标解读如下\n\n![iostat 指标解读图](/img/2025-06-02-linux_tracing_io/image4.png)\n\n注意：\n\n- %util，就是我们前面提到的磁盘 I/O 使用率\n- r/s + w/s，就是 IOPS\n- rkB/s + wkB/s，就是吞吐量\n- r_await+w_await，就是响应时间\n\n在观测指标时，可以结合请求的大小（rareq-sz 和 wareq-sz）一起分析。\n\n### 进程 I/O 观测\n\npidstat 可以实时查看某个进程的 I/O 情况\n\n```\n$ pidstat -d 1\nLinux 3.10.0-957.el7.x86_64 (xxx)       06/17/2025      _x86_64_        (8 CPU)\n\n07:12:18 PM   UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s  Command\n07:12:19 PM    27    362006      0.00    594.17    590.29  mysqld\n07:12:19 PM     0    362323      0.00      3.88      3.88  docker-containe\n07:12:19 PM     0    362403      0.00      7.77      0.00  kundb-meta-serv\n07:12:19 PM     0    362518      0.00      3.88      0.00  java\n07:12:19 PM 65534    363123      0.00      3.88      0.00  prometheus\n07:12:19 PM     0    372218      0.00      7.77      0.00  java\n07:12:19 PM     0    383196      0.00     19.42      0.00  dockerd\n07:12:19 PM     0    389626      0.00     23.30      0.00  kube-apiserver\n07:12:19 PM     0    389731      0.00     62.14      0.00  etcd\n07:12:19 PM     0    391157      0.00     11.65      0.00  kubelet\n07:12:19 PM     0    760300      0.00     11.65      0.00  kundb-meta-serv\n```\n\n指标如下：\n\n- 用户 ID（UID）和进程 ID（PID）\n- 每秒读取的数据大小（kB_rd/s），单位是 KB\n- 每秒发出的写请求数据大小（kB_wr/s），单位是 KB\n- 每秒取消的写请求数据大小（KB_ccwr/s），单位是 KB","tags":["Linux","性能测试"]},{"title":"如何“快准狠”找到系统内存的问题","url":"/2025/05/30/2025-05-30-ru-he-kuai-zhun-hen-de-zhao-dao-xi-tong-nei-cun-wen-ti/","content":"\n## 内存性能指标\n\n系统调用内存分配请求后，并不会立刻为其分配物理内存，而是在请求首次访问时，通过缺页异常来分配\n\n缺页异常又分为以下两种场景：\n\n- 可以直接从物理内存中分配时，被称为**次缺页异常**\n- 需要磁盘 I/O 介入（比如 Swap）时，被称为**主缺页异常**\n\n![内存性能指标](/img/2025-05-30-如何快准狠的找到系统内存问题/image.png)\n\n## 分析内存性能瓶颈\n\n分析过程如下图\n\n- 先用 free 和 top，查看系统整体的内存使用情况\n- 再用 vmstat 和 pidstat，查看一段时间的趋势，从而判断出内存问题的类型\n- 最后进行详细分析，比如内存分配分析、缓存/缓冲区分析、具体进程的内存使用分析等\n\n![分析内存性能](/img/2025-05-30-如何快准狠的找到系统内存问题/image2.png)\n\n## 总结\n\n内存常见的优化思路有这么几种\n\n- 最好禁止 Swap。如果必须开启 Swap，降低 swappiness 的值，减少内存回收时 Swap 的使用倾向\n- 减少内存的动态分配。比如，可以使用内存池、大页（HugePage）等\n- 尽量使用缓存和缓冲区来访问数据。比如，可以使用堆栈明确声明内存空间，来存储需要缓存的数据；或者用 Redis 这类的外部缓存组件，优化数据的访问\n- 使用 cgroups 等方式限制进程的内存使用情况。这样，可以确保系统内存不会被异常进程耗尽\n- 通过 /proc/pid/oom_adj，调整核心应用的 oom_score。这样，可以保证即使内存紧张，核心应用也不会被 OOM 杀死\n","tags":["Linux","性能测试"]},{"title":"Linux性能调优：内存","url":"/2025/05/28/2025-05-28-linux-tracing-mem/","content":"\n## Linux内存工作原理\n\n### 内存分配与回收\n\nmalloc() 是 C 标准库提供的内存分配函数，对应到系统调用上，有两种实现方式，即 brk() 和 mmap()。\n\n对小块内存（小于 128K），C 标准库使用 brk() 来分配，也就是通过移动堆顶的位置来分配内存。这些内存释放后并不会立刻归还系统，而是被缓存起来，这样就可以重复使用。\n\n对大块内存（大于 128K），则使用内存映射 mmap() 来分配，也就是在文件映射找一块空闲内存分配出去。\n\n各自的**优缺点**：\n\n- brk() 方式的缓存，可以减少缺页异常的发生，提高内存访问效率；不过，由于这些内存没有归还系统，在内存工作繁忙时，频繁的内存分配和释放会造成内存碎片\n- mmap() 方式分配的内存，会在释放时直接归还系统，所以每次 mmap 都会发生缺页异常。在内存工作繁忙时，频繁的内存分配会导致大量的缺页异常，使内核的管理负担增大\n\n整体来说，Linux 使用**伙伴系统**来管理内存分配。前面我们提到过，这些内存在 MMU 中以页为单位进行管理，伙伴系统也一样，以页为单位来管理内存，并且会通过相邻页的合并，减少内存碎片化（比如 brk 方法造成的内存碎片）。\n\n在用户空间，malloc 通过 brk() 分配的内存，在释放时并不立即归还系统，而是缓存起来重复利用。在内核空间，Linux 通过 slab 分配器来管理小内存，可以把 slab 堪称构建在**伙伴系统上的一个缓存**，主要作用就是分配并释放内核中的小对象。\n\n系统也不会任由某个进程用完所有内存。在发现内存紧张时，系统会通过一系列机制来回收内存：\n\n- 回收内存，比如使用 LRU（Least Recently Used）算法，回收最近使用最少的内存页面\n- 回收不常访问的内存，把不常用的内存交换分区直接写到磁盘中（会用到交换分区）\n- 杀死进程，内存紧张时系统还会通过 OOM（Out of Memory），直接杀掉占用大量内存的进程\n\nOOM 是内核的一种保护机制。它监控进程的内存使用情况，并且使用 oom_score 为每个进程的内存使用情况进行评分：\n\n- 进程消耗的内存越大，oom_score 就越大\n- 进程运行占用的 CPU 越多，oom_score 就越小\n\n可以手动设置进程的 oom_adj 来调整 oom_score。oom_adj 的范围是 [-17, 15]，数值越大，进程越容易被杀死；反之，越不容易被杀死。\n\n### 如何查看内存使用情况\n\n1、free 命令\n```\n$ free\n              total        used        free      shared  buff/cache   available\nMem:      262695500   106731876   141173212     4257008    14790412   149168720\nSwap:             0           0           0\n```\n\n- total：总内存\n- used：已使用内存，包括共享内存\n- free：空闲内存\n- shared：共享内存\n- buff/cache：缓存内存，包括缓冲区和缓存\n- available：可用内存，包括空闲内存和缓存内存\n\n**注意**：available 不仅包含未使用内存，还包括了可回收的缓存，所以一般会比未使用内存更大。不过，并不是所有缓存都可以回收，因为有些缓存可能正在使用中。\n\n2、top 命令\n\n可以查看每个进程的内存使用情况\n\n```\ntop - 19:28:02 up 201 days,  2:48,  2 users,  load average: 134.36, 136.81, 111.38\nTasks: 1284 total,   6 running, 1278 sleeping,   0 stopped,   0 zombie\n%Cpu(s): 87.2 us,  8.9 sy,  0.0 ni,  0.9 id,  0.0 wa,  1.8 hi,  1.1 si,  0.0 st\nMiB Mem : 256538.6 total, 137892.3 free, 104201.3 used,  14445.0 buff/cache\nMiB Swap:      0.0 total,      0.0 free,      0.0 used. 145701.9 avail Mem\n\n    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND\n 607070 root      20   0  266.3g  82.5g  79228 S  4861  33.0  40025:32 tabletserver_ma\n 835494 root      20   0 8557368 207048  10872 S 121.7   0.1 357:04.40 java\n 842048 1001      20   0   32.8g  31168  14888 S 113.0   0.0   0:03.41 java\n 840498 root      20   0  727932  31336   7304 R  91.3   0.0   2164:46 node_exporter\n 653917 root      20   0   12.3g 997944  46948 S  78.3   0.4  15877:42 kubelet\n...\n```\n\n- VIRT：虚拟内存，只要是进程申请过的内存，即便还没有真正分配物理内存，也会计算在内\n- RES：实际内存，也就是进程**实际使用的物理内存**大小，但**不包括 Swap 和共享内存**\n- SHR：共享内存，比如与其他进程共同使用的共享内存、加载的动态链接库以及程序的代码段等\n- %MEM：进程占用的物理内存占系统总内存的百分比\n\n**注意**：\n\n- 虚拟内存通常并不会全部分配物理内存。从上面的输出，你可以发现每个进程的虚拟内存都大于实际内存，这是因为虚拟内存是进程申请的内存，即使进程没有真正分配物理内存，也会计算在内。\n- 共享内存 SHR 并不一定是共享的，比方说，**程序的代码段、非共享的动态内存链接库**，也都在 SHR 里。SHR 也包括了**进程间真正共享的内存**。所以在计算多个进程的内存使用时，不要把所有进程的 SHR 直接相加得出结果\n\n## 内存的 Buffer 和 Cache\n\n### free 的数据来源\n\nman free 查看\n\n![man free](/img/2025-05-28-linux_tracing_mem/image.png)\n\n从手册看到：\n\n- Buffers：Memory used by kernel buffers (Buffers in /proc/meminfo)\n- Cache：Memory used by the page cache and slabs (Cached and Slab in /proc/meminfo)\n\n### proc 文件系统\n\nman proc 查看\n\n```\nBuffers %lu\n       Relatively temporary storage for raw disk blocks that shouldn't get tremendously large (20MB or so).\n\nCached %lu\n       In-memory cache for files read from the disk (the page cache).  Doesn't include SwapCached.\n...\nSReclaimable %lu (since Linux 2.6.19)\n       Part of Slab, that might be reclaimed, such as caches.\n\nSUnreclaim %lu (since Linux 2.6.19)\n       Part of Slab, that cannot be reclaimed on memory pressure.\n```\n\n通过文档可以看到：\n\n- Buffers 是对原始磁盘的临时存储，也就是用来缓存磁盘的数据，通常不会特别大（20MB 左右）。这样，内核就可以把分散的写集中起来，统一优化磁盘的写入，比如可以把多次小的写入合并成单次大的写等等。\n- Cached 是从单磁盘读取文件的页缓存，也就是用来缓存从文件读取的数据。这样，下次访问这些文件数据时，就可以直接从内存中快速获取，而不需要再次访问缓慢的磁盘。\n- Slab 代表内核数据结构缓存，包括两部分，其中的可回收部分，用 SReclaimable 记录；而不可回收部分，用 SUnreclaim 记录。\n\n## 案例测试\n\n### 场景一：磁盘和文件写\n\n运行 vmstat 命令\n\n```\n$ vmstat 1\nprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----\n r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st\n 1  0 1218088 16790772     60 8758252    0    0    24    97    0    0 12  6 82  0  0\n 4  0 1218088 16779960     60 8762060    0    0     0   159 15274 28820 16  9 75  0  0\n 2  0 1218088 16779968     60 8761840    0    0     0   154 13467 26984  9  4 87  0  0\n 0  0 1218088 16778620     60 8762068    0    0     0   212 13980 26715  6  5 89  0  0\n 6  0 1218088 16773376     60 8762136    0    0     0   170 12838 25315  4  3 93  0  0\n 2  0 1218088 16780544     60 8762164    0    0     0   343 13195 25313  5  4 91  0  0\n 0  0 1218088 16783260     60 8762392    0    0     0   116 18099 33200 13 10 78  0  0\n 1  0 1218088 16782896     60 8762400    0    0     0    40 10645 21760  2  2 96  0  0\n 0  0 1218088 16780616     60 8762412    0    0     0    97 12603 24496  3  3 94  0  0\n 1  0 1218088 16780708     60 8762436    0    0     0    90 14724 27729  9  4 87  0  0\n 1  0 1218088 16779376     60 8762472    0    0     0   116 12702 25101  3  3 93  0  0\n 0  0 1218088 16775968     60 8765976    0    0     0   133 16290 29873 19 10 71  0  0\n 0  0 1218088 16783224     60 8765996    0    0     0    89 13359 25299  4  3 93  0  0\n 0  0 1218088 16782604     60 8766016    0    0     0    73 10976 22399  2  2 96  0  0\n 8  0 1218088 16775272     60 8766032    0    0     0   122 13109 26159  4  2 94  0  0\n```\n\n- buff 和 cache 就是我们前面看到的 Buffers 和 Cache，单位是 KB\n- bi 和 bo 则分别表示块设备读取和写入的大小，单位为 块/秒。因为 Linux 中块的大小是 1KB，所以这个单位也就等价于 KB/s\n\n在另一中端执行 dd 命令通过读取随机设备，生成一个 500MB 大小的文件\n\n```\ndd if=/dev/urandom of=/mnt/disk1/log bs=1M count=500\n```\n\n继续观察 buff 和 cache 的变化如下：\n\n```\n$ vmstat 1\nprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----\n r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st\n 6  0 1218088 16808024     60 8706284    0    0     0   135 17194 30511 12  5 82  0  0\n 2  0 1218088 16812680     60 8706316    0    0     0   108 14214 27386  3  2 94  0  0\n 0  0 1218088 16822344     60 8706268    0    0     0    82 12608 25281  2  2 96  0  0\n 0  0 1218088 16828356     60 8706284    0    0     0    65 16971 31578  6  5 89  0  0\n...\n 1  2 1218088 16438876     60 9110220    0    0     0 264629 19007 27977  5 20 73  1  0\n 8  1 1218088 16324916     60 9227456    0    0     0 22966 20049 31235 13 21 61  5  0\n 2  0 1218088 16329904     60 9227244    0    0     0   327 11770 24005  4  3 87  7  0\n 0  0 1218088 16329340     60 9227248    0    0     0    91 11558 22878  3  2 95  0  0\n 5  0 1218088 16329532     60 9227264    0    0     0    88 14350 28661 10  5 85  0  0\n 1  0 1218088 16325480     60 9227056    0    0     0   162 16735 30309 11  8 81  0  0\n 2  1 1218088 16325424     60 9230360    0    0     0 225680 15589 31332 15 10 72  2  1\n 1  0 1218088 16325160     60 9231060    0    0     0   124 14815 26517 10  6 79  5  0\n\n```\n\n可以看到：\n\n- 在 dd 命令运行时，Cache 在不停地增长，而 Buffer 基本保持不变\n- 在 dd 命令结束后，Cache 不再增长，但是块设备写还会持续一段时间，并且，多次 1/0 写的结果加起来，才是 dd 要写的 500M 的数据\n\n下面的命令对环境要求很高，需要你的系统配置多块磁盘，并且磁盘分区 /dev/sdb1 还要处于未使用状态。**如果你只有一块磁盘，千万不要尝试，否则将会对你的磁盘分区造成损坏**。\n\n如果你的系统符合标准，就可以继续在第二个终端中，运行下面的命令。清理缓存后，向磁盘分区 /dev/sdb1 写入 2GB 的随机数据：\n\n```\n# 首先清理缓存\n$ echo 3 > /proc/sys/vm/drop_caches\n# 然后运行 dd 命令向磁盘分区 /dev/sdb1 写入 2G 数据$ dd if=/dev/urandom of=/dev/sdb1 bs=1M count=2048\n```\n\n然后，再回到终端一，观察内存和 I/O 的变化情况：\n\n```\nprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----\n r b swpd free buff cache si so bi bo in cs us sy id wa st\n 1 0 0 7584780 153592 97436 0 0 684 0 31 423 1 48 50 2 0 \n 1 0 0 7418580 315384 101668 0 0 0 0 32 144 0 50 50 0 0 \n 1 0 0 7253664 475844 106208 0 0 0 0 20 137 0 50 50 0 0 \n 1 0 0 7093352 631800 110520 0 0 0 0 23 223 0 50 50 0 0 \n 1 1 0 6930056 790520 114980 0 0 0 12804 23 168 0 50 42 9 0 \n 1 0 0 6757204 949240 119396 0 0 0 183804 24 191 0 53 26 21 0 \n 1 1 0 6591516 1107960 123840 0 0 0 77316 22 232 0 52 16 33 0\n```\n\n从这里你会看到，虽然同是写数据，写磁盘跟写文件的现象还是不同的。写磁盘时（也就是 bo 大于 0 时），Buffer 和 Cache 都在增长，但显然 Buffer 的增长快得多。\n\n### 场景二：磁盘和文件读\n\n运行文件读的命令如下\n```\n# 文件读\n$ dd if=/mnt/disk1/log of=/dev/null\n```\n\n```\n$ echo 3 > /proc/sys/vm/drop_caches\n$ mstat 1\nprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----\n r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st\n 1  0 1218088 22631652      0 3037032    0    0   792   225 15443 29060 17  8 75  0  0\n 1  0 1218088 22629780      0 3037096    0    0    48    33 13210 25184  3  3 94  0  0\n 8  0 1218088 22474456      0 3192744    0    0 155593   379 11851 21896  4  6 89  0  0\n 5  0 1218088 22184464      0 3471364    0    0 282644   181 13324 22371  5 12 83  0  0\n 0  0 1218088 22119672      0 3549248    0    0 73920    82 14720 26164  7  8 84  0  0\n 0  0 1218088 22118224      0 3549468    0    0   136    29 17030 32835 13  9 78  0  0\n 2  0 1218088 22116736      0 3549488    0    0    80   327 11854 23476  4  2 93  0  0\n```\n\n运行磁盘读的命令如下\n\n```\n# 磁盘读\n$ dd if=/dev/vdc of=/dev/null bs=1M count=1024\n```\n\n```\n$ dvmstat 1\nprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----\n r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st\n 6  0 1218088 21827684      0 3716568    0    0    24    97    0    0 12  6 82  0  0\n 4  0 1218088 21816680      0 3721036    0    0     0   117 16130 30199 16 11 73  0  0\n 0  0 1218088 21819240      0 3720212    0    0     9   195 14200 26901  6  4 89  0  0\n 1  0 1218088 21818228      0 3720252    0    0     4   123 11836 23517  3  2 95  0  0\n 1  0 1218088 21802832  14336 3720200    0    0 17369   248 10953 21760  3  2 91  4  0\n 2  1 1218088 21740512  75776 3720308    0    0 58416    77 14897 27732  4  5 79 11  0\n 3  1 1218088 21696460 133120 3720692    0    0 57344    76 20717 40621 14 10 66  9  0\n10  0 1218088 21639256 190464 3720328    0    0 57372   349 18512 29321 11  5 75 10  0\n 2  1 1218088 21600056 247808 3720308    0    0 57344    72 17332 28977 10  5 74 10  0\n 8  1 1218088 21539120 296960 3720340    0    0 49152   688 22618 37060 16  8 66  9  0\n 0  1 1218088 21473532 354304 3720184    0    0 57348   109 18331 30615  9  5 74 11  0\n 1  1 1218088 21414276 407552 3723624    0    0 53248   150 16057 29868 17  9 64 10  0\n 0  1 1218088 21356020 464896 3723924    0    0 57344    29 14159 25301 12  4 74 10  0\n 2  1 1218088 21302964 518144 3723736    0    0 53248   147 10678 21725  3  2 84 12  0\n 2  0 1218088 21278632 542720 3724092    0    0 24576   428 10163 21080  2  2 91  5  0\n 8  0 1218088 21269044 542720 3724072    0    0     0    73 15601 29313  7  5 88  0  0\n23  0 1218088 21272568 542720 3724488    0    0     0    33 20061 36123 22 12 67  0  0\n```\n\n可以看到，读取文件时（也就是 bi 大于 0 时），Buffer 保持不变，而 Cache 则在不停增长；而读取磁盘时，Cache 保持不变，Buffer 不断增长。\n\n## 结论\n\nBuffer 是对磁盘数据的缓存，而 Cache 是文件数据的缓存，它们既会用在读请求中，也会用在写请求中。\n","tags":["Linux","性能测试"]},{"title":"系统的Swap机制","url":"/2025/05/16/2025-05-16-xi-tong-de-swap-ji-zhi/","content":"\n**文件页**：代表可回收内存，文件页的大部分可以直接回收，以后有需要时，再从磁盘重新读取；而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放\n\n脏页一般以两个方式写入磁盘：\n\n- 在应用程序中，通过系统调用 fync，把脏页同步到磁盘中\n- 由内核线程 pdflush 负载这些脏页的刷新\n\n**匿名页**：应用程序动态分配的**堆空间**，使用 swap 机制回收\n\n## Swap 原理\n\nSwap 简单来说就是把一块磁盘空间或者一个本地文件夹，当成内存来使用。它包括换出和换入两个过程：\n\n- **换出**，就是把进程暂时不用的内存数据存储到磁盘中，并释放这些数据占用的内存\n- **换入**，则是把进程再次访问这些内存的时候，把它们从磁盘读到内存中来\n\n常见的笔记本电脑的休眠和快速开机功能，也基于 Swap。休眠时，把系统的内存存入磁盘，这样等到再次开机时，只要从磁盘中加载内存就可以。这样省去了很多应用程序的初始化过程，加快了开机速度。\n\n内存回收的时机：\n\n1、**直接内存回收**：当有新的大块内存分配请求，但是剩余内存不足，这个时候系统就需要回收一部分内存\n\n2、**内核线程 kswapd0**来定期回收内存，它定义了三个内存阈值（watermark，也称为水位），分别是页最小阈值（pages_min）、页最低阈值（pages_low）和页最高阈值（pages_high）。剩余内存，则使用 pages_free 表示\n\n![pages_free](/img/2025-05-16-系统的Swap机制/image.png)\n\nkswapd0 定期扫描内存的使用情况，并根据剩余内存落在这三个阈值的空间位置，进行内存的会后操作：\n\n- 剩余内存小于页最小阈值，说明进程可用内存都耗尽了，只有内核才可以分配空间\n- 剩余内存落在页最小阈值和页最低阈值中间，说明内存压力比较大，剩余内存不多了。这时 kswapd0 会执行内存回收，直到剩余内存大于高阈值为止\n- 剩余内存落在页最低阈值和页最高阈值中间，说明内存有一定压力，但还可以满足新压力请求\n- 剩余内存大于页内存阈值，说明剩余内存比较多，没有内存压力\n\n**页低阈值**是由内核选项 /proc/sys/vm/min_free_kbytes 设置，其他两个阈值，都是根据页最小阈值计算生成的\n\n## NUMA 和 Swap\n\n在 NUMA 架构下，多个处理器被划分到不同 Node 上，且每个 Node 都拥有自己的本地内存空间。而同一个 Node 内部的内存空间，实际上又可以在进一步分为不同的内存域（Zone），比如直接内存访问区（DMA）、普通内存区（NORMAL）、伪内存区（MOVABLE）等，如下图所示：\n\n![Node 内部的内存空间](/img/2025-05-16-系统的Swap机制/image2.png)\n\n使用 numactl 命令查看 Node 的分布情况\n\n```\n$ numactl --hardware\navailable: 2 nodes (0-1)\nnode 0 cpus: 0 1 2 3 4 5 6 7 8 9 20 21 22 23 24 25 26 27 28 29\nnode 0 size: 130960 MB\nnode 0 free: 7308 MB\nnode 1 cpus: 10 11 12 13 14 15 16 17 18 19 30 31 32 33 34 35 36 37 38 39\nnode 1 size: 131072 MB\nnode 1 free: 17581 MB\nnode distances:\nnode   0   1\n  0:  10  21\n  1:  21  10\n```\n\n前面提到的三个内存阈值（页最小阈值、页低阈值和页高阈值），都可以通过内存域在 proc 文件系统中的接口 /proc/zoneinfo 来查看\n\n```\n$ cat /proc/zoneinfo| head -n 20\nNode 0, zone      DMA\n  pages free     3957\n        min      7\n        low      8\n        high     10\n        scanned  0\n        spanned  4095\n        present  3992\n        managed  3971\n    nr_free_pages 3957\n    nr_alloc_batch 2\n    nr_inactive_anon 0\n    nr_active_anon 0\n    nr_inactive_file 0\n    nr_active_file 0\n    nr_unevictable 0\n    nr_mlock     0\n    nr_anon_pages 0\n    nr_mapped    0\n    nr_file_pages 0\n```\n\n主要指标包括：\n\n- pages 处的 min、low、high，就是上面提到的三个内存阈值，而 free 是**剩余内存页数**，它跟后边的 nr_free_pages 相同\n- nr_zone_active_anon 和 nr_zone_inactive_anon，分别代表**活跃匿名页**和**不活跃匿名页**的数量\n- nr_zone_active_file 和 nr_zone_inactive_file，分别代表**活跃文件页**和**不活跃文件页**的数量\n\n某个 Node 内存不足时，系统可以从其他 Node 寻找空闲内存，也可以从本地内存种回收内存。具体选哪种模式，你可以通过 /proc/sys/vm/zone_reclaim_mode 来调整。它支持以下几个选项：\n\n- 默认的是 0，也就是刚刚提到的模式，表示既可以从其他 Node 寻找空闲内存，也可以从本地内存中回收\n- 1、2、4 都表示只回收本地内存，2 表示可以回写脏数据来回收内存，4 表示可以用 Swap 方式回收内存\n\n## swapness\n\n内存回收包括文件页和匿名页：\n\n- 对文件页的回收，是直接回收缓存，或者把脏页写回磁盘后再回收\n- 对匿名页的回收，是通过 Swap 机制，把它们写入磁盘后再释放内存\n\nLinux 提供了一个 /proc/sys/vm/swapiness 选项，用来调整使用 Swap 的积极程度；swappiness 的范围是 0-100，数值越大，越积极使用 Swap，也就是更倾向于回收匿名页；数值越小，越消极使用 Swap，也就是更倾向于回收文件页。\n\n## 系统 Swap 升高的原因\n\n### 案例\n\nLinux 本身支持两种类型的 Swap，即 Swap 分区和 Swap 文件，以 Swap 文件为例子，例如如下命令开启 Swap 文件\n\n```\n# 创建swap文件\nfallocate -l 500M /data/swapfile\n# 修改权限，仅root用户可读写\nchmod 600 /data/swapfile\n# 配置swap文件\nmkswap /data/swapfile\n# 开启swap\nswapon /data/swapfile\n```\n\n执行 free 看到 swap 添加成功\n\n```\n$ free\n              total        used        free      shared  buff/cache   available\nMem:       16092196      562160      613616      295992    14916420    15135272\nSwap:        511996           0      511996\n```\n\n执行 dd 命令，模拟大文件的读取\n\n```\ndd if=/dev/vdb1 of=/dev/null bs=1G count=400\n```\n\n执行 sar 查看内存和 swap 指标\n\n```\n$ sar -rS 3\nLinux 3.10.107-1-tlinux2_kvm_guest-0051 (VM_194_74_centos)      07/05/20        _x86_64_        (8 CPU)\n\n20:16:14    kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty\n20:16:17     12016228   4075968     25.33   1944876    394804   3089884     18.61   2364636   1364468        88\n\n20:16:14    kbswpfree kbswpused  %swpused  kbswpcad   %swpcad\n20:16:17       511996         0      0.00         0      0.00\n\n20:16:17    kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty\n20:16:20     11542068   4550128     28.28   2405684    394868   3089856     18.61   2364984   1825212       120\n\n20:16:17    kbswpfree kbswpused  %swpused  kbswpcad   %swpcad\n20:16:20       511996         0      0.00         0      0.00\n...\n\n20:16:50    kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty\n20:16:53      6331744   9760452     60.65   7474548    395052   3089736     18.61   2364948   6894124        84\n\n20:16:50    kbswpfree kbswpused  %swpused  kbswpcad   %swpcad\n20:16:53       511996         0      0.00         0      0.00\n...\n\n20:17:44    kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty\n20:17:47        90140  16002056     99.44  13573540    392440   3089728     18.61   2180308  13149900       164\n\n20:17:44    kbswpfree kbswpused  %swpused  kbswpcad   %swpcad\n20:17:47       486836     25160      4.91       120      0.48\n...\n\n20:18:44    kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty\n20:18:47        87988  16004208     99.45  13658536    354504   3089760     18.61   2112144  13218932       140\n\n20:18:44    kbswpfree kbswpused  %swpused  kbswpcad   %swpcad\n20:18:47       403652    108344     21.16       140      0.13\n```\n\n可以看到，总的内存使用率（%memused）在不断增长，从开始的 25% 一直涨到了 99%，并且主要内存都被缓冲区（kbbuffers）占用，大致的变化过程为：\n\n- 刚开始，剩余内存（kbmemfree）不断减少，而缓冲区（kbbuffers）则不断增大，由此可知，剩余内存不断分配给了缓冲区\n- 一段时间后，剩余内存已经很小了，而缓存区占用了大部分内存。此时，Swap 的使用开始逐渐增大，缓冲区和剩余内存则只在小范围内波动\n\n为什么 Swap 会升高呢？（按理来说，应该先回收缓冲区的内存，这属于可回收内存），观察 /proc/zoneinfo 指标如下\n\n```\n$ watch -d grep -A 15 'Normal' /proc/zoneinfo\n\nEvery 2.0s: grep -A 15 Normal /proc/zoneinfo                                                             Sun Jul  5 20:19:39 2020\n\nNode 0, zone   Normal\n  pages free     5200\n        min      3268\n        low      4085\n        high     4902\n        scanned  24\n        spanned  3407872\n        present  3407872\n        managed  3276302\n    nr_free_pages 5200\n    nr_inactive_anon 134532\n    nr_active_anon 246943\n    nr_inactive_file 2466171\n    nr_active_file 280987\n    nr_unevictable 0\n    nr_mlock     0\n```\n\n可以看到，剩余内存（pages free）在一个很小范围内不停地波动。当它小于页低阈值（pages low）时，又会突然增大到一个大于页高阈值（pages high）的数值\n\n- 当剩余内存小于页低阈值时，系统会回收一些缓存和匿名内存，使剩余内存增大。其中，缓存的回收导致 sar 中的缓冲区减少，而匿名内存的回收导致了 Swap 的使用增大。其中，缓存的回收导致 sar 中的缓冲区减少，而匿名内存的回收导致了 Swap 的使用增大。\n- 同事由于 dd 还在继续，剩余内存又会重新分配给缓存，导致剩余内存减少，缓冲区增大\n\n利用 proc 文件系统，可以查看 Swap 换出的虚拟内存大小，它保存在 /proc/pid/status 中 VmSwap\n\n```\n$ for file in /proc/*/status ; do awk '/VmSwap|Name|^Pid/{printf $2 \" \" $3}END{ print \"\"}' $file; done | sort -k 3 -n -r | head\nsystemd-journal 3048 86160 kB\nwriteback 50 \nwatchdog/7 41 \nwatchdog/6 36 \nwatchdog/5 31 \nwatchdog/4 26 \nwatchdog/3 21 \nwatchdog/2 16 \nwatchdog/1 11 \nwatchdog/0 10 \n```\n\n可以看到，使用 swap 较多的是 systemd-journal\n\n结束之后，需要关闭 swap\n\n```\nswapoff -a\n```\n\n一般关闭 swap 并重新打开，可以这么执行（是一种常见的 swap 清理方法）\n\n```\nswapoff -a && swapon /data/swapfile\n```\n\n### 小结\n\n在内存资源紧张时，Linux 会通过 Swap，把不常访问的匿名页换出到磁盘中，下次访问的时候再从磁盘换入到内存中来。你可以设置 /proc/sys/vm/min_free_kbytes，来调整系统定期回收内存的阈值；也可以设置 /proc/sys/vm/swappiness，来调整文件页和匿名页的回收倾向。\n\n当 Swap 变高时，你可以用 sar、/proc/zoneinfo、/proc/pid/status 等方法，查看系统和进程的内存使用情况，进而找出 Swap 升高的根源和受影响的进程。\n\n通常，降低 Swap 的使用，可以提高系统的整体性能。有几种常见的降低方法：\n\n- 禁用 Swap，现在服务器的内存走足够大，所有除非有必要，一般会**禁用 Swap**，大部分云平台中的虚拟机都默认禁用 Swap\n- 如果实在需要用到 Swap，可以尝试**降低 swappiness**值，减少内存回收时 Swap 的使用倾向\n- 响应延迟敏感的应用，如果它们可能在开启 Swap 的服务器中运行，你还可以使用库函数 mlock() 或者 mlockall() **锁定内存**，阻止它们的内存换出\n\n常见的三种清理缓存的方法：\n\n1、清理 pagecache\n```\necho 1 > /proc/sys/vm/drop_caches  # 或者 sysctl -w vm.drop_caches = 1\n```\n\n2、清理 dentries 和 inodes\n\n```\necho 2 > /proc/sys/vm/drop_caches  # 或者 sysctl -w vm.drop_caches = 2\n```\n\n3、清理 pagecache、dentries 和 inodes\n\n```\necho 3 > /proc/sys/vm/drop_caches  # 或者 sysctl -w vm.drop_caches = 3\n```\n\n4、使用 sync 命令来清理文件系统内存，还会清理僵尸（zombie）对象和它们占用的内存\n\n```\nsync\n```\n","tags":["Linux","性能测试"]},{"title":"Linux性能调优：cpu","url":"/2025/05/15/2025-05-15-linux-tracing-cpu/","content":"\n## 怎么理解“平均负载”\n\n简单来说，平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数。它和 CPU 使用率没有直接关系，因为 CPU 使用率是指单位时间内 CPU 繁忙程度的百分比。\n\n> 可运行状态：进程正在运行或准备运行。也就是我们常用 ps 命令看到的处于 R 状态的进程\n> 不可中断状态：进程正在等待某个事件的完成，例如 I/O 操作、等待锁、等待信号量等。也就是我们常用 ps 命令看到的处于 D 状态的进程\n\n那么，在实际生产环境中，平均负载多高时，需要我们重点关注呢？\n\n在我看来，当平均负载高于 CPU 数量 70% 的时候，就应该分析排查负载高的问题了。平均负载提供了一个快速查看系统整体性能的手段，反映了整体的负载情况。但是平均负载本身，我们不能直接发现到底是哪里出现了瓶颈。所以，在理解平均负载时，也要注意：\n\n- 平均负载高可能是 CPU 密集型进程导致的\n- 平均负载高不一定代表 CPU 利用率高，还有可能是 I/0 更繁忙了\n- 当发现负载高的时候，你可看到使用 mpstat、pidstat 等工具，辅助分析负载的来源\n\n## CPU 上下文切换（上）\n\n- CPU 上下文：包括 CPU 寄存器和程序计数器\n- CPU 寄存器：是 CPU 内置的容量小、但速度极快的内存\n- 程序计数器：是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置的寄存器\n\n![cpu 架构](/img/2025-05-15-linux_tracing_cpu/image.png)\n\n- CPU 上下文切换：是先把前一个任务的 CPU 上下文（也就是 CPU 寄存器和程序计数器）保存起来，然后加载到新任务的上下文到这些寄存器和程序计数器，然后再跳转到程序计数器指向的新位置，运行新任务\n- 这些保存下来的上下文，会存储在系统内核中，并在任务重新调度执行时再次加载出来\n\n根据任务的不同，CPU 的上下文切换可分为进程上下文切换、线程上下文切换和中断上下文切换。\n\n### 进程上下文切换\n\nLinux 按照特权等级，把进程的运行空间分为内核空间和用户空间，对应着下图，CPU 特权等级的 Ring 0 和 Ring 3。\n\n- 内核空间（Ring 0）具有最高权限，可以直接访问所有资源\n- 用户空间（Ring 3）只能访问受限资源，不能直接访问内存等硬件设备，必须通过系统调用陷入到内核中，才能访问这些特权资源\n\n![运行空间](/img/2025-05-15-linux_tracing_cpu/image2.png)\n\n从进程用户态到内核态的转变，需要通过**系统调用**来完成，系统调用的过程中会发生**两次 CPU 上下文切换**。CPU 里原本用户态指令的执行位置需要先保存起来，然后更新为内核态的指令位置，最后跳转到内核态运行内核任务；在系统调用结束后，CPU 寄存器需要恢复原本保存的用户态，然后再切换到用户空间，继续执行进程。\n\n**注意：**\n\n1. 系统调用的过程中，不会涉及到虚拟内存等进程态的资源，不会切换进程，系统调用过程和进程上下文切换不一样，整个过程都是同一个进程\n2. 系统调用称为特权模式切换，不是上下文切换\n\n进程上下文切换和系统调用的区别是，进程的上下文切换比系统调用多了一步：在保存当前进程的内核状态和 CPU 寄存器之前，需要先把该进程的虚拟内存、栈等保存下来；而加载了下一进程的内核态后，还需要刷新进程的虚拟内存和用户栈。\n\n![进程上下文切换](/img/2025-05-15-linux_tracing_cpu/image3.png)\n\n**保存上下文和恢复上下文的过程需要内核在 CPU 上运行才能完成**（上下文切换过程是 CPU 密集型），每次上下文切换都需要几十纳秒到数微妙的 CPU 时间。\n\n在进程上下文切换次数过多的情况下，很容易导致 CPU 将大量时间耗费在**寄存器、内核栈以及虚拟内存**等资源的保存和恢复上，进而大大缩短了真正运行进程的时间，从而导致系统平均负载升高。\n\nLinux 通过 TLB（Translation Lookaside Buffer）来管理虚拟内存到物理内存的映射关系。当虚拟内存更新后，TLB 也需要刷新，内存的访问也会随之变慢。特别是在**多处理器系统**上，缓存是被多个处理器**共享**的，刷新缓存不仅会影响当前处理器的进程，还会影响共享缓存的其他处理器的进程。\n\nLinux 为每个 CPU 都维护了一个就绪队列，将活跃进程（即正在运行和正在等待 CPU 的进程）按照优先级和等待 CPU 的时间排序，然后选在最需要 CPU 的进程，也就是**优先级最高和等待 CPU 时间最长**的进程来运行。\n\n进程被 CPU 重新调度的时机：\n\n1. 进程执行完终止了，它之前使用的 CPU 会释放出来，这个时候再从就绪队列里，拿一个新的进程过来运行\n2. 为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，就会被系统挂起，切换到其它正在等待 CPU 的进程运行\n3. 进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其它进程运行\n4. 进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度\n5. 有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行\n6. 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序\n\n### 线程上下文切换\n\n线程和进程的区别：**线程是调度的基本单位，而进程则是资源拥有的基本单位**。\n\n所谓内核中的任务调度，实际上的调度对象是**线程**；而进程只是给线程提供了虚拟内存、全局变量等资源。\n\n- 当进程只有一个线程时，可以认为进程就等于线程\n- 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源。这些资源在上下文切换时是不需要修改的\n- 另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的\n\n因此，线程的上下文切换分为两种情况：\n\n- 前后两个进程属于不同进程。此时，因为资源部共享，所以切换过程就跟进程上下文切换是一样的\n- 前后两个线程属于用一个进程。此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的**私有数据、寄存器**等不共享的资源\n\n**注意：**同进程的线程切换要比进程间的切换消耗更少的资源，更加轻量级\n\n### 中断上下文切换\n\n为了响应硬件事件，**中断处理会打断进程的正常调度和执行**，转而调用中断处理程序，响应设备事件。\n\n中断上下文切换不会涉及进程的用户态，它其实只包括内核态中断服务程序执行所必需的状态，包括 **CPU 寄存器、内核堆栈、硬件中断参数**等\n\n对同一个 CPU 来说，中断处理比进程拥有更高的优先级，所以**中断上下文切换不会与进程上下文切换同步发生**\n\n大部分中断处理程序都短小精悍，以便尽可能快的执行结束。\n\n中断上下文切换也需要消耗 CPU，切换次数过多也会消耗大量的 CPU，甚至严重降低系统的整体性能\n\n## CPU上下文切换（下）\n\n### 查看上下文切换\n\n1、查看系统的总体情况\n\n```\n$ vmstat 5 5\nprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----\n r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st\n 4  0 1218196 17324820     60 8417344    0    0    25    97    0    0 12  6 82  0  0\n 1  0 1218196 17311424     60 8426964    0    0   900    97 15273 28505 11  6 83  0  0\n 1  0 1218196 17399080     60 8343224    0    0   410   310 15800 29604  8  6 86  0  0\n 9  0 1218196 17385124     60 8350312    0    0   787   300 13754 26351  7  4 89  0  0\n 2  0 1218196 17415052     60 8336488    0    0   276   132 15567 29585  8  5 87  0  0\n```\n\n参数：\n\n- cs：context switch，每秒上下文切换的次数\n- in：interrupt，每秒中断的次数\n- r：运行队列的长度（正在运行和等待CPU的进程数）\n- b：处于阻塞状态的进程数\n\n2、查看进程的详细信息\n\n```\n$ pidstat -w 5\nLinux 3.10.0-957.el7.x86_64 (xxx)       05/27/2025      _x86_64_        (8 CPU)\n\n07:35:35 PM   UID       PID   cswch/s nvcswch/s  Command\n07:35:40 PM     0         1      3.77      0.40  systemd\n07:35:40 PM     0         3      2.58      0.00  ksoftirqd/0\n07:35:40 PM     0         7      7.34      0.00  migration/0\n07:35:40 PM     0         9    218.45      0.00  rcu_sched\n07:35:40 PM     0        11      0.40      0.00  watchdog/0\n07:35:40 PM     0        12      0.40      0.00  watchdog/1\n07:35:40 PM     0        13      3.57      0.00  migration/1\n...\n```\n\n参数：\n\n- cswch/s：每秒自愿上下文切换的次数\n- nvcswch/s：每秒非自愿上下文切换的次数\n\n>自愿上下文切换：进程无法获取所需资源导致的上下文切换，比如 I/O，内存等系统资源不足时发生的上下文切换\n>非自愿上下文切换：进程因时间片已到等原因，被系统强制调度发生的上下文切换，比如多个进程竞争 CPU 是发生的上下文切换\n\n### 案例分析\n\nsysbench 模拟多线程调度切换\n\n1、运行 sysbench\n\n```\n# 以 10 个线程运行 5 分钟的基准测试，模拟多线程切换的问题\n$ sysbench --threads=10 --max-time=300 threads run\n```\n\n2、运行 vmstat\n\n```\n$ vmstat 1\nprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----\n r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st\n 9  0      0 107736672     64 88038080    0    0    24   199    0    1  2  1 97  0  0\n 8  0      0 107731792     64 88045280    0    0 16384    40 105267 1167081 12 15 72  0  0\n 9  0      0 107733720     64 88038080    0    0  4192    20 100233 1237404  6 16 78  0  0\n 7  0      0 107726368     64 88045280    0    0 14464    68 128551 1548455  6 17 78  0  0\n10  0      0 107735168     64 88039216    0    0  4096    64 111126 1468157  6 16 78  0  0\n...\n```\n\n指标观察：\n\n- cs 列：上升到 100w\n- r 列：就绪队列长度上升到 10\n- in 列：终端次数上升到 10w\n- us（user）和sy（system）列：使用率加起来接近 100%，sy 为 78%，主要被内核占用\n\n3、查看进程情况\n\n```\n# 每隔1秒输出1组数据（需要 Ctrl+C 才结束）\n# -w 参数表示输出进程切换指标，而 -u 参数则表示输出 CPU 使用指标\n$ pidstat -w -u 1\n19时34分55秒   UID       PID    %usr %system  %guest    %CPU   CPU  Command\n19时34分56秒     0    561077    0.00    1.00    0.00    1.00     2  sshd\n19时34分56秒     0    562599  100.00  100.00    0.00  100.00    13  sysbench\n19时34分56秒     0    566600    0.00    2.00    0.00    2.00    32  pidstat\n\n19时34分55秒   UID       PID   cswch/s nvcswch/s  Command\n19时34分56秒     0    256312      1.00      0.00  kworker/37:31\n19时34分56秒     0    263655      1.00      0.00  kworker/33:2\n19时34分56秒     0    299865      1.00      0.00  kworker/21:2\n19时34分56秒     0    562931      1.00      2.00  vmstat\n19时34分56秒     0    560904      1.00      0.00  sshd\n19时34分56秒     0    561077     78.00      0.00  sshd\n19时34分56秒     0    566600      1.00    671.00  pidstat\n```\n\n分析：CPU 使用率的升高果然是 sysbench 导致的，它的 CPU 使用率已经达到了 100%。但上下文切换则是来自其他进程，包括非自愿上下文切换频率最高的 pidstat ，以及自愿上下文切换频率最高的内核线程 kworker 和 sshd\n\n**注意：**pidstat 输出的上下文切换次数，加起来也就几百，比 vmstat 的 100 万明显小了太多？\n\n|工具|统计粒度|上下文切换数据来源|显示内容|\n|--|--|--|--|\t\t\n|pidstat|按进程/线程级别|/proc/[pid]/sched 或 /proc/[pid]/status|显示某些（非全部）PID 的上下文切换次数|\n|vmstat|系统全局级别|内核调度器|显示全系统每秒上下文切换总数|\n\n4、查看线程情况\n\n```\n# 每隔 1 秒输出一组数据（需要 Ctrl+C 才结束）\n# -wt 参数表示输出线程的上下文切换指标\n$ pidstat -wt 1\n19时34分55秒  UID      TGID       TID   cswch/s nvcswch/s  Command\n19时34分56秒     0    616348         -      0.00      0.00  sysbench\n19时34分56秒     0         -    616348      0.00      0.00  |__sysbench\n19时34分56秒     0         -    616349  67080.00      6.00  |__sysbench\n19时34分56秒     0         -    616350  63009.00      3.00  |__sysbench\n19时34分56秒     0         -    616351  68060.00      1.00  |__sysbench\n19时34分56秒     0         -    616352  69808.00      4.00  |__sysbench\n19时34分56秒     0         -    616353  68806.00      5.00  |__sysbench\n19时34分56秒     0         -    616354  73688.00      6.00  |__sysbench\n19时34分56秒     0         -    616355  72296.00      4.00  |__sysbench\n19时34分56秒     0         -    616356  63978.00      1.00  |__sysbench\n19时34分56秒     0         -    616357  67409.00      1.00  |__sysbench\n19时34分56秒     0         -    616358  67859.00      2.00  |__sysbench\n\n```\n\n可以看到，sysbench 进程（也就是主线程）的上下文切换次数看起来并不多，但它的子线程的上下文切换次数却有很多。上下文切换罪魁祸首，还是过多的 sysbench 线程\n\n5、查看中断升高的原因\n\n```\n$ watch -d cat /proc/interrupts\n           CPU0       CPU1       CPU2\n...\n RES:  117962220   27310354   17986708   Rescheduling interrupts\n...\n```\n\n观察发现，变化速度最快的是重调度中断（RES），它代表唤醒空闲状态的 CPU 来调度新的任务运行，这是在多处理器系统（SMP）中，调度器用来分散任务到不同 CPU 的机制，通常也被称为处理器间中断（Inter-Processor Interrupts，IPI）\n\n**分析：**过多任务导致了重调度中断的升高，和前面分析结果一致\n\n## 每秒上下文切换多少次正常\n\n**上下文切换次数取决于系统本身的CPU性能。**如果系统的上下文切换次数比较稳定，那么从数百到一万以内，都应该算是正常的。但当上下文切换次数超过一万次，或者切换次数出现数量级增长时，就很有可能出现了性能问题，这时根据具体上下文切换的类型具体分析：\n\n- 资源上下文切换变多了，说明进程在等在资源，可能发生了 I/O 等其他问题\n- 非自愿上下文切换变多了，说明进程都在被强制调度，也就是都在争抢 CPU，说明 CPU 的确成了瓶颈\n- 中断次数变多了，说明 CPU 被中断处理程序占用，还序号通过查看 /proc/interrupts 文件来分析具体的中断类型\n","tags":["Linux","性能测试"]},{"title":"如何迅速分析出CPU的瓶颈","url":"/2025/05/15/2025-05-15-ru-he-xun-su-fen-xi-chu-cpu-de-ping-jing/","content":"\n## CPU性能指标\n\n性能指标总览\n\n![性能指标总览](/img/2025-05-15-如何迅速分析出CPU的瓶颈/image.png)\n\n### CPU使用率\n\nCPU 使用率描述了非空闲时间占总 CPU 时间的百分比，根据 CPU 上运行任务的不同，又被分为用户 CPU、系统 CPU、等待 I/0 CPU、软中断和硬中断等。用户 CPU 使用率，包括用户态 CPU 使用率（user）和低优先级用户态：\n\n- CPU 使用率（nice），表示 CPU 在**用户态**运行的时间百分比。用户 CPU 使用率高，通常说明有**应用程序**比较繁忙\n- 系统 CPU 使用率，表示 CPU 在内核状态运行的时间百分比（不包括中断）。系统 CPU 使用率高，说明**内核**比较繁忙\n- 等待 I/O 的 CPU 使用率，通常为 iowait，表示**等待 I/O** 的时间百分比。iowait 高，通常说明系统与硬件设备的 I/O 交互比较长\n- 软中断和硬中断的 CPU 利用率，分别表示内核调用软中断处理程序、硬中断处理程序的时间百分比。它们的使用率高，通常说明系统发生了大量的中断\n- 除了上述这些，还有在虚拟化环境中会用到的**窃取 CPU 利用率（steal）和客户 CPU 使用率（guest）**，分别表示被其他虚拟机占用的 CPU 时间百分比，和运行客户虚拟机的 CPU 时间百分比\n\n### 平均负载\n\n系统的活跃进程数。反映了系统的整体负载情况，主要包括三个数值，分别表示过去 1 分钟、过去 5 分钟和过去 15 分钟的平均负载。理想情况下，平均负载等于逻辑 CPU 个数，这个代表每个 CPU 都恰好被充分利用。如果负载大于逻辑 CPU 个数，就表示负载比较重了。\n\n### 进程上下文切换\n\n进程上下文切换分为：自愿上下文切换和非自愿上下文切换\n\n注意：过多的上下文切换，会将原本运行进程的 CPU 时间，消耗在**寄存器、内核栈以及虚拟内存等数据的保存和恢复上**，缩短进程真正进行的时间，成为性能瓶颈。\n\n### CPU 缓存命中率\n\nCPU 缓存的速度介于 CPU 和内存之间，缓存的是**热点的内存数据**。\n\n如下图，根据不断增长的热点数据，这些缓存按照大小不同分为 L1、L2、L3 等三级缓存，其中 L1 和 L2 常在单核中，L3 则在多核中。从 L1 到 L3，三级缓存的大小依次增大，相应的，性能依次减少（当然内存还是好得多）。而它们的命中率，衡量的是 **CPU 缓存的复用情况**，命中率越高，则表示性能越好。\n\n![CPU 缓存](/img/2025-05-15-如何迅速分析出CPU的瓶颈/image2.png)\n\n## CPU 性能工具\n\n平均负载案例：使用 uptime 查看平均负载，在平均负载升高时，使用 mpstat 和 pidstat 分别观察每个 CPU 和每个进程 CPU 的使用情况，找到导致平均负载升高的 stress 进程\n\n上下文切换的案例：先使用 vmstat，查看系统上下文切换次数和中断次数；然后使用 pidstat（-w 参数）观察进程的自愿上下文切换和非自愿上下文切换；最后通过 vmstat（-wt参数）查看线程的上下文切换情况，从而找到了线程上下文切换增多的原因是 sysbench 工具\n\n进程 CPU 使用率升高的案例：先使用 top 找出系统和进程 CPU 的使用情况，发现了 CPU 使用率很高的进程 php-fpm，再使用 perf top 找出热点函数 sqrt()；如果是 Python 应用，可以使用 profiler 工具 pyflame 对指定进程分析（pyflame -p pid --threads -s 检测时间 -r 取样间隔 -o <file.txt>），再通过 flamegraph.pl 将输出的 txt 文件转换为 *.svg 格式的火焰图（./flamegraph.pl prof.txt > prof.svg）\n\n不可中断进程和僵尸进程的案例：\n\n- 不可中断进程分析过程：先使用 top 查看，发现存在 D 状态（不可中断休眠进程）和 Z 状态（僵尸进程），并且 iowait 较高；使用 dstat 分析磁盘 I/O，发现 app 进程有大量的磁盘读请求；使用 pidstat（-d -p 参数）分析 app 进程的 I/O 操作，发现没有大量的 I/O 操作，再用 pidstat -d 分析系统的 I/O 情况，发现还是 app 进程在进行磁盘读；再使用 strace 跟踪 D 状态进程对应进程号的系统调用，发现没有权限；ps 查看发现对应进程号的进程已经变成僵尸进程；之后，通过 perf record -g 和 perf report 生成报告，查看 app 进程的调用栈，发现 CPU 使用主要是在 sys_read() 函数，定位到是在对磁盘进行直接读（direct_IO）；查看代码发现 open() 系统调用使用了 O_DIRECT 参数\n- 僵尸进程分析：使用 pstree 命令找出僵尸进程的父进程是 app 进程，然后查看 app.c 文件，发现 wait() 使用位置不当导致不能回收子进程\n\n软中断的案例：先使用 top 查看系统指标，发现系统 CPU 使用率很低，但是主要是在软中断 si 上，然后查看 /proc/softirqs 查看系统软中断变化情况，发现 NET_RX 变化率很快，再使用 sar 工具查看系统的网络收发情况，发现 eth0 网卡接收到了大量的小包；在通过抓包工具 tcpdump，发现 eth0 接受到了大量的 SYN 包，最终确定了是 SYN FLOOD 攻击\n\n### 性能指标找工具\n\n![性能指标找工具](/img/2025-05-15-如何迅速分析出CPU的瓶颈/image3.png)\n\n### 工具找指标\n\n![工具对应指标](/img/2025-05-15-如何迅速分析出CPU的瓶颈/image4.png)\n\n## 如何分析 CPU 的性能瓶颈\n\n重点：弄清楚性能指标之间的关联性\n\n![指标关联性](/img/2025-05-15-如何迅速分析出CPU的瓶颈/image5.png)\n\n## CPU 性能优化的几个思路\n\n### 性能优化方法论\n\n确定三个问题：\n\n- 判断所做的性能优化是否有效？优化后，能提升多少性能，有多少收益？\n- 如果有多个性能问题同时存在，应该先优先哪一个？\n- 当有多个优化方法，应该选择哪一种\n\n**怎么评估性能优化结果：**\n\n三步走原则：\n\n1. 确定优化的量化指标\n2. 测试优化前的性能指标\n3. 测试优化后的性能指标\n\n第一步，性能的量化指标包括 CPU 使用率、应用的吞吐量，响应时间等等，**不要局限在单一维度的指标上**。例如，以 web 应用为例：\n\n- 应用程序的维度，使用**吞吐量和请求延时**来评估\n- 系统资源的维度，使用**CPU 使用率**来评估\n\n好的应用程序是性能优化的最终结果和目的，要使用应用程序的指标，来评估性能优化的整体效果；而系统资源的使用情况是影响应用程序的根源，需要用资源的指标，来分析应用性能的瓶颈来源。\n\n第二三步，对比第一部确定的**量化指标**在优化前后的差距，拿数据说话。例如，使用 ab 工具测试 Web 应用的并发请求数和响应延时，同时使用 vmstat，pidstat 等工具，观察系统和进程的 CPU 使用率，同时获得了应用和系统两个维度的性能指标\n\n**进行性能测试需要注意的是：**\n\n- 要避免性能测试工具干扰应用程序的性能\n- 避免外部环境的变化影响性能指标的评估。在优化前、后的应用程序，都运行在相同配置的机器上，并且它们的外部依赖也要完全一致\n\n**多个性能问题同时存在，怎么选择？**\n\n遵循**二八原则**，80% 的性能问题都是由于 20% 的代码导致的，**并不是所有的性能问题都值得优化**\n\n分析的步骤：\n\n- 挨个分析出所有的性能瓶颈，排除掉有因果关系的性能问题\n- 在剩下的几个性能问题中，选择能明显提升应用性能的问题进行修复，有两种方法：\n  - 如果系统资源出现瓶颈，首先优化系统资源使用的问题\n  - 针对不同类型的指标，首先优化导致**性能指标变化幅度最大**的那些瓶颈问题\n\n**有多种优化方法时，如何选择？**\n\n性能优化并非没有成本。\n\n一个很典型的例子网络中的 DPDK（Data Plane Development Kit）。DPDK 是一种优化网络处理速度的方法，它通过绕开内核网络协议栈的方法，提升网络的处理能力。不过它有一个很典型的要求，就是要独占一个 CPU 以及一定数量的内存大页，并且总是以 100% 的 CPU 使用率运行。所以，如果你的 CPU 核数很少，就有点得不偿失了。\n\n因此，在考虑性能优化方法时，要结合实际情况，考虑多方面的因素，进行权衡在做选择\n\n### CPU优化\n\n**常见的几种应用程序方法：**\n\n- **编译器优化**：很多编译器都会提供优化选项，适当开启它们，在编译阶段你就可以获得编译器的帮助，来提升性能。比如，gcc 就提供了优化选项 -O2，开启后会自动对应用程序的代码进行优化\n- **算法优化**：使用复杂度更低的算法，显著加快处理速度\n- **异步处理**：使用异步处理，可以避免程序因为等待某个资源而一直阻塞，从而提升程序的并发处理能力。比如，把轮询替换为事件通知，就可以避免轮询耗费 CPU 的问题\n- **多线程代替多进程**：前面讲过，相对于进程的上下文切换，线程的上下文切换并不切换进程地址空间，因此可以降低上下文切换的成本\n- **善用缓存**：经常访问的数据或者计算过程中的步骤，可以放到内存中缓存起来，这样在下次用时就能直接从内存中获取，加快程序的处理速度\n\n**常见的系统优化方法：**\n\n- **CPU 绑定**：把进程绑定到一个或者多个 CPU 上，可以提高 CPU 缓存的命中率，减少跨 CPU 调度带来的上下文切换问题\n- **CPU 独占**：跟 CPU 绑定类似，进一步将 CPU 分组，并通过 CPU 亲和性机制为其分配进程。这样，这些 CPU 就由指定的进程独占，换句话说，不允许其他进程再来使用这些 CPU\n- **优先级调整**：使用 nice 调整进程的优先级，正值调低优先级，负值调高优先级。可以适当降低非核心应用的优先级，增高核心应用的优先级，可以确保核心应用得到优先处理\n- **为进程设置资源限制**：使用 Linux cgroups 来设置进程的 CPU 使用上限，可以防止由于某个应用自身的问题，而耗尽系统资源\n- **NUMA（Non-Uniform Memory Access）优化**：支持 NUMA 的处理器会将内存划分为多个 node，每个 node 关联到系统的一个处理器。NUMA 优化，其实就是让 CPU 尽可能只访问本地内存\n- **中断负载均衡**：无论是软中断还是硬中断，它们的中断处理程序都可能会耗费大量的 CPU。开启 irqbalance 服务或者配置 smp_affinity，就可以把**中断处理过程自动负载均衡到多个 CPU 上**\n\n**避免过早优化：**\n\n性能优化最好是**逐步完善，动态进行**，不追求一步到位，而要**首先保证能满足当前的性能要求**。当发现性能不满足要求或者出现性能瓶颈时，再根据性能评估的结果，选择最重要的性能问题进行优化\n\n### 总结\n\n**要忍住“把 CPU 性能优化到极致”的冲动**，因为 CPU 并不是唯一的性能因素，还会有其他的性能问题，比如内存、网络、I/O 甚至是架构设计的问题。\n\n如果不做全方位的分析和测试，只是单纯地把某个指标提升到极致，并不一定能带来整体的收益。\n","tags":["Linux","性能测试"]},{"title":"浅谈 Python 传参机制与对象传递","url":"/2025/02/24/2025-02-24-qian-tan-python-chuan-can-ji-zhi-yu-dui-xiang-chuan-di/","content":"\nPython 的传参机制是其内存管理和函数设计的重要组成部分，尤其在处理可变和不可变对象时，可能会导致意想不到的行为。本报告将详细探讨 Python 的传参方式（按值还是按引用），并深入分析如何理解“传对象”，涵盖对象引用的概念、可变性对传参的影响，以及开发者如何在实践中管理这些行为。\n\n## 背景与问题概述\n\n在编程语言中，传参通常分为按值传递（pass by value）和按引用传递（pass by reference）。按值传递意味着函数接收的是参数的副本，修改不会影响原始变量；按引用传递意味着函数接收的是原始变量的引用，修改会影响原始变量。Python 的传参机制与这些传统概念有所不同，官方文档和社区讨论中常提到“按对象引用传递”（call by object reference）或“按赋值传递”（pass by assignment）。\n\n## Python 传参的本质：按对象引用传递\n\n根据官方文档和权威资源，Python 的传参方式是按对象引用传递。这意味着当你将参数传递给函数时，函数接收的是指向同一个对象的引用，而不是对象的副本。具体来说：\n\n- 函数的参数成为函数局部命名空间中的一个新变量，这个变量绑定到与调用者传递的对象相同的对象。\n- 这种绑定是通过赋值完成的，因此也被称为按赋值传递。\n\n为了理解这一点，我们需要回顾 Python 的对象模型：\n\n- Python 中一切都是对象，变量只是指向对象的引用（reference）。 \n- 当你执行 `x = 5`，`x` 是一个名称，绑定到整数对象 5。\n- 当你调用 `func(x)`，函数 `func` 的参数绑定到同一个对象 5。\n\n## 可变与不可变对象的影响\n\nPython 对象的可变性（mutability）对传参行为有显著影响：\n\n1. **不可变对象**（immutable objects）：如整数（int）、字符串（str）、元组（tuple）。这些对象一旦创建就不能修改。\n\t- 如果函数尝试修改不可变对象的参数（例如重新赋值），实际上是创建了一个新对象，并绑定到参数名称上，但这不会影响调用者的原始变量。\n\t- 例如：\n\t\t```python\n\t\tdef modify_num(num):\n\t\t    num = 10  # 创建新整数对象 10，绑定到 num\n\t\t\n\t\tx = 5\n\t\tmodify_num(x)\n\t\tprint(x)  # 输出 5，原始变量未变\n\t\t```\n\t- 在这种情况下，行为类似于按值传递，因为无法修改原始对象。\n2. **可变对象**（mutable objects）：如列表（list）、字典（dict）、集合（set）。这些对象可以被修改。\n\t- 如果函数修改可变对象的状态（例如追加列表元素），这些修改会反映到调用者的原始对象上，因为两者引用的是同一个对象。\n\t- 例如：\n\t\t```python\n\t\tdef modify_list(lst):\n\t\t    lst.append(4)  # 修改列表，影响原始对象\n\t\t\n\t\ty = [1, 2, 3]\n\t\tmodify_list(y)\n\t\tprint(y)  # 输出 [1, 2, 3, 4]，原始列表已改变\n\t\t```\n\t- 在这种情况下，行为类似于按引用传递，因为可以修改原始对象。\n\n然而，需要注意的是，如果函数内重新赋值参数（而不是修改对象内容），这不会影响原始变量：\n\n```python\ndef reassign_list(lst):\n    lst = [5, 6, 7]  # 重新绑定 lst 到新列表，原始对象不变\n\ny = [1, 2, 3]\nreassign_list(y)\nprint(y)  # 输出 [1, 2, 3]，原始列表未变\n```\n这表明，参数的重新赋值只影响函数内的局部命名空间，不会改变调用者的绑定。\n## 如何理解“传对象”\n\n“传对象”意味着函数接收的是对象的引用，而不是对象本身的副本。以下是关键点：\n\n- Python 中的变量是对象的引用，传递参数时，函数的参数绑定到与调用者相同的对象。\n- 函数可以通过这个引用访问对象的内容，并根据对象的可变性决定是否能修改它。\n- 如果对象是可变的，函数可以修改其状态，影响原始对象；如果对象是不可变的，函数只能创建新对象，原始对象不受影响。\n\n为了更直观地理解，可以将变量想象为指向对象的标签（label）。传递参数时，函数得到的是同一个标签的副本，但标签指向的对象是共享的：\n\n- 对于可变对象，修改对象内容相当于在同一个对象上操作，所有标签都会看到变化。\n- 对于不可变对象，试图修改会创建新对象，函数内的标签指向新对象，而原始标签仍指向旧对象。\n\n## 按值、引用、对象传递对比与总结\n\n以下表格对比了按值传递、按引用传递与 Python 传参的差异：\n\n| 机制 | 描述 | Python 示例 | 影响原始变量 |\n|--|--|--|--|\n| 按值传递（Pass by Value）| 函数接收参数的副本，修改不影响原变量 |\tnum = 10，函数内赋值新值 | 否 |\n| 按引用传递（Pass by Reference）|\t函数接收变量的引用，修改影响原变量 | C++ 中的指针或引用传递 | 是 |\n| Python 按对象引用传递\t| 函数接收对象的引用，可变对象可修改\t| 列表追加元素，字典修改键值 | 是（可变对象，修改内容）|\n\nPython 的传参机制结合了按值和按引用的特性，具体行为取决于对象的可变性。这种灵活性适合大多数场景，但需要开发者理解对象模型以避免误用。\n\n## 思考题\n\n```python\ndef bad_append(new_item, a_list=[]):\n    a_list.append(new_item)\n    return a_list\n```\n执行两次 `print bad_append('one')` 的结果是什么？\n```python\ndef bad_append(new_item, a_list=None):\n    a_list.append(new_item)\n    return a_list\n```\n执行两次 `print bad_append('one')` 的结果是什么？\n\n## 参考\n\n - [Python 函数中，参数是传值，还是传引用？](https://foofish.net/python-function-args.html)\n - [Pass by Reference in Python: Background and Best Practices](https://realpython.com/python-pass-by-reference/)\n - [8.7. Function definitions](https://docs.python.org/3/reference/compound_stmts.html#function-definitions)\n - [How do I pass a variable by reference?](https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference)\n","tags":["Python"]},{"title":"容器 overlay 文件系统简述","url":"/2024/08/28/2024-08-28-rong-qi-overlay-wen-jian-xi-tong-jian-shu/","content":"\n💡 转载自\n- https://www.zsythink.net/archives/4345\n- https://blog.csdn.net/qq_24433609/article/details/130430322\n- https://blog.csdn.net/m0_49023005/article/details/121583100\n\n## 目的\n\n有个问题困惑着我：容器删除 docker rm 后，docker cp 到容器内的文件，在 /var/lib/docker/overlay2 目录中是否还会存在\n\n答案：容器删除后 docker rm 后，会自动删除 /var/lib/docker/overlay2 中的对应文件\n\n实验步骤\n\n```bash\ndocker run --name test-container -it busybox:latest sh\n## 主机拷贝文件到容器\ndocker cp test-file.txt  test-container:/tmp\n## 去  /var/lib/docker/overlay2  查看是否有此文件\ncd  /var/lib/docker/overlay2 \nfind ./ -name test-file.txt\n## 发现在容器运行时，该文件存在与 diff 和 merged 目录\n## 容器内执行 exit 退出容器，容器会处于 exited 状态，或者 docker stop \n## 发现在容器停止或 exited 状态，此时该文件会存在于 diff 文件中\n## 删除容器后，此文件就不存在了\n\n## 因此就好奇这几个目录的意义\n## 同时发现 /var/lib/docker/overlay2  中的 hash id 与容器 id 并不对应，因此考虑就和 overlay 文件系统有关了\n```\n\n简单解释，例如下边容器的信息：\n\n```bash\n## docker inspect 0fcfdcf1b5ff |jq '.[].GraphDriver'\n{\n  \"Data\": {\n    \"LowerDir\": \"/var/lib/docker/overlay2/3cc96d59abc8c7653b124c39277c4da2830640a1a7b0939175ab3b41b1983303-init/diff:/var/lib/docker/overlay2/27ac3a1da2eea77dd8ecfcbb10dda293196408630099796c77bbf71840163759/diff:/var/lib/docker/overlay2/0ca615083cdc29e27697c00bd1ab6ce548760a3101f83bb6f697cb6c63ffcc55/diff:/var/lib/docker/overlay2/d11260c6a8a656e6c689417a2eabf2a097e65935da20b979b3f143ff5b0e7d92/diff:/var/lib/docker/overlay2/ff38b128d890e22b98851afcd608d4e70980d5e2a67a074e65fc68d40fb11f9b/diff:/var/lib/docker/overlay2/c1764658c479cfb45edac77699a4da0d2e481e6999db23854a40d54369fb132c/diff:/var/lib/docker/overlay2/b853ec37273e73902d6e9d3aa9fcc5aa4215b2ef8d56e7076d5673c699c34820/diff:/var/lib/docker/overlay2/e8d350b0980d01b145a7ce8dcf68f66d66c89d1f8b043a73e1d073896c20cdac/diff:/var/lib/docker/overlay2/2f69b30f1e7f26b4dfcaf483306b66bff6d2a9f301f49f02c0847bddc413caaa/diff:/var/lib/docker/overlay2/fbc7a7f9c03dbcd7fd507b802186a563c10d70718c019138d0f04389b9acf2bb/diff:/var/lib/docker/overlay2/1902c5596c2e232ecd2f74c1485e9742b8aa36cffb17abca756efb5020fba82c/diff:/var/lib/docker/overlay2/fdacc494a2fc86b92a1b6fdcec7074f985e0ff07b94be74baeb86399dd7187e1/diff:/var/lib/docker/overlay2/ad913d5690c729d32aef928345f8f84dc5fe9df3fb8d6b1eaf38ecb541408a82/diff:/var/lib/docker/overlay2/3f9061393985ee37edb071aac649af44bc7d19fa71861517d83000f69ba0a889/diff:/var/lib/docker/overlay2/0160cfc728093c0d737eeee1ce87ee7dbb36c27f41fa8301e6a966dee3205fe7/diff:/var/lib/docker/overlay2/d56448445573eb1d2236fd855c13a322b817ceb8482e9a64a8afa1423fbe859d/diff:/var/lib/docker/overlay2/2c8c22223361f41b06da49379023c8be1812dad70acbd0fff4b98508d813a343/diff:/var/lib/docker/overlay2/eb90ded5e398c49c6127187b68d7cf6a878f686cb4475bfd427ada9521905191/diff:/var/lib/docker/overlay2/aa4b8e69ae8ba46ddf2cbaa1db9bb63dc630471f829360f540a774533249c060/diff:/var/lib/docker/overlay2/acfea1fe0ce15416c5efac6bab4b52a27aec7205f7fa899e568e1d9dda9fc03c/diff:/var/lib/docker/overlay2/f843b96cc41cb5948dd88233fa961ad2433889bb2765c8737cd0408e999bacf9/diff:/var/lib/docker/overlay2/45f0eafde0438ec844886856ed68e07b2eb65fe8133353aa4240489d074e6e74/diff:/var/lib/docker/overlay2/3bbb18f0ad656534f45b20e6c8a3a869f3a4f177c2859e39121244737b5bd4cb/diff:/var/lib/docker/overlay2/7de504f0fd3c6aa359ec06ded02d3153405f1c4f7fac29d1b88e351d166364bc/diff:/var/lib/docker/overlay2/bb25f883772fc8502362a124574b3a741090502eaed6268e869843087f98cbe4/diff:/var/lib/docker/overlay2/b93a3576a6fa85ad54890c6163ad26b5c6fda0f403a8e8768a6c052cfad39c93/diff:/var/lib/docker/overlay2/023afc8e2f044ac2d55a804d577b4b5a9f93ff67c5e041f02dc45636ae66d949/diff:/var/lib/docker/overlay2/15573352d289785a83a1ecaa3b65168e68185125e395478e66ca4d71dc5c8e34/diff:/var/lib/docker/overlay2/5d149bcd3163486f89923e9dbc7d067909fd4c2328b3693ee9b4cd2bacb7b5d3/diff:/var/lib/docker/overlay2/9a6e123d5b2659c82fa6955cfd3e689ec0b43cedf8cce3586d11f5b9de31377d/diff:/var/lib/docker/overlay2/ab95d820e29c009efc444c6a3caff6b0cdb7c56bdd18c3fefeac35fdc2048074/diff:/var/lib/docker/overlay2/1ae1804931b744310f3410ce5dedcc3910839fb9e5b55f0483a6bd4abef51521/diff\",\n    \"MergedDir\": \"/var/lib/docker/overlay2/3cc96d59abc8c7653b124c39277c4da2830640a1a7b0939175ab3b41b1983303/merged\",\n    \"UpperDir\": \"/var/lib/docker/overlay2/3cc96d59abc8c7653b124c39277c4da2830640a1a7b0939175ab3b41b1983303/diff\",\n    \"WorkDir\": \"/var/lib/docker/overlay2/3cc96d59abc8c7653b124c39277c4da2830640a1a7b0939175ab3b41b1983303/work\"\n  },\n  \"Name\": \"overlay2\"\n}\n```\n\n在 Docker  中，一个很重要的概念就是 GraphDriver，它主要用于管理和维护镜像，包括把镜像从仓库下载下来，到运行时把镜像挂载起来可以被容器访问等，都是 GraphDriver 去完成的。\n\n- \"Name\": \"overlay2\"：docker存储驱动是overlay2\n- LowerDir：包含容器内所有层的文件系统，最后一层除外\n    - 基础镜像，可以看到有很多 init，这是对应 From 的基础镜像（所有只读层）\n- UpperDir：容器最上层的文件系统。这也是反映任何运行时修改的地方\n    - 容器读写层\n- MergedDir：文件系统所有层的组合视图\n    - 联合挂载层 ：将 基础层和容器读写层  挂载在一起 ，展示一个统一的视图\n- WorkDir：用于管理文件系统的内部工作目录\n\n![GraphDriver 示意图](/img/2024-08-28-了解容器overlay文件系统/Untitled.png)\n\n## 实例\n\n通过上述实验，我们已经对 overlay2 有了一定认识了，现在，我们来看看 overlay2 是怎样和 docker 中的镜像层以及容器层结合在一起的。\n\n当我们通过 docker pull 命令拉去第一个镜像时，可以看到镜像每一层被拉取的过程，例如\n\n```bash\n[root@pudding-160 ~]## docker pull 172.16.1.99/hippo/runtime/x86/faiss_benchmark:20240712_68ba1e1\n20240712_68ba1e1: Pulling from hippo/runtime/x86/faiss_benchmark\n648c0ccfae96: Pull complete\nd77e7370c4fa: Pull complete\n00701f0aa522: Pull complete\nd4516580db57: Pull complete\nfca65a19a3bf: Pull complete\nDigest: sha256:e9b215174cd7a01eafd1913d2bd1c59aafd797649de906dea53eda3582dfdc6b\nStatus: Downloaded newer image for 172.16.1.99/hippo/runtime/x86/faiss_benchmark:20240712_68ba1e1\n```\n\n如上所见，此处拉取的 `faiss_benchmark:20240712_68ba1e1` 镜像一共有 5 层，每一层拉取完毕后，都会显示 Pull complete（Already exists 则表示本地目录已经有该层的文件）；每一层都有一个 ID 号，比如上列中的 648c0ccfae96 就是层的哈希值前 12 位。\n\n下载镜像后，我们可以通过 docker inspect 命令查看镜像的详细信息，在镜像的详细信息中找到 RootFS 段，可以查看当前镜像包含的层，如下：\n\n```bash\n[root@pudding-160 ~]## docker inspect 172.16.1.99/hippo/runtime/x86/faiss_benchmark:20240712_68ba1e1 | jq '.[].RootFS'\n{\n  \"Type\": \"layers\",\n  \"Layers\": [\n    \"sha256:4f118a86fef9debde65113068bd2b85f9c5fd65250ac6af2e8281a502cc0a724\",\n    \"sha256:004114a8d0e34895acdd9c1c370b1184b239d538e3951887d04d1bda771bd441\",\n    \"sha256:0d5cae34765c1f89a17e5e8e7e6f6f9ddc541151e3efab2487b013faeecac3a6\",\n    \"sha256:fbc981c1f97f7139dd25bc0924272ae4f8f9e07d8c57a1ca4b0c9344266a93ff\",\n    \"sha256:457b93dcc46ca598ce9378e015aae678218bb9a699c4e373250e4021b60c0566\"\n  ]\n}\n```\n\n如上所示，faiss_benchmark 镜像的 RootFS 段中一共有 5 层，这 5 个层就是刚才 docker pull 拉取下来的层，RootFS 中的每个层也是用一个哈希值表示，RootFS 中的层的哈希值的前 12 位和刚才 docker pull 命令中的 ID 根本对应不上，这是因为 dcoker pull 中显示的 ID 是层在压缩状态下计算出的哈希值，当层被下载到本地，会自动解压，而 RootFS 中的层哈希值不是在压缩状态下计算的，显然它们两个的值不会一样。如果想要确定它们之间的对应关系，可以通过 `diffid-by-digest或者v2metadata-by-diffid/sha256/`目录中的文件来查看它们之间的对应关系\n\n```bash\n[root@pudding-160 distribution]## pwd\n/var/lib/docker/image/overlay2/distribution\n[root@pudding-160 distribution]## tree -L 2\n.\n├── diffid-by-digest\n│   └── sha256\n└── v2metadata-by-diffid\n    └── sha256\n\n4 directories, 0 files\n```\n\n- `diffid-by-digest/sha256`：\n    - 这个目录存储了按镜像层的 Digest (SHA256) 计算的映射到 DiffID 的信息。\n    - Digest 是一个唯一标识符，用于识别镜像层的内容。\n    - DiffID 是镜像层的一个变化 ID，表示这一层和它下面一层之间的差异。\n    - 这个映射文件可以帮助 Docker 快速查找特定层的变化信息。\n- `v2metadata-by-diffid/sha256`：\n    - 这个目录存储了按 DiffID (SHA256) 计算的映射到 v2 元数据的文件。\n    - 这些元数据包括关于镜像层的各种信息，如创建时间、大小、标签等。\n    - 这个目录有助于 Docker 管理和检索与特定层相关的元数据。\n\n例如 289ce7e41289 的对应关系：\n\n```bash\n[root@pudding-160 sha256]## find . -name \"648c0ccfae96*\"\n./648c0ccfae963a8b0d71c267d8cb5bb4fc6f26f5e9bd05ab7a6f82db8e95332e\n[root@pudding-160 sha256]## cat ./648c0ccfae963a8b0d71c267d8cb5bb4fc6f26f5e9bd05ab7a6f82db8e95332e\nsha256:4f118a86fef9debde65113068bd2b85f9c5fd65250ac6af2e8281a502cc0a724\n\n这是我们可以看到 docker pull 中的 648c0ccfae96 和 docker insepct 中的 648c0ccfae96 联系了起来\n```\n\n在 RootFS 所显示的层中，第一层是最底层，最后一行是最上层，RootFS 显示的层顺序和在镜像中的实际顺序是相反的，在上例中 4f118a86fef9d 是镜像最底层，457b93dcc46 是镜像的最上层。\n\n既然这些层已经下载到本地，那么这些层对应的文件到底存放到那里呢？我们可以通过如下命令，可以查看这些层的实际存放位置。\n\n```bash\n[root@pudding-160 sha256]## docker inspect 172.16.1.99/hippo/runtime/x86/faiss_benchmark:20240712_68ba1e1 -f '{{.GraphDriver.Data}}' | awk -v RS=' ' '{print}' | nl | sort -nr | cut -f2 | awk -v RS=':' '{print}' | grep diff\n/var/lib/docker/overlay2/43722a4a12628179c70d588fcc7f64b86aa92cbd30c8599035d0433059423dcf/diff\n/var/lib/docker/overlay2/0fed41f6f307ef92b1b1d475108575f0130d224eb008dfa3ff4383c8fa506de6/diff\n/var/lib/docker/overlay2/cd5c2d405030b7ed966d1b78c3b038c1c6b313b8be7d0033835bf9ae20c34c37/diff\n/var/lib/docker/overlay2/784dc7dce7d8625dc10a4fa065f2a1f27ff65e19def543c9f491f32575ec09dd/diff\n/var/lib/docker/overlay2/0fee07bf5795a78e666b18059a4f64eb84d184d07eb6a5d1118ed487338e9edf/diff\n```\n\n如上所示，这些层实际存放在 `/var/lib/docker/overlay2/层哈希值/diff`目录中，很明显，上述命令查询出的路径中的层哈希值和之前`docker pull`或者`RootFS`中显示的哈希值都不一样，上述路径中的哈希值是根据一定的规律，层层递进计算出来的，如果对这些哈希值之间的关系和计算方法感兴趣，可以去搜索“docker layerID diffID chainID cacheID”这些关键字，这并不是此处要关注的重点，所以不用纠结这些细节，我们只要知道，这些查出来路径就是镜像层实际的存放路径即可。\n\n由于上述命令已经完成了排序，所以我们看到的层的顺序就是对应层在镜像中的位置，也就是说，上例中查询出来的 43722a4a12628 是最上层，对应 RootFS 中的 457b93dcc46 ，上例中的 0fee07bf5795a7 是最下层，对应 RootFS 中的 4f118a86fef9d ，总之，镜像的层对应的文件实际存放在 diff 目录中。\n\n其实聊了半天，无非都是在说镜像的层而已，现在咱们基于镜像，创建一个容器，看看容器层是怎么和镜像层结合的。\n\n此处基于 faiss_benchmark 镜像创建一个 faiss-demo1 容器：\n\n```bash\ndocker run --name faiss-demo1 -dit 172.16.1.99/hippo/runtime/x86/faiss_benchmark:20240712_68ba1e1 bash\n```\n\n使用 docker inspect 命令查看容器的详细信息，在详细信息的 GraphDriver 段可以看到容器的层信息：\n\n```bash\n[root@pudding-160 ~]## docker inspect faiss-demo1 | jq '.[].GraphDriver'\n{\n  \"Data\": {\n    \"LowerDir\": \"/var/lib/docker/overlay2/c156d03c1532a2efce8670b7d665e0d4840e1b798c47998b8f746c3aaf8d82b4-init/diff:/var/lib/docker/overlay2/0fee07bf5795a78e666b18059a4f64eb84d184d07eb6a5d1118ed487338e9edf/diff:/var/lib/docker/overlay2/43722a4a12628179c70d588fcc7f64b86aa92cbd30c8599035d0433059423dcf/diff:/var/lib/docker/overlay2/0fed41f6f307ef92b1b1d475108575f0130d224eb008dfa3ff4383c8fa506de6/diff:/var/lib/docker/overlay2/cd5c2d405030b7ed966d1b78c3b038c1c6b313b8be7d0033835bf9ae20c34c37/diff:/var/lib/docker/overlay2/784dc7dce7d8625dc10a4fa065f2a1f27ff65e19def543c9f491f32575ec09dd/diff\",\n    \"MergedDir\": \"/var/lib/docker/overlay2/c156d03c1532a2efce8670b7d665e0d4840e1b798c47998b8f746c3aaf8d82b4/merged\",\n    \"UpperDir\": \"/var/lib/docker/overlay2/c156d03c1532a2efce8670b7d665e0d4840e1b798c47998b8f746c3aaf8d82b4/diff\",\n    \"WorkDir\": \"/var/lib/docker/overlay2/c156d03c1532a2efce8670b7d665e0d4840e1b798c47998b8f746c3aaf8d82b4/work\"\n  },\n  \"Name\": \"overlay2\"\n}\n```\n\n仔细观察上列的返回信息，你会发现，faiss-demo1 容器其实就是使用了 overlay2 文件系统，将 faiss_benchmark 镜像各个层的 diff 目录作为 LowerDir 只读层（在这个基础上添加了一层 init 只读层，之后再聊它），将容器的 diff 目录（c156d03c1532 文件夹中的 diff 目录）作为 UpperDir 可读写层，叠加后呈现在了 MergedDir 层（MergedDir 是 c156d03c1532 文件夹中的 merged 目录），而我们在容器中看到的、操作的文件，其实就是 MergedDir 中的内容。\n\n我们从宿主机的挂载信息中，也可以侧面验证这一点，在容器启动的情况下，执行如下命令，查看对应的 overlay2挂载点信息：\n\n```bash\n[root@pudding-160 ~]## mount | grep overlay | grep c156d03c1532\noverlay on /var/lib/docker/overlay2/c156d03c1532a2efce8670b7d665e0d4840e1b798c47998b8f746c3aaf8d82b4/merged type overlay (rw,relatime,lowerdir=/var/lib/docker/overlay2/l/62APW7R2QAZIKL2JBXGDL2SZFX:/var/lib/docker/overlay2/l/VHFAUXFFYMW7NZ5S3SKLFYMS6R:/var/lib/docker/overlay2/l/FUWWJ73CD3TWQY4ESCXJSQD3Y7:/var/lib/docker/overlay2/l/V2E4YYCC3PEBB4VYHJ3P2E7JMA:/var/lib/docker/overlay2/l/5FRUEQSAL6URPMBZ4V5VHEOJDR:/var/lib/docker/overlay2/l/54MNMNIOUGOPX7SLOTKFTZHE5R,upperdir=/var/lib/docker/overlay2/c156d03c1532a2efce8670b7d665e0d4840e1b798c47998b8f746c3aaf8d82b4/diff,workdir=/var/lib/docker/overlay2/c156d03c1532a2efce8670b7d665e0d4840e1b798c47998b8f746c3aaf8d82b4/work)\n\n#上述挂载点中的有很多/var/lib/docker/overlay2/l/下的路径，查看这些路径，会发现这些路径都是软链接，软连接指向的路径就是那些diff目录\n[root@pudding-160 ~]## ll /var/lib/docker/overlay2/l/62APW7R2QAZIKL2JBXGDL2SZFX\nlrwxrwxrwx 1 root root 77 Jul 29 15:47 /var/lib/docker/overlay2/l/62APW7R2QAZIKL2JBXGDL2SZFX -> ../c156d03c1532a2efce8670b7d665e0d4840e1b798c47998b8f746c3aaf8d82b4-init/diff\n[root@pudding-160 ~]#\n[root@pudding-160 ~]## ll /var/lib/docker/overlay2/l/VHFAUXFFYMW7NZ5S3SKLFYMS6R\nlrwxrwxrwx 1 root root 72 Jul 29 15:38 /var/lib/docker/overlay2/l/VHFAUXFFYMW7NZ5S3SKLFYMS6R -> ../0fee07bf5795a78e666b18059a4f64eb84d184d07eb6a5d1118ed487338e9edf/diff\n```\n\n看到这里，我们应该能够完全理解镜像层、容器层、overlay2 文件系统时怎么融合在一起的了。首先，镜像下载到本地后，各个镜像层的文件存放在对应的 diff 目录中，当我们基于镜像创建容器时，docekr 引擎会为容器创建对应的各个目录，比如 diff、work、merged 目录，然后把镜像层的 diff 目录作为 overlay 中的 lowerDir，将容器的 diff 目录作为 overlay 中 upperDir，将折叠后的结果挂载到了 merge 目录中，最后，docekr 通过 `mount namespace` 技术，将 merged 目录隔离挂载到容器中。\n\n现在，再看下图是不是一目了然了\n\n![镜像层、容器层之间的关系](/img/2024-08-28-了解容器overlay文件系统/Untitled1.png)\n\n你可以做一些实验，比如，在容器中创建一些文件，修改一些文件，看看容器的 diff 目录中的变化情况，因为容器的 diff 目录就是读写层，当在容器中进行写操作时，最直接的变化会体现到容器的 diff 目录中，但是，你可能会遇到一些“意外情况”，比如，你在容器中修改了/etc/hosts 文件，发现容器的 diff 目录中并没有对应的 /etc/hosts 文件出现，这是因为有一个特殊的层存在，这个层就是我们刚才看到的”-init层”。当我们创建一个容器时，docker 会为容器进行一些初始化工作，其中就包括生成 hosts 信息、生成 hostname 等，你会发现，即使你在容器中修改了 /etc/host 文件，重启容器后，hosts 文件也会变成原来的样子（通过其他方法可以永久修改），因为 /etc/hosts、/etc/hostname、/etc/resolv.conf 文件中的信息都是 docker 生成的，docker 认为这些信息应该是针对容器当前的状态而存在的，以 hosts 文件为例来说，如果容器没有固定的 IP 地址，那么重启容器后，容器的 IP 可能会发生变化，所以每次重启容器时 docker 都会重新生成 hosts 内容，避免之前生成的 hosts 与当前状态所需要的 hosts 不符，当我们在容器中修改  /etc/hosts 文件时，会发现宿主机中的`/var/lib/docker/containers/容器ID/`目录下的 hosts 文件内容也发生了同样的变化，其实，docker 就是将宿主机中的`/var/lib/docker/containers/容器ID/hosts`文件挂载到了容器中的，既然这些状态应该属于容器，那么当我们基于容器创建镜像时，就不应该把容器中的这些信息带入到新创建的镜像中，当我们使用`docker commit`命令基于容器创建镜像时，会把容器的可读写层变成新创建出的镜像的最上层，所以，如果容器的可读写层中包含 hosts 文件，新镜像中就会带入容器的 hosts 信息，而容器因为 init 层和挂载操作的存在，避免了这些信息进入到容器的可读写层，所以可以保障我们基于容器创建镜像时，得到的镜像是“纯净”的。\n\n## 前言\n\n### rootfs\n\n在讲 overlay2 之前，我们需要先简单了解一下什么是 rootfs：\n\nrootfs 也叫 **根文件系统**，是 Linux 使用的最基本的文件系统，是内核启动时挂载的第一个文件系统，提供了根目录 `/` ，根文件系统的各个目录，例如 /bin、/etc、/mnt 等，再将其他分区挂载到 /mnt，/mnt 目录下就有了这个分区的各个目录和文件。\n\ndocker 容器中使用的同样也是 rootfs 这种文件系统，当我们通过 `dockr exec` 命令进入到容器内部时也可以看到在根目录下有 /bin、/etc、/tmp 等目录，但是在 docker 容器中与 Linux 不同的是，在挂载 rootfs 后，docker deamon 会利用**联合挂载技术**在已有的 rootfs 上再挂载一个读写层，容器在运行过程中文件系统发生的变化只会在读写层进行修改，并通过 whiteout 文件隐藏只读层中的旧版本文件。\n\n> whiteout 文件：\nwhiteout 概念存在于联合文件系统（UnionFS）中，代表某一类占位符形态的特殊文件，当用户文件夹的共通部分联合到一个目录时（例如 bin）目录，用户可以删除归属于自己的某些系统文件副本，但归属于系统级的原件仍存留于同一个联合目录，此时系统将产生一份 whiteout 文件，表示该文件在当前用户目录中已删除，但系统目录中仍然保留。\n> \n\n### 联合挂载文件\n\n所谓联合挂载文件（Union Mount），就是将原有的文件系统中的不同目录进行**合并（merge）**，最后向我们呈现出一个合并后文件系统。在 overlay2 文件结构中，联合挂载技术通过联合三个不同的目录来实现：lower 目录、upper 目录和 work 目录，这三个目录联合挂载后得到 merged 目录：\n\n- lower 目录：**只读层**，可以有多个，处于最底层目录\n- upper 目录：**读写层**，只有一个\n- work 目录：工作基础目录，挂载后内容被清空，且在使用过程中其内容不可见\n- merged 目录：联合挂载后得到的**视图**，其中本身并没有实体文件，实际文件都在 upper 目录和 lower 目录中。在 merged 目录中对文件进行编辑，实际会修改 upper 目录中文件；而在 upper 目录与 lower 目录中修改文件，都会影响我们在 merged 目录看到的结果。\n\n## **overlayFS**\n\n在介绍 docker 中使用的 overlay2 文件结构前，我们先通过对 overlay 文件系统进行简单的操作演示以便更深入理解不同层不同目录之间的关系\n\n先创建几个文件夹和文件\n\n```bash\npudding@DESKTOP-1QCHCU4:~$ mkdir A B C worker\npudding@DESKTOP-1QCHCU4:~$ sudo echo \"From A\" >> A/b.txt\npudding@DESKTOP-1QCHCU4:~$ sudo echo \"From A\" >> A/c.txt\npudding@DESKTOP-1QCHCU4:~$ sudo echo \"From B\" >> B/a.txt\npudding@DESKTOP-1QCHCU4:~$ sudo echo \"From B\" >> B/d.txt\npudding@DESKTOP-1QCHCU4:~$ sudo echo \"From C\" >> C/b.txt\npudding@DESKTOP-1QCHCU4:~$ sudo echo \"From C\" >> C/e.txt\npudding@DESKTOP-1QCHCU4:~$ tree\n```\n\n![目录 tree](/img/2024-08-28-了解容器overlay文件系统/image.png)\n\n使用 mount 命令挂载成 overlayFS 文件系统，格式如下\n\n```bash\nmount -t overlay overlay -o lowerdir=lower1:lower2:lower3,upperdir=upper,workdir=work merged_dir\n```\n\n在这个例子中，我们用 A 和 B 两个文件夹作为 lower 目录，用 C 作为 upper 目录，worker 作为 work 目录，挂载到 /home/pudding/merged 目录下\n\n```bash\nmkdir merged\nsudo mount -t overlay overlay -o lowerdir=A:B,upperdir=C,workdir=worker /home/pudding/merged\n```\n\n挂载后我们可以查看一下 merged 目录下的文件\n\n![merged tree](/img/2024-08-28-了解容器overlay文件系统/image1.png)\n\n可以看到我们原本的 A B C 三个目录下的文件已经合并，相同的文件名的文件将会选择性的显示，在 merged 中显示里 merged 层更近的文件，upper 层比 lower 层更近，同样 lower 层中，排序靠前的比排序靠后的更近（取决于mount 脚本中 lowerdir=A:B ），在这个例子中就是 A 比 B 更靠近 merged 层\n\n根据这个规律，我们可以先分析下 merge 层中的文件来源，a.txt 在 A、B 中都有，但是 A 比 B 更靠近 merged 层，所以 merged 层的 a.txt 应该来自 A 目录，b.txt 在 A 和 C 中都有，但是 C 是 upper 层，所以 b.txt 应该来自 C 目录，我们可以核实一下\n\n![cat files](/img/2024-08-28-了解容器overlay文件系统/image2.png)\n\n接下来我们可以看下 upper 层、lower 曾和 merged 层之间的关系，上文已经提到了 upper 层是**读写层**而 lower 层是**只读层**，merged 层是联合挂载后的视图，那如果我们在 merged 层中对文件进行操作会生什么\n\n![change merged file](/img/2024-08-28-了解容器overlay文件系统/image3.png)\n\n我们修改 merge 层的 a.txt 文件，可以看到 merged 层的 a.txt 内容虽然改变，但是 A 目录（只读层）下的 a.txt 内容并没有发生变化，而在 C 目录（读写层）下多了一个 a.txt 文件，内容就是我们修改过的 a.txt 的内容，这就是只读层和读写层的关系，**在 merged 目录对文件进行修改并不会影响到只读层的源文件，只会对读写层进行编辑**。\n\n如果我们在 merged 层删除文件会发生什么\n\n![delete file](/img/2024-08-28-了解容器overlay文件系统/image4.png)\n\n可以看到在 merged 目录中已经没有 c.txt 文件了，但是 c 目录下却多了一个 c.txt，这个文件就是我们在一开始提到的 **whiteout 文件**，它是主/次设备号都为 0 的字符设备，overlay 文件结构通过使用这种特殊文件来实现文件删除功能，在 merged 目录下使用 ls 命令查看文件时，overlay 会自动过滤掉 upper 目录下的 whiteout 文件以及在 lower 目录下的同名文件，以此实现文件删除效果\n\n还有一个值得提到的点：overlay 在文件进行操作时用到了**写时复制（Copy on Write）技术**，在没有对文件进行修改时，merged 目录直接使用 lower 目录下的文件，只有当我们在 merged 目录对文件进行修改时，才会把修改的文件复制到 upper 目录\n\n## **Docker overlay2**\n\n有了对 overlayFS 的基本了解，我们接下来就可以着手分析 Docker 的 overlay2 文件结构了，实际上 Docker 支持的存储驱动有很多种：overlay、overlay2、aufs、vfs 等，在 Ubuntu 较新版本中的 Docker 中普遍采用了 overlay2 这种文件结构，其具有更优越的驱动性能，而 overlay 和 overlay2 的本质区别就是二者在镜像层之间的共享数据方法不同：\n\n- overlay 通过 硬链接 的方式共享数据，只支持，增加磁盘 inode 负担\n- overlay2 通过 将多层的 lower 文件联合在一起\n\n简而言之，overlay2 就是 overlay 的改进版本，我们可以通过 docker info 命令查看\n\n```bash\npudding@DESKTOP-1QCHCU4:~$ sudo docker info | grep -i \"storage driver\"\n Storage Driver: overlay2\n```\n\n在 Docker 中，我们日常操作主要涉及两个方面：镜像层与容器层，镜像层就是我们通过 **docker pull** 等命令下载到本机中的镜像，而容器层则是我们通过 **docker exec** 等命令进入的交互式终端，如果你使用过 Docker，你会发现我们只用一个镜像，通过 **docker run** 可以产生很多个容器，这就可以类比 upper 与 lower 两层，镜像作为 lower 层，只读提供文件系统基础，而容器作为 upper 层，我们可以在其中进行任意文件操作，只用同一个镜像就可以申引出不同的容器，这也是一种节约空间资源的方式吧（我的推测\n\n接下来我们稍微详细地探讨下镜像层与容器层，还有他们的元数据\n\n### 镜像层\n\n我们可以通过 `docker inspect [IMAGE ID]` 来查看镜像配置\n\n![image GraphDriver](/img/2024-08-28-了解容器overlay文件系统/image5.png)\n\n其中的 GraphDriver 字段中关于 overlay2 文件结构的目录信息\n\n每一层的对应都在配置信息中体现的非常清楚，但是有一点问题，我们在实际查看文件夹的时候，可以发现镜像层其实并没有 /merged 目录，**我的理解** /merged 目录只在运行容器时存在；这个目录是 Docker 为容器提供的一个视图，它将 lowerdir 和 upperdir 层合并为一个统一的文件系统供容器访问；虽然 merged 目录不存在于镜像层，但 Docker 在 GraphDriver 字段中提供了这些信息，以确保我们能够理解整个 overlay2 文件系统的结构。（不一定对\n\n可以看到镜像的目录是在 `/var/lib/docker/overlay2` 下，我们打开一个镜像层看一看其中都有哪些文件\n\n![image overlay2](/img/2024-08-28-了解容器overlay文件系统/image6.png)\n\n其中我们关注一下 diff 目录、link 和 lower 文件\n\n#### diff 目录\n\n**在这个目录中存放的是当前镜像层的文件，**刚刚在介绍 overlay2 与 overlay 区别的时候提到了 overlay2 是将多个 lower 层联合到一起，在上面的图中也可以看到，多个 lower 层之间用`:`分割，在这些层中每一层都有一部分文件，把他们联合到一起就得到了完整的 rootfs\n\n![image diff](/img/2024-08-28-了解容器overlay文件系统/image7.png)\n\n#### link 文件\n\nlink 文件中的内容是**当前层的软链接名称**\n\n![image link](/img/2024-08-28-了解容器overlay文件系统/image8.png)\n\n这些链接都在 `/var/lib/docker/overlay2/l` 目录下\n\n![image link](/img/2024-08-28-了解容器overlay文件系统/image9.png)\n\n使用软链接的目的是**为了避免受到 mount 命令参数的长度限制**\n\n> `getconf ARG_MAX`\n该值决定了一个进程的命令行参数和环境变量的总长度\n通常在 Linux 系统上为 2MB（2097152 字节）\n> \n\n#### lower 文件\n\nlower 文件中的内容是**在此层之下的所有层的软连接名称**，最底层不存在该文件，我们知道 upper 层在 lower 层之上，而 lower 层中越靠后的则越在底层\n\n我们查看 upper 层对应目录下 lower 文件，可以看到其中有 4 个软链接\n\n![image lower](/img/2024-08-28-了解容器overlay文件系统/image10.png)\n\n恰好 lower 目录中有 4 个镜像层\n\n![image GraphDriver lower](/img/2024-08-28-了解容器overlay文件系统/image11.png)\n\n在 lower 层中，处于最底层的则是应该在 `:` 最后的目录，即，\n\n```bash\n/var/lib/docker/overlay2/784dc7dce7d8625dc10a4fa065f2a1f27ff65e19def543c9f491f32575ec09dd\n```\n\n查看这一目录下的文件，可以发现它并没有 lower 文件\n\n![image lowest](/img/2024-08-28-了解容器overlay文件系统/image12.png)\n\n这一层对应的软链接即 link 文件内容为 `54MNMNIOUGOPX7SLOTKFTZHE5R`，我们查看其上一层的 lower 文件内容\n\n![image one floor up](/img/2024-08-28-了解容器overlay文件系统/image13.png)\n\n可以发现确实对应了最底层目录的软链接\n\n### 元数据\n\nDocker 的元数据存储目录为 `/var/lib/docker/image/overlay2` \n\n![image overlay2](/img/2024-08-28-了解容器overlay文件系统/image14.png)\n\n我们主要看 imagedb 和 layerdb 这两个文件夹\n\n#### imagedb\n\n这个文件夹中存储了镜像相关的元数据，具体位置是在 `/imagedb/content/sha256`  目录下，这个目录下的文件以 **IMAGE ID** 来命令\n\n![image imagedb](/img/2024-08-28-了解容器overlay文件系统/image15.png)\n\n这个文件的内容就是我们通过 `docker inspect [IMAGE ID]` 命令查看到的信息，其中我们关注 `RootFS` 字段\n\n![image RootFS](/img/2024-08-28-了解容器overlay文件系统/Untitled2.png)\n\n可以看出这个字段中有很多 sha256 值，这些哈希值称为 **diff_id**，其从上至下的顺序就表示镜像层最底层到最顶层，也就是说每个 diff_id 对应了一个镜像层，实际上，对应每一个镜像层的还有另外两个 id：**cache_id** 和 **chain_id**\n\n- **cache_id** 就是在 `docker/overlay2` 目录下看到的文件夹名称，也是我们通过 `docker inspect [IMAGE ID]` 命令查看 GraphDriver 字段对应不同的 Dir，其本质是宿主机随机生成的 uuid\n    \n    ![image cache_id](/img/2024-08-28-了解容器overlay文件系统/image16.png)\n    \n- chain_id 是通过 diff_id 计算出来的，是 Docker 内容寻址机制采用的索引 ID\n    - chain_id 在目录 `/var/lib/docker/image/overlay2/layerdb/sha256` 查看\n    - 如果当前镜像层为最底层，则其 chain_id 与 diff_id 相同\n    - 如果当前镜像层不是最底层，则其 chain_id 计算方式为：`sha256(上层chain_id + \" \" + 本层diff_id)`\n\n这三个 id 之间存在一一对应的关系，我们可以通过 diff_id 计算得到 chain_id，又可以通过 chain_id 找到对应的 cache_id，下面我们举个栗子说明一下：\n\n我们刚刚提到了 diff_id 从上至下是最底层到最顶层\n\n![image RootFS](/img/2024-08-28-了解容器overlay文件系统/image17.png)\n\n查看 chain_id\n\n![image chain_id](/img/2024-08-28-了解容器overlay文件系统/image18.png)\n\n可以看到其中确实有一个 chain_id 与 最底层的 diff_id 相同，有了最底层的 chain_id 我们就可以计算出下一层的 chain_id，至于具体如何计算，以及如何通过 chain_id 找到对应的 cache_id，我们需要先了解 layerdb 目录下的内容\n\n#### layerdb\n\n我们现在已知 Docker 的镜像层作为只读层，容器曾作为读写层，而 Docekr 实际上定义了 roLayer 接口与 mountLayer 接口，分别用来描述（只读）镜像层与（读写）容器层，这两个接口的元数据就在目录 `/var/lib/docker/image/overlay2/layerdb` 下\n\n- **roLayer**\n    \n    rolayer 接口用来描述镜像层，元数据的具体目录在 `layerdb/sha256/` 下，在此目录下每个文件夹都以每个镜像层的 chain_id 命名\n    \n    ![image roLayer](/img/2024-08-28-了解容器overlay文件系统/image19.png)\n    \n    在文件夹中主要有这 5 个文件，我们简单介绍一下：\n    \n    - cache-id：当前 chain_id 对应的 cache_id，用来索引镜像层\n    - diff：当前 chain_id 对应的 diff_id\n    - parent：当前 chain_id 对应的镜像层的下一层（父层）镜像 chain_id，最底层不存在该文件\n    - size：当前 chain_id 对应的镜像层物理大小，单位是字节\n    - tar-split.json.gz：当前 chain_id 对应镜像层压缩包的 split 文件，可以用来还原镜像层的 tar 包，通过 `docker save` 命令导出镜像时会用到\n    \n    我们在上一节中已经判断出了最底层对应的 chain_id，不妨查看一下对应目录下的文件\n    \n    ![image lowest chain_id](/img/2024-08-28-了解容器overlay文件系统/image20.png)\n    \n    可以看到该目录下确实没有 parent 文件，那么我们再查看其下一层，通过 diff_id 的顺序我们可以得知其下一层的 diff_id 为 `0d5cae34765c1f89a17e5e8e7e6f6f9ddc541151e3efab2487b013faeecac3a6` （上文提到的 inspect 的 RootFS 里 Layers 的 sha256 信息），通过计算 sha256，我们可以得出下一层的 chain_id\n    \n    ![image one floor up chain_id](/img/2024-08-28-了解容器overlay文件系统/image21.png)\n    \n    计算得到最底层的下一层镜像 chain_id 为 `696245322de78f67f7f15ab9ade64bf0c35cf1f280a66d763230d9e99a3a6d39`\n    \n    ![image diff](/img/2024-08-28-了解容器overlay文件系统/image22.png)\n    \n    确实存在该目录，可以看到：\n    \n    - diff 文件内容是 `004114a8d0e34895acdd9c1c370b1184b239d538e3951887d04d1bda771bd441`\n    - parent 文件内容是 `4f118a86fef9debde65113068bd2b85f9c5fd65250ac6af2e8281a502cc0a724`\n    \n    可以看到与我们计算用到的两个值也完全相同\n    \n- **mountLayer**\n    \n    mountLayer 接口用来描述容器层，元数据的具体目录在 `layerdb/mounts/` ，在此目录下的文件夹以每个容器的容器 ID（CONTAINER ID）命名\n    \n    ![image contain](/img/2024-08-28-了解容器overlay文件系统/image23.png)\n    \n    在这个文件夹下只有 3 个文件，内容如下：\n    \n    ![image mountLayer](/img/2024-08-28-了解容器overlay文件系统/image24.png)\n    \n    简单介绍一下这3个文件：\n    \n    - init-id：对应容器 init 层目录名，源文件在 `/var/lib/docker/overlay2` 目录下\n    - mount-id：容器层存储在 `/var/lib/docker/overlay2` 目录下的名称\n    - parent：容器的镜像层**最顶层**镜像的 chain_id\n    \n    我们可以查看 parent 文件中 chain_id 对应目录下的 diff 文件\n    \n    ![image diff](/img/2024-08-28-了解容器overlay文件系统/image25.png)\n    \n    根据 diff_id 从上至下的顺序，我们可以确定这个 diff_id 的确是镜像层的最顶层\n    \n    ![image rootfs](/img/2024-08-28-了解容器overlay文件系统/image26.png)\n    \n    在这里我们引入了一个叫做 **init 层** 的概念，实际上，一个完善的容器分为 3 层：镜像层、init 层和容器层，镜像层提供完整的文件系统基础（rootfs），容器层提供给用户进行交互操作与读写权限，而 init 层则是对应每个容器自己的一些系统配置文件，我们可以看一下 ini 层的内容\n    \n    ![image init](/img/2024-08-28-了解容器overlay文件系统/image27.png)\n    \n    可以看到在 diff 目录中有一些 /etc/hosts、/etc/resolv.conf 等配置文件，需要这一层的原因是当容器启动的时候，会有一些每个容器特定的配置文件（例如 hostname），但由于镜像层是只读层无法进行修改，所以就在镜像层之上单独挂载一层 init 层，用户通过修改每个容器对应的 init 层中的一些配置文件从而达到修改镜像配置文件的目的，而在 init 层中的配置文件也仅对当前容器生效，通过 docker commit 命令创建镜像时也不会提交 init 层。\n    \n\n### 容器层\n\n最后我们来看一下容器层的构造，刚刚我们在 **mountLayer** 一节的讲述中提到了 **mount-id** 这个文件，而这个文件的内容就是容器目录的名称，我们可以通过 `docker inspect [CONTAINER ID]` 命令也可以判断\n\n![image mount-id](/img/2024-08-28-了解容器overlay文件系统/image28.png)\n\n![image graphdriver](/img/2024-08-28-了解容器overlay文件系统/image29.png)\n\n可以看到其实容器层的目录与镜像层、init层都在同一目录下，其实也就说明了他们在文件结构上都是相同的\n\n![image overlay2](/img/2024-08-28-了解容器overlay文件系统/image30.png)\n\n同样都是这几个文件，但不同的是，我们可以看到在容器层确实有了 merge 这个目录，与我们在文章一开始实现的 overlayFS 是相同的\n\n![image merged](/img/2024-08-28-了解容器overlay文件系统/image31.png)\n\n在 merge 目录下展现了完整的 rootfs 文件系统，这就是 overlay2 通过联合挂载技术，将镜像层、init 层与容器层挂载到一起呈现的结果，这也是我们通过 `docker exec` 命令进入容器的交互式终端看到的结果，也就是所谓的**视图**\n\n![image contain](/img/2024-08-28-了解容器overlay文件系统/image32.png)\n\n#### **link & lower 文件**\n\n我们在镜像层的时候已经讲过这两个文件了，在容器层中这两个文件与镜像层作用是相同的，不过我们可以看一下 lower 文件的内容\n\n![image lower](/img/2024-08-28-了解容器overlay文件系统/image33.png)\n\n前面讲过，lower 文件的内容是在此层之下的所有层的软链接名称，我们已知此镜像的镜像层共 4 层（lower 层 3 个，upper 层 1 个），但是我们从上图可以看到在容器层之下有 5 个其他层，那多出来的一个就是我们在上一节中提到的 init 层，init 层也有其对应的软链接（看上一节中的图），所以在 `docker/overlay2/l` 目录下实际上有 6 个软连接（4个镜像层，1个 init 层，1 个容器层）\n\n![image link](/img/2024-08-28-了解容器overlay文件系统/image34.png)\n\n而通过 `docker inspect [CONTAINER ID]` 命令我们也可以判断出容器层是最顶层，其次是 init 层，最下面是镜像层，也对应了 lower 文件中软链接的顺序\n\n![image graphdriver](/img/2024-08-28-了解容器overlay文件系统/image35.png)\n\n#### **diff 目录**\n\n这个目录实际上就是 overlayFS 文件结构中的 upper 层（上图中也能看到），所以它的用途就是保存用户在容器中（merged 层）对文件进行的编辑\n\n![image diff](/img/2024-08-28-了解容器overlay文件系统/image36.png)\n\n我们在容器内的 /root/A 目录下创建了一个 a.txt 文件，可以看到在 diff 目录下也体现了出来，我们再尝试在容器中删除原本镜像自带的文件看一看效果\n\n![image contain](/img/2024-08-28-了解容器overlay文件系统/image37.png)\n\n我们在容器中删除 /etc 目录下的 shadow 文件，可以看到在 diff 目录下的 /etc 中多了一个 shadow 文件，而这个文件实际上就是我们在文章一开始讲到的 whiteout 文件，用来隐藏我们已经删掉的 shadow 文件，而实际上镜像层的 shadow 文件并没有被删除\n\n![image diff](/img/2024-08-28-了解容器overlay文件系统/image38.png)\n\n至此，我们对于 Docker 使用的 overlay2 文件结构分析结束。","tags":["Docker"]},{"title":"github 国内代理访问下载","url":"/2024/08/20/2024-08-20-github-guo-nei-dai-li-fang-wen-xia-zai/","content":"\n## **演示代理**\n\n1. 前缀\n\n> https://github.jobcher.com/gh/\n> \n1. 下载仓库\n\n> git clone https://github.jobcher.com/gh/<你要下载的GitHub地址>\n> \n\n```bash\ngit clone https://github.jobcher.com/gh/https://github.com/wu3227834/ann-filtering-benchmark-datasets.git\n```\n\n## **另外一种方法**\n\n在你有科学上网的前提下使用代理方式来连接github\n\n```bash\ngit config --global https.proxy http://127.0.0.1:1080\n#取消设置\ngit config --global --unset https.proxy\n```\n\n[http://127.0.0.1:1080](http://127.0.0.1:1080/) 是你的代理服务地址","tags":["Git"]},{"title":"python 并发函数","url":"/2024/08/20/2024-08-20-python-bing-fa-han-shu/","content":"\n## 前言\n\n工作需要向几十万表写入亿级别数据，想使用 pyhon 的并发执行。才开始使用 ThreadPoolExecutor 发现奇慢无比，大佬说这其实是串行，并发得用  multiprocessing，立帖研究。\n\n本文以 python3.10 为例，学习一下 python 的并发执行。\n\n## 并发执行\n\npython 并发执行分三个方面：多线程（threading）、多进程（multiprocessing）、多协程（asynico）\n\n适当的工具选择主要取决于要执行的任务（CPU 密集型或 IO 密集型）：\n\n- CPU 密集型（CPU-bound）：也叫做计算密集型，是指 I/O 在很短时间内就可以完成，CPU  需要大量的计算和处理，特点是 CPU 占用率相当高；例如：**压缩/解压缩、加密解密、正则表达式搜索、计算**；\n- IO 密集型（I/O bound）：是指系统运作大部分的状况是 CPU 在等 I/O（硬盘，内存）的读写操作，CPU 占用率较低，例如：**文件处理，网络爬虫，读写数据库；**\n\n在对比这三种方式之前，让我们先了解两个概念：**并行和并发**\n\n### 并行和并发的区别\n\n在 Python 中，\"并发\"和\"并行\"是两个相关但不同的概念。\n\n> 并发 （Concurrency）是指程序的设计方式，允许多个任务在重叠的时间段内执行。虽然在同一时刻只能执行一个任务，但任务之间可以通过切换上下文来实现交替执行。这种交替执行的方式可以提高程序的响应性和效率，尤其是在处理 I/O 密集型任务时。在并发编程中，任务之间通常是独立的，它们可以通过多线程、多进程、协程或异步编程等方式来实现。\n> \n> 并行（Parallelism）是指多个任务同时执行的能力。在并行编程中，多个任务真正地同时执行，通常需要多个物理或逻辑处理单元（例如多核 CPU）。并行执行任务可以显著提高计算密集型任务的性能，但对于I/O密集型任务则没有明显的优势。\n\n简单来说，**并发是指多个任务在重叠的时间段内交替执行，通过切换上下文实现任务之间的交替执行，以提高程序的响应性和效率；而并行是指多个任务真正地同时执行，通常需要多个物理或逻辑处理单元，用于同时处理不同任务，以提高计算密集型任务的性能。**\n\n```python\nimport time\nimport concurrent.futures\n\n# 并发执行任务\ndef task(name):\n    print(f'Task {name} started')\n    time.sleep(2)\n    print(f'Task {name} completed')\n\n# 并行执行任务\ndef parallel_task(name):\n    print(f'Task {name} started')\n    time.sleep(2)\n    print(f'Task {name} completed')\n\n# 并发示例\nwith concurrent.futures.ThreadPoolExecutor() as executor:\n    tasks = ['A', 'B', 'C']\n    executor.map(task, tasks)\n\n# 并行示例\nwith concurrent.futures.ProcessPoolExecutor() as executor:\n    tasks = ['X', 'Y', 'Z']\n    executor.map(parallel_task, tasks)\n```\n\n在上面的示例中，'task' 函数模拟了一个耗时 2 秒的任务，并使用线程池实现了并发执行。'parallel_task' 函数也是一个耗时 2 秒的任务，但使用了进程池实现了并行执行。我们可以运行这段代码，观察任务启动时 python 进程的数目、执行的顺序和时间，以更好地理解并发和并行的区别。\n\n然后，我们来聊 多进程、多线程、多协程的不同、关系以及怎么选择。\n\n### 进程、线程、协程的对比\n\n- 多进程：\n    - 优点：可以实现并行，且只有多进程可以实现并行\n    - 缺点：占用资源多，可启动数目最少\n- 多线程：\n    - 占用资源少，轻量级\n    - python 的线程是无法并行的（占用多个 cpu），只能进行并发\n    - 切换线程也是有开销的。\n    - 适合 IO 密集型运算、同时运行任务不多（线程可启动数量也是有限制的）\n- 多协程：\n    - 优点：内存开销最小，可启动数量最多\n    - 缺点：支持的库比较少，代码复杂，例如爬虫不支持，所以想用多协程爬取的话，可以用 aiohttp，不能用 requests\n    - 适用于：IO 密集型、超多任务运行\n\n### 进程、线程、协程的关系\n\n- 一个进程中可以启动很多线程\n- 一个线程中可以启动很多协程\n\n### **python 慢的原因**\n\n两个原因：\n\n- 是解释型语言，边解释边执行\n- GIL，无法利用多核 CPU\n\nGIL 是什么，为什么有 GIL？\n\n全局解释器锁（Global interpreter lock），是计算机程序设计语言解释器用于同步线程的一种机制，它使得任何时刻仅有一个线程在执行。\n\npython 设计初期为了解决线程并发的问题引入了 GIL，但是现在很难去除，本质是一种锁，它的好处在于简化了 python 对共享资源的管理，但是导致 python 无法实现真正的多线程执行。\n\n怎样规避 GIL 带来的限制：\n\n- IO 期间线程会释放 GIL，实现 CPU 和 IO 的并发，因此 GIL 的存在对于 IO 密集型计算是有好的，但是对 CPU 密集型则会拖累速度\n- 利用 multiprocessing，可以利用多核 CPU 的优势\n\n### **怎样选择**\n\n- IO 密集型运算优先选择多进程\n- 若满足三点：需要超多任务量、有现成协程库支持 、代码复杂度可以接受，则选择协程，否则选择线程\n\n## **threading --- 基于线程的并行**\n\n[3.10.13 Documentation » Python 标准库 » 并发执行 » threading --- 基于线程的并行](https://docs.python.org/zh-cn/3.10/library/threading.html)\n\n## multiprocessing --- 基于进程的并行\n\n[3.10.13 Documentation » Python 标准库 » 并发执行 » multiprocessing --- 基于进程的并行](https://docs.python.org/zh-cn/3.10/library/multiprocessing.html)\n\n## 参考\n\n- [3.10.13 Documentation » Python 标准库 » 并发执行](https://docs.python.org/zh-cn/3.10/library/concurrency.html)\n- [python并发编程这一篇就够了](https://blog.csdn.net/weixin_52906070/article/details/132317118)\n- [python并发从0到1](https://xz.aliyun.com/t/12766?time__1311=GqGxu7G%3DoYqWqGN4eeqBKIh4Rh%3D9kFda4D)\n- [Python中的并发和并行是什么意思?](https://www.itheima.com/news/20230710/103420.html)","tags":["Python"]},{"title":"Java命令学习系列—Jmap","url":"/2024/06/30/2024-06-30-java-ming-ling-xue-xi-xi-lie-jmap/","content":"\n> jmap 是 JDK 自带的工具软件，主要用于打印指定 Java 进程（或核心文件、远程调试服务器）的共享对象内存映射或堆内存细节。可以使用 jmap 生成 Heap Dump。\n> \n\n## 什么是堆 dump\n\n堆 dump 是反应 Java 堆使用情况的内存镜像，其中主要包括**系统信息、虚拟机信息、完整的线程 dump、所有类和对象的状态**等。一般，在内存不足、GC 异常等情况下，我们怀疑有内存泄漏。这个时候我们就可以制作堆 Dump 来查看具体情况，分析原因。\n\n## 基础知识\n\n《Java虚拟机的内存组成以及堆内存介绍》《Java GC工作原理》常见内存错误：\n\n> outOfMemoryError：年老代内存不足\n> \n> \n> outOfMemoryError:PermGen Space：永久代内存不足\n> \n> outOfMemoryError:GC overhead limit exceed：垃圾回收时间占用系统运行时间的 98% 或以上\n> \n\n## jmap\n\n### 用法摘要\n\n```java\nUsage:\n    jmap [option] <pid>\n        (to connect to running process)\n    jmap [option] <executable <core>\n        (to connect to a core file)\n    jmap [option] [server_id@]<remote server IP or hostname>\n        (to connect to remote debug server)\n\nwhere <option> is one of:\n    <none>               to print same info as Solaris pmap\n    -heap                to print java heap summary\n    -histo[:live]        to print histogram of java object heap; if the \"live\"\n                         suboption is specified, only count live objects\n    -permstat            to print permanent generation statistics\n    -finalizerinfo       to print information on objects awaiting finalization\n    -dump:<dump-options> to dump java heap in hprof binary format\n                         dump-options:\n                           live         dump only live objects; if not specified,\n                                        all objects in the heap are dumped.\n                           format=b     binary format\n                           file=<file>  dump heap to <file>\n                         Example: jmap -dump:live,format=b,file=heap.bin <pid>\n    -F                   force. Use with -dump:<dump-options> <pid> or -histo\n                         to force a heap dump or histogram when <pid> does not\n                         respond. The \"live\" suboption is not supported\n                         in this mode.\n    -h | -help           to print this help message\n    -J<flag>             to pass <flag> directly to the runtime system\n```\n\n#### 参数\n\n**option**：选项参数是互斥的(不可同时使用)。想要使用选项参数，直接跟在命令名称后即可。\n\n**pid**：需要打印配置信息的进程 ID。该进程必须是一个 Java 进程。想要获取运行的 Java 进程列表，你可以使用 jps。\n\n**executable**：产生核心 dump 的 Java 可执行文件。\n\n**core**：需要打印配置信息的核心文件。\n\n**remote-hostname-or-IP**：远程调试服务器的（请查看jsadebugd）主机名或 IP 地址。\n\n**server-id**：可选的唯一 id，如果相同的远程主机上运行了多台调试服务器，用此选项参数标识服务器。\n\n#### 选项\n\n**\\<no option\\>**：如果使用不带选项参数的 jmap 打印共享对象映射，将会打印目标虚拟机中加载的每个共享对象的起始地址、映射大小以及共享对象文件的路径全称。这与 Solaris 的 pmap 工具比较相似。\n\n- **dump:[live,]format=b,file=<filename>**：以 hprof 二进制格式转储 Java 堆到指定 filename 的文件中。live 子选项是可选的。如果指定了 live 子选项，堆中只有活动的对象会被转储。想要浏览 heap dump，你可以使用 jhat（Java 堆分析工具）读取生成的文件。\n- **finalizerinfo**：打印等待终结的对象信息。\n- **heap**：打印一个堆的摘要信息，包括使用的 GC 算法、堆配置信息和 generation wise heap usage。\n- **histo[:live]**：打印堆的柱状图。其中包括每个 Java 类、对象数量、内存大小（单位：字节）、完全限定的类名。打印的虚拟机内部的类名称将会带有一个’*’前缀。如果指定了live子选项，则只计算活动的对象。\n- **permstat**：打印 Java 堆内存的永久保存区域的类加载器的智能统计信息。对于每个类加载器而言，它的名称、活跃度、地址、父类加载器、它所加载的类的数量和大小都会被打印。此外，包含的字符串数量和大小也会被打印。\n- **F**：强制模式。如果指定的 pid 没有响应，请使用 jmap -dump 或 jmap -histo 选项。此模式下，不支持 live 子选项。\n- **h**：打印帮助信息。\n- **help**：打印帮助信息。\n- **J<flag> **：指定传递给运行jmap的JVM的参数。\n\n### 举例\n\n**查看 java 堆（heap）使用情况**，执行命令： \n\n```bash\njmap -heap 31846\n\nAttaching to process ID 31846, please wait...\nDebugger attached successfully.\nServer compiler detected.\nJVM version is 24.71-b01\n\nusing thread-local object allocation.\nParallel GC with 4 thread(s) //GC 方式\n\nHeap Configuration: //堆内存初始化配置\n   MinHeapFreeRatio = 0 //对应jvm启动参数-XX:MinHeapFreeRatio设置JVM堆最小空闲比率(default 40)\n   MaxHeapFreeRatio = 100 //对应jvm启动参数 -XX:MaxHeapFreeRatio设置JVM堆最大空闲比率(default 70)\n   MaxHeapSize      = 2082471936 (1986.0MB) //对应jvm启动参数-XX:MaxHeapSize=设置JVM堆的最大大小\n   NewSize          = 1310720 (1.25MB) //对应jvm启动参数-XX:NewSize=设置JVM堆的‘新生代’的默认大小\n   MaxNewSize       = 17592186044415 MB //对应jvm启动参数-XX:MaxNewSize=设置JVM堆的‘新生代’的最大大小\n   OldSize          = 5439488 (5.1875MB) //对应jvm启动参数-XX:OldSize=<value>:设置JVM堆的‘老生代’的大小\n   NewRatio         = 2 //对应jvm启动参数-XX:NewRatio=:‘新生代’和‘老生代’的大小比率\n   SurvivorRatio    = 8 //对应jvm启动参数-XX:SurvivorRatio=设置年轻代中Eden区与Survivor区的大小比值 \n   PermSize         = 21757952 (20.75MB)  //对应jvm启动参数-XX:PermSize=<value>:设置JVM堆的‘永生代’的初始大小\n   MaxPermSize      = 85983232 (82.0MB) //对应jvm启动参数-XX:MaxPermSize=<value>:设置JVM堆的‘永生代’的最大大小\n   G1HeapRegionSize = 0 (0.0MB)\n\nHeap Usage: //堆内存使用情况\nPS Young Generation\nEden Space: //Eden区内存分布\n   capacity = 33030144 (31.5MB) //Eden区总容量\n   used     = 1524040 (1.4534378051757812MB) //Eden区已使用\n   free     = 31506104 (30.04656219482422MB) //Eden区剩余容量\n   4.614088270399305% used //Eden区使用比率\nFrom Space:  //其中一个Survivor区的内存分布\n   capacity = 5242880 (5.0MB)\n   used     = 0 (0.0MB)\n   free     = 5242880 (5.0MB)\n   0.0% used\nTo Space:  //另一个Survivor区的内存分布\n   capacity = 5242880 (5.0MB)\n   used     = 0 (0.0MB)\n   free     = 5242880 (5.0MB)\n   0.0% used\nPS Old Generation //当前的Old区内存分布\n   capacity = 86507520 (82.5MB)\n   used     = 0 (0.0MB)\n   free     = 86507520 (82.5MB)\n   0.0% used\nPS Perm Generation//当前的 “永生代” 内存分布\n   capacity = 22020096 (21.0MB)\n   used     = 2496528 (2.3808746337890625MB)\n   free     = 19523568 (18.619125366210938MB)\n   11.337498256138392% used\n\n670 interned Strings occupying 43720 bytes.\n```\n\n**查看堆内存（histogram）中的对象数量及大小**。执行命令： \n\n```bash\njmap -histo 3331\n\nnum     #instances         #bytes  class name\n编号     个数                字节     类名\n----------------------------------------------\n   1:             7        1322080  [I\n   2:          5603         722368  <methodKlass>\n   3:          5603         641944  <constMethodKlass>\n   4:         34022         544352  java.lang.Integer\n   5:           371         437208  <constantPoolKlass>\n   6:           336         270624  <constantPoolCacheKlass>\n   7:           371         253816  <instanceKlassKlass>\n```\n\n> **jmap -histo:live 这个命令执行，JVM会先触发gc，然后再统计信息。**\n> \n\n**将内存使用的详细情况输出到文件**，执行命令：\n\n```bash\njmap -dump:format=b,file=heapDump 6900\n```\n\n然后用 `jhat` 命令可以参看 `jhat -port 5000 heapDump` 在浏览器中访问：`http://localhost:5000/` 查看详细信息\n\n> 这个命令执行，JVM 会将整个 heap 的信息 dump 写入到一个文件，heap 如果比较大的话，就会导致这个过程比较耗时，并且执行的过程中为了保证 dump 的信息是可靠的，所以会暂停应用。\n> \n\n### 总结\n\n1. 如果程序内存不足或者频繁GC，很有可能存在内存泄露情况，这时候就要借助 Java 堆 Dump 查看对象的情况。\n2. 要制作堆 Dump 可以直接使用 jvm 自带的 jmap 命令\n3. 可以先使用 `jmap -heap` 命令查看堆的使用情况，看一下各个堆空间的占用情况。\n4. 使用 `jmap -histo:[live]` 查看堆内存中的对象的情况。如果有大量对象在持续被引用，并没有被释放掉，那就产生了内存泄露，就要结合代码，把不用的对象释放掉。\n5. 也可以使用 `jmap -dump:format=b,file=<fileName>`命令将堆信息保存到一个文件中，再借助jhat命令查看详细内容\n6. 在内存出现泄露、溢出或者其它前提条件下，建议多 dump 几次内存，把内存文件进行编号归档，便于后续内存整理分析。\n\n**Error attaching to process: sun.jvm.hotspot.debugger.DebuggerException: Can’t attach to the process**\n\n在ubuntu中第一次使用 jmap 会报错：`Error attaching to process: sun.jvm.hotspot.debugger.DebuggerException: Can't attach to the process`，这是oracla文档中提到的一个bug：[http://bugs.java.com/bugdatabase/view_bug.do?bug_id=7050524,解决方式如下：](http://bugs.java.com/bugdatabase/view_bug.do?bug_id=7050524,%E8%A7%A3%E5%86%B3%E6%96%B9%E5%BC%8F%E5%A6%82%E4%B8%8B%EF%BC%9A)\n\n1. echo 0 | sudo tee /proc/sys/kernel/yama/ptrace_scope 该方法在下次重启前有效。\n2. 永久有效方法 sudo vi /etc/sysctl.d/10-ptrace.conf 编辑下面这行 `kernel.yama.ptrace_scope = 1` 修改为 `kernel.yama.ptrace_scope = 0` 重启系统，使修改生效。","tags":["性能测试","Java"]},{"title":"Java命令学习系列—Jps","url":"/2024/06/30/2024-06-30-java-ming-ling-xue-xi-xi-lie-jps/","content":"\n> jps 位于 jdk 的 bin 目录下，其作用是显示当前系统的 java 进程情况，及其 id 号。 jps 相当于 Solaris 进程工具 ps。不像 ”pgrep java” 或 ”ps -ef grep java” ，jps 并不使用应用程序名来查找 JVM 实例。因此，它查找所有的 Java 应用程序，包括即使没有使用 java 执行体的那种（例如，定制的启动 器）。另外，jps 仅查找当前用户的 Java 进程，而不是当前系统中的所有进程。\n> \n\n## 位置\n\n我们知道，很多 JAVA 命令都在 jdk 的 JAVA_HOME/bin/ 目录下面，jps 也不例外，它就在 bin 目录下，它是 java 自带的一个命令。\n\n## 功能\n\njps（Java Virtual Machine Process Status Tool）是 JDK 1.5 提供的一个显示当前所有 java 进程 pid 的命令，简单实用，非常适合在 linux/unix 平台上简单察看当前 java 进程的一些简单情况。\n\n## 原理\n\njdk 中的 jps 命令可以显示当前运行的 java 进程以及相关参数，它的实现机制如下：\n\njava 程序在启动以后，会在 `java.io.tmpdir` 指定的目录下，就是临时文件夹里，生成一个类似于\n\n`hsperfdata_User` 的文件夹，这个文件夹里（在 Linux 中为 /tmp/hsperfdata_{userName}/），有几个文件，名字就是 java 进程的 pid，因此列出当前运行的 java 进程，只是把这个目录里的文件名列一下而已。 至于系统的参数什么，就可以解析这几个文件获得。例如：\n\n```bash\n[root@pudding-160 hsperfdata_root]## ll\ntotal 96\n-rw------- 1 root root 32768 Jun 25 21:28 372997\n-rw------- 1 root root 32768 Jun 25 21:27 49553\n-rw------- 1 root root 32768 Jun 25 21:27 5032\n[root@pudding-160 hsperfdata_root]## pwd\n/tmp/hsperfdata_root\n[root@pudding-160 hsperfdata_root]## jps\n372997 ManagerMaster\n49553 RunJar\n5032 ManagerAgent\n433884 Jps\n```\n\n## 使用\n\n想要学习一个命令，先来看看帮助，使用 `jps -help` 查看帮助：\n\n```bash\n[root@pudding-160 ~]## jps -help\nusage: jps [-help]\n       jps [-q] [-mlvV] [<hostid>]\n\nDefinitions:\n    <hostid>:      <hostname>[:<port>]\n```\n\n接下来，为了详细介绍这些参数，我们编写几个类，在 main 方法里写一个 while(true) 的循环，查看 java 进程情况。代码如下：\n\n```java\npackage com.JavaCommand;\n/**\n * @author pudding\n */\npublic class JpsDemo {\n    public static void main(String[] args) {\n        while(true){\n            System.out.println(1);\n        }\n    }\n}\n```\n\n**-q 只显示 pid，不显示 class 名称、jar 文件名和传递给 main 方法的参数**\n\n```bash\npudding@DESKTOP-1QCHCU4:/mnt/wsl/demo$ jps -q\n4167\n4312\n```\n\n**-m 输出传递给 main 方法的参数，在嵌入式 jvm 上可能是null，**在这里，在启动 main 方法的时候，我给 String[] args 传递一个参数：pudding，执行`jsp -m` ：\n\n```bash\npudding@DESKTOP-1QCHCU4:/mnt/wsl/demo$ jps -m\n7760 Jps -m\n7674 JpsDemo pudding\n```\n\n**-l 输出应用程序 main class 的完整 package 名或者应用程序的 jar 文件完整路径名：**\n\n```bash\npudding@DESKTOP-1QCHCU4:/mnt/wsl/demo$ jps -l\n4517 sun.tools.jps.Jps\n4167 com.JavaCommand.JpsDemo\n```\n\n**-v 输出传递给 JVM 的参数；**在这里，在启动 main 方法的时候，我给 jvm 传递一个参数：-Dfile.encoding=UTF-8，执行`jps -v`：\n\n```bash\npudding@DESKTOP-1QCHCU4:/mnt/wsl/demo$ jps -v\n9317 JpsDemo -Dfile.encoding=UTF-8\n9391 Jps -Dapplication.home=/usr/lib/jvm/java-8-openjdk-amd64 -Xms8m\n```\n\nPS：jps 命令有个地方很不好，似乎只能显示当前用户的 java 进程，要显示其他用户的还是只能用 unix/linux 的 ps 命令。\n\n> jps 是我最常用的 java 命令。使用 jps 可以查看当前有哪些 Java 进程处于运行状态。如果我运行了一个 web 应用（使用 tomcat、jboss、jetty 等启动）的时候，我就可以使用 jps 查看启动情况。有的时候我想知道这个应用的日志会输出到哪里，或者启动的时候使用了哪些 javaagent，那么我可以使用 jps -v 查看进程的 jvm 参数情况。\n> \n\n## jps 失效处理\n\n### 现象\n\n用 `ps -ef|grep java` 能看到启动的 java 进程，但是用 jps 查看却不存在该进程的 id。待会儿解释过之后就能知道在该情况下，jconsole、jvisualvm 可能无法监控该进程，其他 java 自带工具也可能无法使用。\n\n### 分析\n\njps、jconsole、jvisualvm 等工具的数据来源就是这个文件（/tmp/hsperfdata_${userName}/pid)。所以当该文件不存在或是无法读取时就会出现 jps 无法查看该进程号，jconsole 无法监控等问题\n\n### 原因\n\n1. **磁盘读写、目录权限问题**：若该用户没有权限写/tmp目录或是磁盘已满，则无法创建 /tmp/hsperfdata_${userName}/pid 文件。或该文件已经生成，但用户没有读权限\n2. **临时文件丢失，被删除或是定期清理**：对于 linux 机器，一般都会存在定时任务对临时文件夹进行清理，导致 /tmp 目录被清空。这也是我第一次碰到该现象的原因。常用的可能定时删除临时目录的工具为 crontab、redhat 的 tmpwatch、ubuntu 的 tmpreaper 等等\n    \n    > 这个导致的现象可能会是这样，用 jconsole 监控进程，发现在某一时段后进程仍然存在，但是却没有监控信息了。\n    > \n3. **java 进程信息文件存储地址被设置，不在 /tmp 目录下**：上面我们在介绍时说默认会在 /tmp/hsperfdata_${userName} 目录保存进程信息，但由于以上 1、2 所述原因，可能导致该文件无法生成或是丢失，所以 java 启动时提供了参数（-Djava.io.tmpdir），可以对这个文件的位置进行设置，而 jps、jconsole 都只会从 /tmp 目录读取，而无法从设置后的目录读物信息，这是我第二次碰到该现象的原因","tags":["性能测试","Java"]},{"title":"Java命令学习系列—Jstack","url":"/2024/06/30/2024-06-30-java-ming-ling-xue-xi-xi-lie-jstack/","content":"\n> jstack 是 java 虚拟机自带的一种堆栈跟踪工具\n> \n\n## 功能\n\njstack 用于生成 java 虚拟机当前时刻的线程快照。线程快照是当前 java 虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是**定位线程出现长时间停顿的原因**，如**线程间死锁、死循环、请求外部资源导致的长时间**等待等。 线程出现停顿的时候通过 jstack 来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么事情，或者等待什么资源。 如果 java 程序崩溃生成 core 文件，jstack 工具可以用来获得 core 文件的 java stac k和 native stack 的信息，从而可以轻松地知道 java 程序是如何崩溃和在程序何处发生问题。另外，jstack 工具还可以附属到正在运行的 java 程序中，看到当时运行的 java 程序的 java stack 和 native stack 的信息, 如果现在运行的 java 程序呈现 hung 的状态，jstack 是非常有用的。\n\n> So，**jstack命令主要用来查看Java线程的调用堆栈的，可以用来分析线程问题（如死锁）。**\n> \n\n## **线程状态**\n\n想要通过 jstack 命令来分析线程的情况的话，首先要知道线程都有哪些状态，下面这些状态是我们使用 jstack 命令查看线程堆栈信息时可能会看到的**线程的几种状态**：\n\n1. NEW，未启动的。不会出现在 Dump 中。\n2. RUNNABLE，在虚拟机内执行的。\n3. BLOCKED，受阻塞并等待监视器锁。\n4. WATING，无限期等待另一个线程执行特定操作。\n5. TIMED_WATING，有时限的等待另一个线程的特定操作。\n6. TERMINATED，已退出的。\n\n## Monitor\n\n在多线程的 JAVA 程序中，实现线程之间的同步，就要说说 Monitor。Monitor 是 Java 中用来实现线程之间的互斥与协作的主要手段，它可以看成是对象或者 class 的锁。每一个对象都有，也仅有一个 monitor。下图，描述了线程和 Monitor 之间的关系，以及线程的状态转换图：\n\n![monitor](/img/2024-06-30-Jstack/Untitled.png)\n\n**进入区（Entrt Set）**：表示线程通过 synchronized 要求获取对象的锁。如果对象未被锁住，则进入拥有者；否则则在进入区等待。一旦对象锁被其他线程释放,立即参与竞争。\n\n**拥有者（The Owner）**：表示某一线程成功竞争到对象锁。\n\n**等待区（Wait Set）**：表示线程通过对象的 wait 方法，释放对象的锁，并在等待区等待被唤醒。\n\n从图中可以看出，一个 Monitor 在某个时刻，只能被一个线程拥有，该线程就是 `“Active Thread”`，而其它线程都是 `“Waiting Thread”`，分别在两个队列 `“Entry Set”` 和 `“Wait Set”` 里面等候。在 `“Entry Set”` 中等待的线程状态是 `“Waiting for monitor entry”`，而在 `“Wait Set”` 中等待的线程状态是 `“in Object.wait()”`。 先看  `“Entry Set”` 里面的线程。我们称被 synchronized 保护起来的代码段为临界区。当一个线程申请进入临界区时，它就进入了 `“Entry Set”` 队列。对应的 code 就像：\n\n```java\nsynchronized(obj) {\n\t.........\n}\n```\n\n## 调用修饰\n\n表示线程在方法调用时，额外的重要的操作。线程 Dump 分析的重要信息。修饰上方的方法调用。\n\n> locked <地址> 目标：使用 synchronized 申请对象锁成功，监视器的拥有者。\nwaiting to lock <地址> 目标：使用 synchronized 申请对象锁未成功，在迚入区等待。\nwaiting on <地址> 目标：使用 synchronized 申请对象锁成功后，释放锁幵在等待区等待。\nparking to wait for <地址> 目标\n> \n\n### **locked**\n\n```java\nat oracle.jdbc.driver.PhysicalConnection.prepareStatement\n- locked <0x00002aab63bf7f58> (a oracle.jdbc.driver.T4CConnection)\nat oracle.jdbc.driver.PhysicalConnection.prepareStatement\n- locked <0x00002aab63bf7f58> (a oracle.jdbc.driver.T4CConnection)\nat com.jiuqi.dna.core.internal.db.datasource.PooledConnection.prepareStatement\n```\n\n通过 synchronized 关键字，成功获取到了对象的锁,成为监视器的拥有者，在临界区内操作。对象锁是可以线程重入的。\n\n### **waiting to lock**\n\n```java\nat com.jiuqi.dna.core.impl.CacheHolder.isVisibleIn(CacheHolder.java:165)\n- waiting to lock <0x0000000097ba9aa8> (a CacheHolder)\nat com.jiuqi.dna.core.impl.CacheGroup$Index.findHolder\nat com.jiuqi.dna.core.impl.ContextImpl.find\nat com.jiuqi.dna.bap.basedata.common.util.BaseDataCenter.findInfo\n```\n\n通过 synchronized 关键字，没有获取到了对象的锁，线程在监视器的进入区等待。在调用栈顶出现，线程状态为 Blocked。\n\n### **waiting on**\n\n```java\nat java.lang.Object.wait(Native Method)\n- waiting on <0x00000000da2defb0> (a WorkingThread)\nat com.jiuqi.dna.core.impl.WorkingManager.getWorkToDo\n- locked <0x00000000da2defb0> (a WorkingThread)\nat com.jiuqi.dna.core.impl.WorkingThread.run\n```\n\n通过 synchronized 关键字，成功获取到了对象的锁后，调用了 wait 方法，进入对象的等待区等待。在调用栈顶出现，线程状态为 WAITING 或 TIMED_WATING 。\n\n### **parking to wait for**\n\npark 是基本的线程阻塞原语，不通过监视器在对象上阻塞。随 concurrent 包会出现的新的机制，synchronized 体系不同。\n\n## 线程动作\n\n线程状态产生的原因：\n\n> runnable：状态一般为RUNNABLE。\n> \n> \n> in Object.wait()：等待区等待，状态为 WAITING 或 TIMED_WAITING。\n> \n> waiting for monitor entry：进入区等待，状态为 BLOCKED。\n> \n> waiting on condition：等待区等待、被 park。\n> \n> sleeping：休眠的线程，调用了 Thread.sleep()。\n> \n\n**Wait on condition** 该状态出现在线程等待某个条件的发生。具体是什么原因，可以结合 stacktrace 来分析。\n\n- 最常见的情况就是线程处于 sleep 状态，等待被唤醒。\n- 常见的情况还有等待网络 IO：在 java 引入 nio 之前，对于每个网络连接，都有一个对应的线程来处理网络的读写操作，即使没有可读写的数据，线程仍然阻塞在读写操作上，这样有可能造成资源浪费，而且给操作系统的线程调度也带来压力。在  NewIO 里采用了新的机制，编写的服务器程序的性能和可扩展性都得到提高。正等待网络读写，这可能是一个网络瓶颈的征兆。因为网络阻塞导致线程无法执行。\n    - 一种情况是网络非常忙，几乎消耗了所有的带宽，仍然有大量数据等待网络读写；\n    - 另一种情况也可能是网络空闲，但由于路由等问题，导致包无法正常的到达。\n\n所以要结合系统的一些性能观察工具来综合分析，比如 netstat 统计单位时间的发送包的数目，如果很明显超过了所在网络带宽的限制；观察 cpu 的利用率，如果系统态的 CPU 时间，相对于用户态的 CPU 时间比例较高；如果程序运行在 Solaris 10 平台上，可以用 dtrace 工具看系统调用的情况，如果观察到  read/write 的系统调用的次数或者运行时间遥遥领先；这些都指向由于网络带宽所限导致的网络瓶颈。\n\n## 线程 Dump 的分析\n\n### 原则\n\n结合代码阅读的推理。需要线程 Dump 和源码的相互推到和印证。\n\n造成 Bug 的根源往往会在调用栈上直接体现，一定要格外注意线程当前调用之前的所有调用。\n\n### 入手点\n\n**进入区等待**\n\n```java\n\"d&a-3588\" daemon waiting for monitor entry [0x000000006e5d5000]\njava.lang.Thread.State: BLOCKED (on object monitor)\nat com.jiuqi.dna.bap.authority.service.UserService$LoginHandler.handle()\n- waiting to lock <0x0000000602f38e90> (a java.lang.Object)\nat com.jiuqi.dna.bap.authority.service.UserService$LoginHandler.handle()\n```\n\n线程状态 BLOCKED，线程动作 wait on monitor entry，调用修饰 waiting to lock 总是一起出现。表示在代码级别已经存在冲突的调用。必然有问题的代码，需要尽可能减少其发生。\n\n**同步块阻塞**\n\n一个线程锁住某对象,大量其他线程在该对象上等待。\n\n```java\n\"blocker\" runnable\njava.lang.Thread.State: RUNNABLE\nat com.jiuqi.hcl.javadump.Blocker$1.run(Blocker.java:23)\n- locked <0x00000000eb8eff68> (a java.lang.Object)\n\"blockee-11\" waiting for monitor entry\njava.lang.Thread.State: BLOCKED (on object monitor)\nat com.jiuqi.hcl.javadump.Blocker$2.run(Blocker.java:41)\n- waiting to lock <0x00000000eb8eff68> (a java.lang.Object)\n\"blockee-86\" waiting for monitor entry\njava.lang.Thread.State: BLOCKED (on object monitor)\nat com.jiuqi.hcl.javadump.Blocker$2.run(Blocker.java:41)\n- waiting to lock <0x00000000eb8eff68> (a java.lang.Object)\n```\n\n**持续运行的IO** \n\nIO操作是会以 RUNNABLE 状态达成阻塞。例如：数据库死锁、网络读写。 格外注意对 IO 线程的真实状态的分析。一般来说，被捕捉到 RUNNABLE 的 IO 调用，都是有问题的。\n\n以下堆栈显示： 线程状态为 RUNNABLE。 调用栈在 SocketInputStream 或 SocketImpl 上，socketRead0 等方法。 调用栈包含了 jdbc 相关的包。很可能发生了数据库死锁\n\n```java\n\"d&a-614\" daemon prio=6 tid=0x0000000022f1f000 nid=0x37c8 runnable\n[0x0000000027cbd000]\njava.lang.Thread.State: RUNNABLE\nat java.net.SocketInputStream.socketRead0(Native Method)\nat java.net.SocketInputStream.read(Unknown Source)\nat oracle.net.ns.Packet.receive(Packet.java:240)\nat oracle.net.ns.DataPacket.receive(DataPacket.java:92)\nat oracle.net.ns.NetInputStream.getNextPacket(NetInputStream.java:172)\nat oracle.net.ns.NetInputStream.read(NetInputStream.java:117)\nat oracle.jdbc.driver.T4CMAREngine.unmarshalUB1(T4CMAREngine.java:1034)\nat oracle.jdbc.driver.T4C8Oall.receive(T4C8Oall.java:588)\n```\n\n**分线程调度的休眠**\n\n正常的线程池等待\n\n```java\n\"d&a-131\" in Object.wait()\njava.lang.Thread.State: TIMED_WAITING (on object monitor)\nat java.lang.Object.wait(Native Method)\nat com.jiuqi.dna.core.impl.WorkingManager.getWorkToDo(WorkingManager.java:322)\n- locked <0x0000000313f656f8> (a com.jiuqi.dna.core.impl.WorkingThread)\nat com.jiuqi.dna.core.impl.WorkingThread.run(WorkingThread.java:40)\n```\n\n可疑的线程等待\n\n```java\n\"d&a-121\" in Object.wait()\njava.lang.Thread.State: WAITING (on object monitor)\nat java.lang.Object.wait(Native Method)\nat java.lang.Object.wait(Object.java:485)\nat com.jiuqi.dna.core.impl.AcquirableAccessor.exclusive()\n- locked <0x00000003011678d8> (a com.jiuqi.dna.core.impl.CacheGroup)\nat com.jiuqi.dna.core.impl.Transaction.lock()\n```\n\n### **入手点总结**\n\n**wait on monitor entry**： 被阻塞的，肯定有问题\n\n**runnable**： 注意 IO 线程\n\n**in Object.wait()**： 注意非线程池等待\n\n## 使用\n\n想要学习一个命令，先来看看帮助，使用 `jstack -help` 查看帮助：\n\n```java\npudding@DESKTOP-1QCHCU4:~$ jstack -help\nUsage:\n    jstack [-l] <pid>\n        (to connect to running process)\n    jstack -F [-m] [-l] <pid>\n        (to connect to a hung process)\n    jstack [-m] [-l] <executable> <core>\n        (to connect to a core file)\n    jstack [-m] [-l] [server_id@]<remote server IP or hostname>\n        (to connect to a remote debug server)\n\nOptions:\n    -F  to force a thread dump. Use when jstack <pid> does not respond (process is hung)\n    -m  to print both java and native frames (mixed mode)\n    -l  long listing. Prints additional information about locks\n    -h or -help to print this help message\n```\n\n- -F：当 ’jstack [-l] pid’ 没有相应的时候强制打印栈信息\n- -l：长列表。打印关于锁的附加信息，例如属于 java.util.concurrent 的 ownable synchronizers 列表\n- -m：打印 java 和 native c/c++ 框架的所有栈信息\n- -h：-help 打印帮助信息\n- pid：需要被打印配置信息的 java 进程 id，可以用 jps 查询\n\n首先，我们分析这么一段程序的线程情况：\n\n```java\n/**\n * @author pudding\n */\n\npublic class JStackDemo1 {\n    public static void main(String[] args) {\n        while (true) {\n            //Do Nothing\n        }\n    }\n}\n```\n\n先是有 jps 查看进程号：\n\n```java\npudding@DESKTOP-1QCHCU4:/mnt/wsl$ jps\n929 org.eclipse.equinox.launcher_1.6.800.v20240513-1750.jar\n1477 sun.tools.jcmd.JCmd\n1499 Jps\n1372 JStackDemo1\n```\n\n然后使用 jstack 查看堆栈信息：\n\n```java\npudding@DESKTOP-1QCHCU4:/mnt/wsl$ jstack 1372\n2024-06-26 21:41:40\nFull thread dump OpenJDK 64-Bit Server VM (25.412-b08 mixed mode):\n...此处省略若干内容...\n\"main\" #1 prio=5 os_prio=0 tid=0x00007fc86c00a800 nid=0x55d runnable [0x00007fc873672000]\n   java.lang.Thread.State: RUNNABLE\n        at JStackDemo1.main(JStackDemo1.java:7)\n```\n\n我们可以从这段堆栈信息中看出什么来呢？我们可以看到，当前一共有一条用户级别线程，线程处于 runnable 状态，执行到 [JStackDemo1.java](/img/2024-06-30-Jstack/http://JStackDemo1.java) 的第七行。 看下面代码：\n\n```java\n/**\n * @author pudding\n */\n\npublic class JStackDemo1 {\n    public static void main(String[] args) {\n        while (true) {\n            Thread thread = new Thread(new Thread1());\n            thread.start();\n        }\n    }\n}\n\nclass Thread1 implements Runnable{\n    @Override\n    public void run() {\n        while(true){\n            System.out.println(1);\n        }\n    }\n}\n```\n\n线程堆栈信息如下：\n\n```java\n\"Reference Handler\" daemon prio=10 tid=0x00007fbbcc06e000 nid=0x286c in Object.wait() [0x00007fbbc8dfc000]\n   java.lang.Thread.State: WAITING (on object monitor)\n    at java.lang.Object.wait(Native Method)\n    - waiting on <0x0000000783e066e0> (a java.lang.ref.Reference$Lock)\n    at java.lang.Object.wait(Object.java:503)\n    at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:133)\n    - locked <0x0000000783e066e0> (a java.lang.ref.Reference$Lock)\n```\n\n我们能看到：\n\n> 线程的状态： WAITING 线程的调用栈\n线程的当前锁住的资源： <0x0000000783e066e0>\n线程当前等待的资源：<0x0000000783e066e0>\n> \n\n为什么同时锁住的等待同一个资源：\n\n> 线程的执行中，先获得了这个对象的 Monitor（对应于 locked <0x0000000783e066e0>）。当执行到 obj.wait()，线程即放弃了 Monitor 的所有权，进入 “wait set” 队列（对应于 waiting on <0x0000000783e066e0> ）。\n> \n\n### **死锁分析**\n\n学会了怎么使用 jstack 命令之后，我们就可以看看，如何使用 jstack 分析死锁了，这也是我们一定要掌握的内容。 **啥叫死锁？** 所谓[死锁](/img/2024-06-30-Jstack/http://zh.wikipedia.org/wiki/%E6%AD%BB%E9%94%81)： 是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。 \n\n说白了，我现在想吃鸡蛋灌饼，桌子上放着鸡蛋和饼，但是我和我的朋友同时分别拿起了鸡蛋和病，我手里拿着鸡蛋，但是我需要他手里的饼。他手里拿着饼，但是他想要我手里的鸡蛋。就这样，如果不能同时拿到鸡蛋和饼，那我们就不能继续做后面的工作（做鸡蛋灌饼）。所以，这就造成了死锁。 **看一段死锁的程序：**\n\n```java\n/**\n * @author pudding\n */\n\npublic class JStackDemo {\n    public static void main(String[] args) {\n        Thread t1 = new Thread(new DeadLockclass(true));\n        Thread t2 = new Thread(new DeadLockclass(false));\n        t1.start();\n        t2.start();\n    }\n}\nclass DeadLockclass implements Runnable {\n    public boolean falg;\n    DeadLockclass(boolean falg) {\n        this.falg = falg;\n    }\n    public void run() {\n        /**\n         * 如果falg的值为true则调用t1线程\n         */\n        if (falg) {\n            while (true) {\n                synchronized (Suo.o1) {\n                    System.out.println(\"o1 \" + Thread.currentThread().getName());\n                    synchronized (Suo.o2) {\n                        System.out.println(\"o2 \" + Thread.currentThread().getName());\n                    }\n                }\n            }\n        }\n        /**\n         * 如果falg的值为false则调用t2线程\n         */\n        else {\n            while (true) {\n                synchronized (Suo.o2) {\n                    System.out.println(\"o2 \" + Thread.currentThread().getName());\n                    synchronized (Suo.o1) {\n                        System.out.println(\"o1 \" + Thread.currentThread().getName());\n                    }\n                }\n            }\n        }\n    }\n}\n\nclass Suo {\n    static Object o1 = new Object();\n    static Object o2 = new Object();\n}\n```\n\n当我启动该程序时，我们看一下控制台：\n\n![控制台](/img/2024-06-30-Jstack/Untitled1.png)\n\n我们发现，程序只输出了两行内容，然后程序就不再打印其它的东西了，但是程序并没有停止。这样就产生了死锁。 当线程 1 使用 `synchronized` 锁住了 o1 的同时，线程 2 也是用 `synchronized` 锁住了 o2。当两个线程都执行完第一个打印任务的时候，线程 1 想锁住 o2，线程 2 想锁住 o1。但是，线程 1 当前锁着 o1，线程 2 锁着 o2。所以两个想成都无法继续执行下去，就造成了死锁。\n然后，我们使用 **jstack 来看一下线程堆栈信息**：\n\n```java\nFound one Java-level deadlock:\n=============================\n\"Thread-1\":\n  waiting to lock monitor 0x00007f6274003ac8 (object 0x000000077e004ec0, a java.lang.Object),\n  which is held by \"Thread-0\"\n\"Thread-0\":\n  waiting to lock monitor 0x00007f62740050c8 (object 0x000000077e004ed0, a java.lang.Object),\n  which is held by \"Thread-1\"\n\nJava stack information for the threads listed above:\n===================================================\n\"Thread-1\":\n        at DeadLockclass.run(JStackDemo.java:40)\n        - waiting to lock <0x000000077e004ec0> (a java.lang.Object)\n        - locked <0x000000077e004ed0> (a java.lang.Object)\n        at java.lang.Thread.run(Thread.java:750)\n\"Thread-0\":\n        at DeadLockclass.run(JStackDemo.java:27)\n        - waiting to lock <0x000000077e004ed0> (a java.lang.Object)\n        - locked <0x000000077e004ec0> (a java.lang.Object)\n        at java.lang.Thread.run(Thread.java:750)\n\nFound 1 deadlock.\n```\n\n哈哈，堆栈写的很明显，它告诉我们 `Found one Java-level deadlock`，然后指出造成死锁的两个线程的内容。然后，又通过 `Java stack information for the threads listed above`来显示更详细的死锁的信息。 他说\n\n> Thread-1 在想要执行第 40 行的时候，当前锁住了资源 `<0x00000007d6aa2ca8>`，但是他在等待资源 `<0x00000007d6aa2c98>` ；\nThread-0 在想要执行第 27 行的时候，当前锁住了资源 `<0x00000007d6aa2c98>`，但是他在等待资源`<0x00000007d6aa2ca8>` ；\n由于这两个线程都持有资源，并且都需要对方的资源，所以造成了死锁。 原因我们找到了，就可以具体问题具体分析，解决这个死锁了。\n> \n\n### **其他**\n\n**虚拟机执行 Full GC 时，会阻塞所有的用户线程。因此，即时获取到同步锁的线程也有可能被阻塞。** 在查看线程 Dump 时，首先查看内存使用情况","tags":["性能测试","Java"]},{"title":"Java命令学习系列—Jstat","url":"/2024/06/30/2024-06-30-java-ming-ling-xue-xi-xi-lie-jstat/","content":"\n> jstat (JVM Statistics Monitoring Tool) 用于监控虚拟机各种运行状态信息的命令行工具。它可以显示本地或远程虚拟机进程中类加载、内存、垃圾收集、JIT 编译等运行数据，再没有 GUI 图形的服务器上，它是运行期间定位虚拟机性能问题首选工具。\n> \n\njstat 位于 java 的 bin 目录下，主要利用 JVM 内建的指令对 Java 应用程序的资源和性能进行实施的命令行的监控，包括了对 Heap size 和垃圾回收状况的监控。可见，Jstat 是轻量级的、专门针对 JVM 的工具，非常适用。\n\n## jstat 命令格式\n\n```bash\njstat -<option> [-t] [-h<lines>] <vmid> [<interval> [<count>]]\n```\n\n### **参数解释：**\n\n- Option — 选项，我们一般使用 -gcutil 查看 gc 情况\n- vmid — VM的进程号，即当前运行的java进程号\n- interval– 间隔时间，单位为秒或者毫秒\n- count — 打印次数，如果缺省则打印无数次\n- 参数 interval 和 count 代表查询间隔和次数，如果省略这两个参数，说明只查询一次。假设需要每 250 毫秒查询一次进程 5828 垃圾收集状况，一共查询 5 次，那命令行如下：\n    \n    ```bash\n    jstat -gc 5828 250 5\n    ```\n    \n\n```bash\n对于命令格式中的 VMID 与 LVMID 需要特别说明下：\n如果是本地虚拟机进程，VMID(Virtual Machine IDentifier,虚机标识符) 和 LVMID(Local Virtual Machine IDentifier，虚机标识符) 是一致的；\n如果是远程虚拟机进程，那 VMID 的格式应当是：[protocol:][//] lvmid [@hostname[:port]/servername]\n```\n\n### **option**\n\n选项 option 代表这用户希望查询的虚拟机信息，主要分为 3 类：类装载、垃圾收集和运行期编译状况，具体选项及作用如下：\n\n- `class` 监视类装载、卸载数量、总空间及类装载所耗费的时间\n- `gc` 监视 Java 堆状况，包括 Eden 区、2 个Survivor区、老年代、永久代等的容量\n- `gccapacity` 监视内容与 -gc 基本相同，但输出主要关注 Java 堆各个区域使用到的最大和最小空间\n- `gcutil` 监视内容与 -gc 基本相同，但输出主要关注已使用空间占总空间的百分比\n- `gccause` 与 -gcutil 功能一样，但是会额外输出导致上一次 GC 产生的原因\n- `gcnew` 监视新生代 GC 的状况\n- `gcnewcapacity`监视内容与 -gcnew 基本相同，输出主要关注使用到的最大和最小空间\n- `gcold` 监视老年代 GC 的状况\n- `gcoldcapacity` 监视内容与 -gcold 基本相同，输出主要关注使用到的最大和最小空间\n- `gcpermcapacity` 输出永久代使用到的最大和最小空间\n- `compiler` 输出 JIT 编译器编译过的方法、耗时等信息\n- `printcompilation` 输出已经被 JIT 编译的方法\n\n## **常见术语**\n\n**1、`jstat –class<pid> :` 显示加载 class 的数量，及所占空间等信息。**\n\n> `Loaded` 装载的类的数量\n`Bytes` 装载类所占用的字节数 \n`Unloaded` 卸载类的数量 \n`Bytes` 卸载类的字节数 \n`Time` 装载和卸载类所花费的时间\n> \n\n**2、`jstat -compiler <pid>`显示 VM 实时编译的数量等信息。**\n\n> `Compiled` 编译任务执行数量 \n`Failed` 编译任务执行失败数量 \n`Invalid` 编译任务执行失效数量 \n`Time` 编译任务消耗时间 \n`FailedType` 最后一个编译失败任务的类型 \n`FailedMethod` 最后一个编译失败任务所在的类及方法\n> \n\n**3、`jstat -gc <pid>`: 可以显示 gc 的信息，查看 gc 的次数，及时间。**\n\n> `S0C` 年轻代中第一个 survivor（幸存区）的容量 （字节）\n`S1C` 年轻代中第二个 survivor（幸存区）的容量 （字节）\n`S0U` 年轻代中第一个 survivor（幸存区）目前已使用空间（字节）\n`S1U` 年轻代中第二个 survivor（幸存区）目前已使用空间（字节）\n`EC` 年轻代中 Eden（伊甸园）的容量（字节）\n`EU` 年轻代中 Eden（伊甸园）目前已使用空间（字节）\n`OC` Old 代的容量（字节）\n`OU` Old 代目前已使用空间（字节）\n`PC` Perm（持久代）的容量（字节） \n`PU` Perm（持久代）目前已使用空间（字节）\n`YGC` 从应用程序启动到采样时年轻代中 gc 次数\n`YGCT` 从应用程序启动到采样时年轻代中 gc 所用时间（s）\n`FGC` 从应用程序启动到采样时 old 代（全 gc）gc 次数\n`FGCT` 从应用程序启动到采样时 old 代（全 gc）gc 所用时间（s）\n`GCT` 从应用程序启动到采样时 gc 用的总时间（s）\n> \n\n**4、`jstat -gccapacity <pid>:`可以显示，VM内存中三代（young,old,perm）对象的使用和占用大小**\n\n> `NGCMN` 年轻代（young）中初始化（最小）的大小（字节） \n`NGCMX` 年轻代（young）的最大容量（字节）\n`NGC` 年轻代（young）中当前的容量（字节）\n`S0C` 年轻代中第一个 survivor（幸存区）的容量（字节） \n`S1C` 年轻代中第二个 survivor（幸存区）的容量（字节） \n`EC` 年轻代中 Eden（伊甸园）的容量（字节） \n`OGCMN` old 代中初始化（最小）的大小（字节）\n`OGCMX` old 代的最大容量（字节）\n`OGC` old代当前新生成的容量（字节）\n`OC` Old代的容量 （字节） \n`PGCMN` perm 代中初始化（最小）的大小 （字节） \n`PGCMX` perm 代的最大容量（字节）\n`PGC` perm 代当前新生成的容量（字节） \n`PC` Perm（持久代）的容量（字节） \n`YGC` 从应用程序启动到采样时年轻代中 gc 次数 \n`FGC` 从应用程序启动到采样时 old 代（全gc）gc 次数\n> \n\n**5、`jstat -gcutil <pid>`:统计gc信息**\n\n> `S0` 年轻代中第一个 survivor（幸存区）已使用的占当前容量百分比\n`S1` 年轻代中第二个 survivor（幸存区）已使用的占当前容量百分比\n`E` 年轻代中 Eden（伊甸园）已使用的占当前容量百分比\n`O` old 代已使用的占当前容量百分比 \n`P` perm 代已使用的占当前容量百分比 \n`YGC` 从应用程序启动到采样时年轻代中 gc 次数 \n`YGCT` 从应用程序启动到采样时年轻代中 gc 所用时间（s）\n`FGC` 从应用程序启动到采样时 old 代（全 gc）gc 次数 \n`FGCT` 从应用程序启动到采样时 old 代（全 gc）gc 所用时间（s） \n`GCT` 从应用程序启动到采样时 gc 用的总时间（s）\n> \n\n**6、`jstat -gcnew <pid>`:年轻代对象的信息。**\n\n> `S0C` 年轻代中第一个survivor（幸存区）的容量（字节）\n`S1C` 年轻代中第二个survivor（幸存区）的容量（字节）\n`S0U` 年轻代中第一个survivor（幸存区）目前已使用空间（字节）\n`S1U` 年轻代中第二个survivor（幸存区）目前已使用空间（字节）\n`TT` 持有次数限制\n`MTT` 最大持有次数限制\n`EC` 年轻代中 Eden（伊甸园）的容量（字节）\n`EU` 年轻代中 Eden（伊甸园）目前已使用空间（字节）\n`YGC` 从应用程序启动到采样时年轻代中 gc 次数\n`YGCT` 从应用程序启动到采样时年轻代中 gc 所用时间（s）\n> \n\n**7、`jstat -gcnewcapacity<pid>`: 年轻代对象的信息及其占用量。**\n\n> `NGCMN` 年轻代（young）中初始化（最小）的大小（字节）\n`NGCMX` 年轻代（young）的最大容量（字节）\n`NGC` 年轻代（young）中当前的容量（字节）\n`S0CMX` 年轻代中第一个 survivor（幸存区）的最大容量（字节）\n`S0C` 年轻代中第一个 survivor（幸存区）的容量（字节）\n`S1CMX` 年轻代中第二个 survivor（幸存区）的最大容量（字节）\n`S1C` 年轻代中第二个 survivor（幸存区）的容量（字节）\n`ECMX` 年轻代中 Eden（伊甸园）的最大容量（字节）\n`EC` 年轻代中 Eden（伊甸园）的容量（字节）\n`YGC` 从应用程序启动到采样时年轻代中 gc 次数\n`FGC` 从应用程序启动到采样时 old 代（全 gc）gc 次数\n> \n\n**8、`jstat -gcold <pid>：`old代对象的信息。**\n\n> `PC` Perm（持久代）的容量 （字节） \n`PU` Perm（持久代）目前已使用空间 （字节） \n`OC` Old代的容量 （字节） OU Old 代目前已使用空间 （字节） \n`YGC` 从应用程序启动到采样时年轻代中 gc 次数 \n`FGC` 从应用程序启动到采样时 old 代（全gc）gc 次数 \n`FGCT` 从应用程序启动到采样时 old 代（全gc）gc 所用时间（s） \n`GCT` 从应用程序启动到采样时 gc 用的总时间（s）\n> \n\n**9、`stat -gcoldcapacity <pid>`: old代对象的信息及其占用量。**\n\n> `OGCMN` old 代中初始化（最小）的大小 （字节）\n`OGCMX` old 代的最大容量（字节）\n`OGC` old 代当前新生成的容量 （字节）\n`OC` Old 代的容量 （字节）\n`YGC` 从应用程序启动到采样时年轻代中 gc 次数\n`FGC` 从应用程序启动到采样时 old 代（全gc）gc 次数\n`FGCT` 从应用程序启动到采样时 old 代（全gc）gc 所用时间（s）\n`GCT` 从应用程序启动到采样时 gc 用的总时间（s）\n> \n\n**10、`jstat -gcpermcapacity<pid>`: perm对象的信息及其占用量。**\n\n> `PGCMN` perm代中初始化（最小）的大小 （字节）\n`PGCMX` perm代的最大容量 （字节）\n`PGC` perm代当前新生成的容量 （字节）\n`PC` Perm（持久代）的容量 （字节）\n`YGC` 从应用程序启动到采样时年轻代中 gc 次数\n`FGC` 从应用程序启动到采样时 old 代（全gc）gc 次数\n`FGCT` 从应用程序启动到采样时 old 代（全gc）gc 所用时间（s）\n`GCT` 从应用程序启动到采样时 gc 用的总时间（s）\n> \n\n**11、`jstat -printcompilation <pid>`：当前VM执行的信息。**\n\n> `Compiled` 编译任务的数目\n`Size` 方法生成的字节码的大小\n`Type` 编译类型\n`Method` 类名和方法名用来标识编译的方法。\n类名使用/做为一个命名空间分隔符。方法名是给定类中的方法。上述格式是由-XX:+PrintComplation选项进行设置的\n>","tags":["性能测试","Java"]},{"title":"Java开发必须掌握的线上问题排查命令","url":"/2024/06/30/2024-06-30-java-kai-fa-bi-xu-zhang-wo-de-xian-shang-wen-ti-pai-cha-ming-ling/","content":"\n作为一个合格的开发人员，不仅要能写得一手代码，还要有一项很重要的技能就是排查问题。这里提到的排查问题不仅仅是在 coding 的过程中 debug 等，还包括的就是线上问题的排查。由于在生成环境中，一般没办法 debug（其实有些问题，debug 也白扯…），所以我们需要借助一些常见命令来查看运行时的具体情况，这些运行时信息包括但不限于运行日志、异常堆栈、堆使用情况、GC情况、JVM参数情况、线程情况等。\n\n给一个系统定位问题的时候，知识、经验是关键，数据是依据，工具是运用知识处理数据的手段。为了便于我们排查和解决问题，Sun 公司为我们提供了一些常用命令。这些命令一般都是 jdk/lib/tools.jar 中类库的一层薄包装。随着 JVM 的安装一起被安装到机器中，在 bin 目录中。下面就来认识一下这些命令以及具体使用方式。\n\n## JPS\n\n**功能：**显示当前所有 java 进程 pid 的命令。\n\n**常见指令：**\n\n`jps`：显示当前用户的所有java进程的PID\n\n`jps -v 3331`：显示虚拟机参数\n\n`jps -m 3331`：显示传递给 main() 函数的参数\n\n`jps -l 3331`：显示主类的全路径\n\n## jinfo\n\n**功能：**实时查看和调整虚拟机参数，可以显示未被显示指定的参数的默认值（jps  -v 则不能）\n\n> jdk8 中已经不支持该命令\n> \n\n**常用指令：**\n\n`jinfo -flag CMSIniniatingOccupancyFration 1444`：查询 CMSIniniatingOccupancyFration 参数值\n\n## jstat\n\n**功能：**显示进程中的类加载、内存、垃圾收集、JIT 编译等运行数据。\n\n**常用指令：**\n\n`jstat -gc 3331 250 20` ：查询进程2764的垃圾收集情况，每250毫秒查询一次，一共查询20次。\n\n`jstat -gccause`：额外输出上次GC原因\n\n`jstat -calss`：件事类装载、类卸载、总空间以及所消耗的时间\n\n## jmap\n\n**功能：**生成堆准储快照（heapdump）\n\n**常用指令：**\n\n`jmap -heap 3331`：查看java 堆（heap）使用情况\n\n`jmap -histo 3331`：查看堆内存（histogram）中的对象数量及大小\n\n`jmap -histo:live 3331`：JVM 会先触发 gc，然后再统计信息\n\n`jmap -dump:format=b,file=heapDump 3331`：将内存使用的详细情况输出到文件，之后一般使用其他工具进行分析。\n\n## **jhat**\n\n**功能：**一般与 jmap 搭配使用，用来分析 jmap 生成的堆转储文件。\n\n> 由于有很多可视化工具（Eclipse Memory Analyzer 、IBM HeapAnalyzer）可以替代，所以很少用。不过在没有可视化工具的机器上也是可用的。\n> \n\n**常用指令：**\n\n`jmap -dump:format=b,file=heapDump 3331` + `jhat heapDump`：解析 Java 堆转储文件，并启动一个 web server\n\n## **jstack**\n\n**功能：**生成当前时刻的线程快照。\n\n**常用指令：**\n\n`jstack 3331`：查看线程情况\n\n`jstack -F 3331`：正常输出不被响应时，使用该指令\n\n`jstack -l 3331`：除堆栈外，显示关于锁的附件信息\n\n# 常见问题定位过程\n\n## 频繁 GC 问题或内存溢出问题\n\n1. 使用 `jps` 查看线程 ID\n2. 使用 `jstat -gc xxx 250 20` 查看 gc 情况，一般比较关注 PERM 区的情况，查看 GC 的增长情况。\n3. 使用 `jstat -gccause` 额外输出上次 GC 原因\n4. 使用 `jmap -dump:format=b,file=heapDump xxx`  生成堆转储文件\n5. 使用 jhat 或者可视化工具（Eclipse Memory Analyzer 、IBM HeapAnalyzer）分析堆情况。\n6. 结合代码解决内存溢出或泄露问题。\n\n## **死锁问题**\n\n1. 使用`jps`查看线程 ID，转换为 16 进制\n    \n    ```python\n    printf %x 线程号\n    ```\n    \n2. 使用`jstack xxx`：查看线程情况\n\n# **结语**\n\n经常使用适当的虚拟机监控和分析工具可以加快我们分析数据、定位解决问题的速度，但也要知道，工具永远都是知识技能的一层包装，没有什么工具是包治百病的。\n\n[**Java命令学习系列（一）— Jps**](https://wu3227834.github.io/2024/06/29/2026-06-30-java-ming-ling-xue-xi-xi-lie-yi-jps/)\n\n[**Java命令学习系列（二）— Jstack**](https://wu3227834.github.io/2024/06/29/2026-06-30-java-ming-ling-xue-xi-xi-lie-er-jstack/)\n\n[**Java命令学习系列（三）— Jmap**](https://wu3227834.github.io/2024/06/29/2026-06-30-java-ming-ling-xue-xi-xi-lie-san-jmap/)\n\n[**Java命令学习系列（四）— Jstat**](https://wu3227834.github.io/2024/06/29/2026-06-30-java-ming-ling-xue-xi-xi-lie-si-jstat/)\n\n[**Java命令学习系列（五）— Jhat**](https://www.notion.so/Java-Jhat-e4da5c23fe34484093bcd8607fd14d07?pvs=21)","tags":["性能测试","Java"]},{"title":"性能测试——火焰图进阶","url":"/2024/04/22/2024-04-22-flamegraph/","content":"\n当程序出现性能瓶颈时，我们通常通过表象（比如请求某个接口时 CPU 使用率飙涨）然后结合代码去推测可能出问题的地方，却不知道问题到底是什么引起的。如果有个一可视化的工具直观地展现程序的性能瓶颈就好了，幸好 [Brendan D. Gregg](/img/2024-04-22-FlameGraph/http://www.brendangregg.com/) 发明了火焰图。\n\n[火焰图](/img/2024-04-22-FlameGraph/http://www.brendangregg.com/flamegraphs.html)（Flame Graph）看起来就像一团跳动的火焰，因此得名。火焰图可以将 CPU 的使用情况可视化，使我们直观地了解到程序的性能瓶颈，通常要结合操作系统的性能分析工具（profiling tracer）使用，常见的操作系统的性能分析工具如下：\n\n- Linux：perf, eBPF, SystemTap, and ktap。\n- Solaris, illumos, FreeBSD：DTrace。\n- Mac OS X：DTrace and Instruments。\n- Windows：Xperf.exe。\n\n## 1.1.1 perf\n\n[perf_events](/img/2024-04-22-FlameGraph/http://www.brendangregg.com/linuxperf.html)（简称 perf）是 Linux Kernal 自带的系统性能分析工具，能够进行函数级与指令级的热点查找。它基于事件采样原理，以性能事件为基础，支持针对处理器相关性能指标与操作系统相关性能指标的性能剖析，常用于查找性能瓶颈及定位热点代码。\n\n测试机器：\n\n```sh\n$ uname -a\nLinux nswbmw-VirtualBox 4.10.0-28-generic #32~16.04.2-Ubuntu SMP Thu Jul 20 10:19:48 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n```\n\n**注意**：非 Linux 用户需要用虚拟机安装 Ubuntu 16.04 和 node@8.9.4 后进行后面的操作。\n\n安装 perf：\n\n```sh\n$ sudo apt install linux-tools-common\n$ perf # 根据提示安装对应的内核版本的 tools, 如下\n$ sudo apt install linux-tools-4.10.0-28-generic linux-cloud-tools-4.10.0-28-generic\n```\n\n创建测试目录 ~/test 和测试代码：\n\n**app.js**\n\n```js\nconst crypto = require('crypto')\nconst Paloma = require('paloma')\nconst app = new Paloma()\nconst users = {}\n\napp.route({ method: 'GET', path: '/newUser', controller (ctx) {\n  const username = ctx.query.username || 'test'\n  const password = ctx.query.password || 'test'\n\n  const salt = crypto.randomBytes(128).toString('base64')\n  const hash = crypto.pbkdf2Sync(password, salt, 10000, 64, 'sha512').toString('hex')\n\n  users[username] = { salt, hash }\n\n  ctx.status = 204\n}})\n\napp.route({ method: 'GET', path: '/auth', controller (ctx) {\n  const username = ctx.query.username || 'test'\n  const password = ctx.query.password || 'test'\n\n  if (!users[username]) {\n    ctx.throw(400)\n  }\n  const hash = crypto.pbkdf2Sync(password, users[username].salt, 10000, 64, 'sha512').toString('hex')\n\n  if (users[username].hash === hash) {\n    ctx.status = 204\n  } else {\n    ctx.throw(403)\n  }\n}})\n \napp.listen(3000)\n```\n\n添加 --perf_basic_prof（或者 --perf-basic-prof）参数运行此程序，会对应生成一个 /tmp/perf-\\<PID\\>.map 的文件。命令如下：\n\n```sh\n$ node --perf_basic_prof app.js &\n[1] 3590\n$ tail /tmp/perf-3590.map\n51b87a7b93e 18 Function:~emitListeningNT net.js:1375\n51b87a7b93e 18 LazyCompile:~emitListeningNT net.js:1375\n51b87a7bad6 39 Function:~emitAfterScript async_hooks.js:443\n51b87a7bad6 39 LazyCompile:~emitAfterScript async_hooks.js:443\n51b87a7bcbe 77 Function:~tickDone internal/process/next_tick.js:88\n51b87a7bcbe 77 LazyCompile:~tickDone internal/process/next_tick.js:88\n51b87a7bf36 12 Function:~clear internal/process/next_tick.js:42\n51b87a7bf36 12 LazyCompile:~clear internal/process/next_tick.js:42\n51b87a7c126 b8 Function:~emitPendingUnhandledRejections internal/process/promises.js:86\n51b87a7c126 b8 LazyCompile:~emitPendingUnhandledRejections internal/process/promises.js:86\n```\n\n**map 文件内容三列依次为**：16进制的符号地址（symbol addresses）、大小（sizes）和符号名（symbol names）。perf 会尝试查找 /tmp/perf-\\<PID\\>.map 文件，用来做符号转换，即把 16 进制的符号地址转换成人能读懂的符号名。\n\n**注意**：使用 --perf_basic_prof_only_functions 参数也可以，但经尝试后发现生成的火焰图信息不全（不全的地方显示 [perf-\\<PID\\>.map]），所以这里使用 --perf_basic_prof。但是，使用 --perf_basic_prof  有个缺点，就是会导致 map 文件一直增大，这是由于符号（symbols）地址不断变换导致的，用 --perf_basic_prof_only_functions 可以缓解这个问题。关于如何取舍，还请读者自行尝试。\n\n接下来 clone 用来生成火焰图的工具：\n\n```sh\n$ git clone http://github.com/brendangregg/FlameGraph ~/FlameGraph\n```\n\n我们先用 ab 压测：\n\n```sh\n$ curl \"http://localhost:3000/newUser?username=admin&password=123456\"\n$ ab -k -c 10 -n 2000 \"http://localhost:3000/auth?username=admin&password=123456\"\n```\n\n新开另一个终端，在 ab 开始压测后立即运行：\n\n```sh\n$ sudo perf record -F 99 -p 3590 -g -- sleep 30\n$ sudo chown root /tmp/perf-3590.map\n$ sudo perf script > perf.stacks\n$ ~/FlameGraph/stackcollapse-perf.pl --kernel < ~/perf.stacks | ~/FlameGraph/flamegraph.pl --color=js --hash> ~/flamegraph.svg\n```\n\n**注意**：第 1 次生成的 svg 可能不太准确，最好重复几次以上步骤，使用第 2 次及以后生成的 flamegraph.svg。\n\n有几点需要解释一下：\n\n- perf record\n  - -F 指定了采样频率 99Hz（即每秒 99 次，如果 99 次都返回同一个函数名，那就说明 CPU 在这一秒钟都在执行同一个函数，可能存在性能问题）。\n  - -p 指定进程的 pid。\n  - -g 启用 call-graph 记录。\n  - -- sleep 30 指定记录 30s。\n\n- sudo chown root /tmp/perf-3009.map，将 map 文件更改为 root 权限，否则会报如下错误：\n\n  > File /tmp/perf-PID.map not owned by current user or root, ignoring it (use -f to override).\n  > Failed to open /tmp/perf-PID.map, continuing without symbols\n\n- perf record 会将记录的信息保存到当前执行目录的 perf.data 文件中，然后使用 perf script 读取 perf.data 的 trace 信息写入 perf.stacks。\n\n- --color=js 指定生成针对 JavaScript 配色的 svg，即：\n\n  - green：JavaScript。\n  - blue：Builtin。\n  - yellow：C++。\n  - red：System（native user-level, and kernel）。\n\nab 压测用了 30s 左右，用浏览器打开 flamegraph.svg，截取关键的部分如下图所示：\n\n![flamegraph1.svg](/img/2024-04-22-FlameGraph/1.1.1.png)\n\n## 1.1.2 理解火焰图\n\n火焰图含义：\n\n- 每一个小块代表了一个函数在栈中的位置（即一个栈帧）。\n- Y 轴代表栈的深度（栈上的帧数），顶端的小块显示了占据 CPU 的函数。每个小块的下面是它的祖先（即父函数）。\n- X 轴代表总的样例群体。它不像绝大多数图表那样从左到右表示时间的流逝，其左右顺序没有特殊含义，仅仅按照字母表的顺序排列。\n- 小块的宽度代表 CPU 的使用时间，或者说相对于父函数而言使用 CPU 的比例（基于所有样例），越宽则代表占用 CPU 的时间越长，或者使用 CPU 很频繁。\n- 如果采取多线程并发运行取样，则取样数量会超过运行时间。\n\n**从上图可以看出**：最上面的绿色小块（即 JavaScript 代码）指向 test/app.js 第 18 行，即 `GET /auth` 这个路由。再往上看，黄色的小块（即 C++ 代码） node::crypto::PBKDF2 占用了大量的 CPU 时间。\n\n**解决方法**：将同步改为异步，即将 crypto.pbkdf2Sync 改为 crypto.pbkdf2。修改如下：\n\n```js\napp.route({ method: 'GET', path: '/auth', async controller (ctx) {\n  const username = ctx.query.username || 'test'\n  const password = ctx.query.password || 'test'\n\n  if (!users[username]) {\n    ctx.throw(400)\n  }\n  const hash = await new Promise((resolve, reject) => {\n    crypto.pbkdf2(password, users[username].salt, 10000, 64, 'sha512', (err, derivedKey) => {\n      if (err) {\n        return reject(err)\n      }\n      resolve(derivedKey.toString('hex'))\n    })\n  })\n\n  if (users[username].hash === hash) {\n    ctx.status = 204\n  } else {\n    ctx.throw(403)\n  }\n}})\n```\n\n用 ab 重新压测，结果用了 16s。重新生成的火焰图如下：\n\n![flamegraph2.svg](/img/2024-04-22-FlameGraph/1.1.2.png)\n\n**可以看出**：只有在左侧极窄的绿色小块可以看到 JavaScript 代码，红色的部分我们不关心也无法优化。那么，为什么异步比同步的 QPS 要高呢？原因是 Node.js 底层的 libuv 用了多个线程进行计算，这里就不再深入介绍了。\n\nsvg 火焰图的其他小技巧如下：\n\n1. 单击任意一个小块即可展开，即被单击的小块宽度变宽，它的子函数也按比例变宽，方便查看。\n2. 可单击 svg 右上角的 search 按钮进行搜索，被搜索的关键词会高亮显示，在有目的地查找某个函数时比较有用。\n\n## 1.1.3 红蓝差分火焰图\n\n虽然我们有了火焰图，但要处理性能回退问题，还需要在修改代码前后的火焰图之间，不断切换和对比，来找出问题所在，很不方便。于是 [Brendan D. Gregg](/img/2024-04-22-FlameGraph/http://www.brendangregg.com/index.html) 又发明了红蓝差分火焰图（Red/Blue Differential Flame Graphs）。\n\n**如下所示**：红色表示增长，蓝色表示衰减。\n\n![flamegraph3.svg](/img/2024-04-22-FlameGraph/1.1.3.png)\n\n红蓝差分火焰图的工作原理如下：\n\n1. 抓取修改前的栈 profile1 文件。\n2. 抓取修改后的栈 profile2 文件。\n3. 使用 profile2 来生成火焰图，这样栈帧的宽度就是以 profile2 文件为基准的。\n4. 使用 profile2 - profile1 的差异来对火焰图重新上色。上色的原则是：如果栈帧在 profile2 中出现出现的次数更多，则标为红色，否则标为蓝色。色彩是根据修改前后的差异来填充的。\n\n这样，通过红蓝差分火焰图，我们就可以清楚地看到系统性能的差异之处。\n\n生成红蓝差分火焰图的流程如下：\n\n1. 修改代码前运行：\n\n   ```sh\n   $ sudo perf record -F 99 -p <PID> -g -- sleep 30\n   $ sudo chown root /tmp/perf-<PID>.map\n   $ sudo perf script > perf_before.stacks\n   ```\n\n2. 修改代码后运行：\n\n   ```sh\n   $ sudo perf record -F 99 -p <PID> -g -- sleep 30\n   $ sudo chown root /tmp/perf-<PID>.map\n   $ sudo perf script > perf_after.stacks\n   ```\n\n3. 将 profile 文件进行折叠（fold），然后生成差分火焰图：\n\n   ```sh\n   $ ~/FlameGraph/stackcollapse-perf.pl ~/perf_before.stacks > perf_before.folded\n   $ ~/FlameGraph/stackcollapse-perf.pl ~/perf_after.stacks > perf_after.folded\n   $ ./FlameGraph/difffolded.pl perf_before.folded perf_after.folded | ./FlameGraph/flamegraph.pl > flamegraph_diff.svg\n   ```\n\n**如上缺点是**：如果一个代码执行路径完全消失了，那么在火焰图中就找不到地方来标注蓝色，我们只能看到当前的 CPU 使用情况，却不知道为什么会变成这样。\n\n一种解决办法是：生成一个相反的差分火焰图，即基于 profile1 生成 profile1 - profile2 的差分火焰图。对应命令如下：\n\n```sh\n$ ./FlameGraph/difffolded.pl perf_after.folded perf_before.folded | ./FlameGraph/flamegraph.pl --negate > flamegraph_diff2.svg\n```\n\n其中，--negate 用于颠倒红/蓝配色。最终我们得到：\n\n- flamegraph_diff.svg：宽度是以修改前的 profile 文件为基准，颜色表明将要发生的情况。\n- flamegraph_diff2.svg：宽度是以修改后的 profile 文件为基准，颜色表明已经发生的情况。\n\n总之，红蓝差分火焰图可能只在代码变化不大的情况下使用时效果明显，在代码变化较大的情况下使用时效果可能就不明显了。\n\n## 1.1.4 参考链接\n\n- https://lidaohang.gitbooks.io/quick_location/content/huo-yan-tu/cpuji-bie-huo-yan-tu/hong-lan-cha-fen-huo-yan-tu.html\n- https://yunong.io/2015/11/23/generating-node-js-flame-graphs/\n- http://www.brendangregg.com/perf.html\n- http://www.brendangregg.com/blog/2014-09-17/node-flame-graphs-on-linux.html\n- https://linux.cn/article-4670-1.html\n- http://www.brendangregg.com/blog/2014-11-09/differential-flame-graphs.html\n- http://www.ruanyifeng.com/blog/2017/09/flame-graph.html\n","tags":["性能测试","Perf","火焰图"]},{"title":"Linux 性能调优基础：top","url":"/2024/04/07/2024-04-07-linux-tracing-basis/","content":"\ntop 命令是 linux 下常用的性能分析工具，能够实时显示系统中各个进程的资源占用使用情况，类似于 windos 的任务窗口。\n\n## top 理论\n\n```shell\n#top - 16:55:39 up 220 days,  1:16,  4 users,  load average: 299.05, 217.84, 106.90\nTasks: 3355 total,  12 running, 3339 sleeping,   3 stopped,   1 zombie\n%Cpu(s): 40.7 us, 38.9 sy,  0.0 ni,  0.1 id,  0.0 wa, 20.1 hi,  0.2 si,  0.0 st\nMiB Mem : 257336.1 total,  17260.1 free,  77063.5 used, 163012.4 buff/cache\nMiB Swap:  32768.0 total,  19075.1 free,  13692.9 used.  42491.5 avail Mem\n\n    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND\n```\n\n统计信息区前五行是系统整体的统计信息。第一行是任务队列信息，同 uptime 命令的执行结果。其内容如下：\n\n|内容|解释|\n|--|--|\n|16:55:39|当前时间|\n|up 220 days|系统运行时间|\n|4 users|当前登录用户数|\n|load average: 299.05, 217.84, 106.90|系统负载，即任务队列平均长度。分别为 1、5、15 min 前到现在平均值|\n\n第二、三行为进程和 CPU 的信息。当有多个 CPU 时，这些内容可能会超过两行。内容如下：\n\n|内容|解释|\n|--|--|\n|Tasks: 3355 total|进程总数[键入 H 可查看线程数]|\n|12 running, 3339 sleeping, 3 stopped|正在运行的进程、睡眠进程、停止的进程|\n|1 zombie|僵尸进程数|\n|%Cpu(s): 40.7 us, 38.9 sy|用户空间占用 CPU 百分比、内核空间占用 CPU 百分比|\n|0.0 ni, 0.1 id|用户进程空间内改变进程优先级占用 CPU、空闲 CPU 百分比|\n|0.0 wa, 20.1 hi, 0.2 si, 0.0 st|等待 IO 的 CPU 时间百分比，最后三个是中断请求相关|\n\n倒数第二、三行为内存相关信息：\n\n|内容|解释|\n|--|--|\n|MiB Mem|表示系统内存的使用情况|\n|MiB Swap|表示交换空间（虚拟内存）的使用情况|\n|xxx total, xxx free, xxx used|分别是内存总量、空闲内存总量、使用内存总量|\n|xxx buff/cache|被用作缓冲或缓存的内存量|\n|xxx avail Mem|可用的交换空间|\n\n- buffe [Difference between buffer and cache](http://wiki.answers.com/Q/Difference_between_buffer_and_cache)\n\n>由硬件设备或程序共享的数据区域称为缓冲区。它们以不同的速度运行，或者有不同的优先顺序。缓冲区允许每个设备或进程在没有其他设备或进程阻碍的情况下运行。为了使缓冲区有效，缓冲区设计器需要考虑缓冲区的大小。与缓存一样，缓冲区是一个“中点保存位置”，但它的存在并不是为了加快活动的速度，而是为了支持单独活动的协调。\n\n>这个术语不仅用于编程，也用于硬件。在编程中，缓冲有时需要从数据的最终预期位置筛选数据，以便在移动到常规文件或数据库之前对数据进行编辑或处理。\n\n- cached\n\n>高速缓冲存储器是随机存取存储器（RAM）的一种。计算机微处理器对高速缓冲存储器的访问速度比普通 RAM 的访问速度更快。就像微处理器处理数据一样，它首先在高速缓冲存储器中查找，如果在那里，它会从之前读取的数据中找到数据，它不需要从更大的内存中进行更耗时的数据读取。\n\n>有时，高速缓冲存储器是按照与微处理器的接近程度和便利程度来描述的。L1 高速缓存与微处理器位于同一芯片上。\n\n>除了高速缓存之外，RAM 本身也是一种用于硬盘存储的高速缓存，因为当你打开计算机并加载正在加载的操作系统时，所有 RAM 的内容都会先到达硬盘，稍后当你启动新应用程序并访问新数据。RAM 还包含一个称为磁盘缓存的特殊区域，该区域由最近从硬盘读取的数据组成。\n\n最后 1 行则是进程相关的资源占用信息:\n\n- PID：进程ID。系统中每个进程都有一个唯一的ID号，称为进程ID。\n- USER：进程的拥有者。显示启动这个进程的用户名称。\n- PR：进程的优先级。内核根据这个值来决定进程的执行优先级。\n- NI：进程的nice值。这是一个用户控制的为进程设置的优先级的值。数值可从-20（最高优先级）到19（最低优先级）。\n- VIRT：虚拟内存使用量。进程使用的所有虚拟内存的和，包括进程使用的库，以及映射的文件和交换空间的大小。\n- RES：常驻内存大小。这是进程当前使用的、未被调出的物理内存量，单位通常是KB。\n- SHR：共享内存大小。这是多个进程可能共享的内存部分，通常包括库等。\n- S：进程的状态。通常的状态有：\n  - S（睡眠中）：等待事件完成（如输入/输出完成）。\n  - R（运行中）：正在运行或在运行队列中等待。\n  - T（停止）：进程已停止执行。\n  - Z（僵尸）：进程已终止，但其父进程尚未收到其终止状态。\n- %CPU：CPU使用率。展示进程使用的CPU时间百分比，这个值是在最后一次更新的时候样本里CPU使用情况的近似值，可能超过100%在多核CPU的系统。\n- %MEM：内存使用率。该进程使用的物理内存和总物理内存的百分比。\n- TIME+：进程使用的CPU时间总计，格式通常为分钟:秒。\n- COMMAND：启动进程的命令名称。\n\n## top 技巧\n\n终端执行 top 命令之后【也可后接一些选项，比如 top -p 1 只监控 init 进程，top -u root 只显示 root 运行进程等等】，可以敲击如下按键，实现不同功能：\n\n- h：获取 top 的命令帮助\n- 1（数字1）：列出所有的单个 CPU 负载情况\n- z：top 显示颜色\n  - x：类似高亮显示，在 z 模式下使用\n- P[大写]：按 CPU 占用高低顺序列出程序\n- M[大写]：按内存占用高低顺序列出程序\n- c：显示进程命令的全路径与参数\n- H：显示线程，默认只显示进程\n- top 默认按 cpu 占用排序，按F（大写）即可选择相应排序\n- d：top 默认刷新时间是 3s ，使用d键可自定义刷新时间\n- top 选择列排序[高到低]的方法[在z颜色和x高亮模式下显示效果明显]：\n  - shift+<：左选\n  - shift+>：右选\n- f：可以指定 top 显示的内容，如 ppid、swap 等都可以选择显示\n  - 显示 Swap 利用率：按 f 键，然后按 p 键，回车即可看到 Swap 状态\n- k：输入 k 之后可以 kill 掉指定的进程\n- A：分类显示各种系统资源高的进程。可用于快速识别系统上的性能要求极高的任务，推荐使用\n- W[大写]:将当前设置写入 ~/.toprc 文件中。这是写 top 配置文件的推荐方法\n\n## 参考\n\n- [SourceWiki-性能调优-top.md](https://github.com/linuxwiki/SourceWiki/blob/master/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/top.md)\n- [鸟哥Linux私房菜](http://linux.vbird.org/) \n- [top - Process Activity Command](http://www.cyberciti.biz/tips/top-linux-monitoring-tools.html)\n- [Learning Linux Commands: top](http://how-to.linuxcareer.com/learning-linux-commands-top)","tags":["Linux","性能测试"]},{"title":"量化索引：Product Quantization 乘积量化","url":"/2024/04/01/2024-04-01-product-quantization/","content":"\n## 引言\n\nProduct Quantization，国内有人直译为乘积量化，这里的乘积量化是指笛卡尔积（Cartesian product），意思是指把原先的向量空间分解为若干个低维向量空间的笛卡尔积，并对分解得到的低纬向量空间的分别做量化（quantization）。这样每个向量就能由多个低纬空间的量化 code 组合表示。为简洁描述起见，下文用 PQ 作为 Product Quantization 的简称。\n\n> The idea is to decomposes the space into a Cartesian product of low dimensional subspaces and to quantize each subspace separately. A vector is represented by a short code composed of its subspace quantization indices.\n\n近几年，深度学习技术被广泛用于图像识别、语音识别、自然语言处理等领域，能够把每个实体（图像、语音、文本）转换为对应的 embedding 向量。一般来说，相似的实体转换得到的 embedding 向量也是相似的。对于相似搜索问题，最简单的想法是暴力穷举法，如果全部实体的个数是 N，N 是千万量级甚至是上亿的规模，每个实体对应的向量是 D，那么当要从这个实体集合中寻找某个实体的相似实体，暴力穷举的计算复杂度是 O(ND)，这是一个非常大的计算量，该方法显然不可取。所以对大数据量下高维度数据的相似搜索场景，我们就需要一些高效的相似搜索技术，而 PQ 就是其中一类方法。\n\n## Product Quantization\n\n### 定义\n\nProduct Quantization 是将每个数据集向量转换为短内存高效表示（称为 PQ 代码）的过程。不是完全保留所有向量，而是存储它们的简短表示。同时，PQ 是一种有损压缩算法，预测精度较低，但在实际应用中效果还不错。\n\n>In general, quantization is the process of mapping infinite values to discrete ones.\n\n### 训练\n\n首先，该算法将每个向量划分为几个相等的部分——子向量。所有数据集向量的各个部分形成独立的子空间，并分别进行处理。然后对向量的每个子空间执行聚类算法。通过这样做，在每个子空间中创建了几个质心。每个子向量都使用它所属质心的 ID 进行编码。此外，存储所有质心的坐标以供以后使用。\n\n>Subspace centroids are also called quantized vectors.\nIn product quantization, a cluster ID is often referred to as a reproduction value.\n\n注意: 在下图中，一个矩形表示一个包含多个值的向量，而一个正方形表示一个数字。\n\n![量化编码](/img/2024-04-01-Product_Quantization/pho1.jpg)\n\n因此，如果一个原始向量被分成 n 个部分，那么它就可以用 n 个数字进行编码——每个子向量的各个质心的 ID。通常，为了更有效地使用内存，创建的质心 k 的数目通常被选为 2 的幂。这样，存储编码向量所需的内存是 n * log(k) bits。\n\n>The collection of all centroids inside a subspace is called a codebook. Running n clustering algorithms for all subspaces produces n separate codebooks.\n\n### 压缩示例\n\n设想一个大小为 1024 的存储浮点数（32bits）的原始向量被分成 n = 8 个子向量，其中每个子向量由 k = 256 个簇中的一个进行编码。因此，编码单个集群的 ID 将需要 $\\log_2 256=8 bits$。让我们比较两种情况下向量表示的内存大小:\n\n- 原始向量: 1024 * 32 bits = 4096 bytes\n- 编码向量: 8 * 8 bits = 8 bytes\n\n最终的压缩是 512 倍! 这是产品量化的真正威力。\n\n![压缩示例：向量中的数字显示它存储了多少个数字](/img/2024-04-01-Product_Quantization/pho2.jpg)\n\n以下是一些重要的注意事项：\n\n- 该算法可以在一个向量子集上进行训练（例如，创建聚类），并用于另一个向量子集：训练完算法后，将传递另一个向量数据集，然后使用每个子空间已构造的质心对新向量进行编码。\n- 通常，选择 k-means 作为聚类算法。它的优点之一是集群的数量 k 是一个超参数，可以根据内存使用需求手动定义。\n\n### 推理\n\n为了更好地理解，让我们首先看看几种朴素方法，并找出它们的缺点。这也将帮助我们认识到为什么它们不应该被正常使用。\n\n#### 朴素方案\n\n第一种朴素的方法包括通过连接每个向量相应的质心来解压缩所有向量。之后，可以计算从查询向量到所有数据集向量的 L2 距离（或其他度量）。显然，这种方法是可行的，但是非常耗时，因为要对高维解压向量进行暴力搜索和距离计算。\n\n另一种可能的方式是将查询向量分割成子向量，并基于其 PQ 码计算从每个查询子向量到数据库向量的各个量化向量的距离之和。因此，这里再次使用了暴力搜索技术，并且距离计算仍然需要原始向量维数的线性时间，就像前面的情况一样。\n\n![计算近似距离，以欧几里得度量为例](/img/2024-04-01-Product_Quantization/pho3.jpg)\n\n另一种可能的方法是将查询向量编码成 PQ 码。然后这个 PQ 码被直接用来计算到所有其他 PQ 码的距离。将距离最短的数据集向量与相应的 PQ 码作为查询的最近邻。这种方法比前两种方法更快，因为它总是计算低维 PQ 码之间的距离。然而，PQ 码是由群集 ID 组成的，这种群集 ID 没有多少语义意义，可以看作是一个明确用作实变量的范畴变量。显然，这是一个不好的做法，这种方法可能会导致预测质量差。\n\n#### 最佳方案\n\n查询向量被划分为子向量。对于每个子向量，计算到相应子空间的所有质心的距离。最终，该信息存储在表 d 中。\n\n![获取存储部分查询子向量到质心距离的表 d](/img/2024-04-01-Product_Quantization/pho4.jpg)\n\n>Calculated subvector-to-centroid distances are often referred to as partial distances.\n\n通过使用这个子向量到质心距离表 d，可以很容易地通过其 PQ 码获得从查询到任何数据库向量的近似距离:\n\n1. 对于数据库向量的每个子向量，找到最近的质心 j (通过使用来自 PQ 码的映射值) ，并获得从该质心到查询子向量 i（通过使用计算的矩阵 d）的偏距（partial distance） d[i][j]。\n2. 所有的偏距均被平方并求和。通过对该值求平方根，即可获得近似的欧氏距离。如果您还想知道如何获得其他度量的近似结果，请导航到“其他距离度量的近似值”部分。\n\n![利用 PQ 码和距离表计算查询到数据库向量的距离](/img/2024-04-01-Product_Quantization/pho5.jpg)\n\n>Using this method for calculating approximate distances assumes that partial distances d are very close to actual distances a between query and database subvectors.\n\n然而，这个条件可能不被满足，特别是当数据库子向量与其质心之间的距离 c 很大时。在这种情况下，计算会导致精度降低。\n\n![左边的例子展示了当实际距离非常接近偏距（c 很小）时的一个很好的近似情况。在右边，我们可以观察到一个糟糕的场景，因为偏距比实际距离长得多（c 很大）。](/img/2024-04-01-Product_Quantization/pho6.jpg)\n\n在获得所有数据库行的近似距离后，我们搜索具有最小值的向量。这些向量将是查询的最近邻。\n\n#### 其他距离度量的近似\n\n到目前为止，我们已经研究了如何通过使用偏距来近似欧几里得度量。让我们将这个规则推广到其他度量标准。\n\n想象一下我们想要计算一对向量之间的距离度量。如果我们知道度量的公式，我们可以直接应用它来得到结果。但是有时候我们可以通过以下方式分部分的做：\n\n- 两个向量被分成 n 个子向量\n- 对于每对各自的子向量，计算距离度量\n- 然后将计算出的 n 个度量结合起来生成原始向量之间的实际距离\n\n![该图显示了计算度量的两种方法。在左边，度量公式直接应用于两个向量。在右边，部分距离计算每对各自的子向量。然后使用聚合函数 h、g 和 f 对它们进行组合。](/img/2024-04-01-Product_Quantization/pho7.jpg)\n\n欧几里得度量是一个可以按部分计算的度量标准的例子。根据上图，我们可以选择聚合函数 $h(z)=z^2$，$g(z_0,z_1...,z_n)=sum(z_0,z_1,...,z_n)$ 和 $f(z)=\\sqrt{z}$。\n\n![欧几里得度量可按部分计算](/img/2024-04-01-Product_Quantization/pho8.jpg)\n\n内积是这种度量的另一个例子，其聚合函数 $h(z)=z$，$g(z_0,z_1...,z_n)=sum(z_0,z_1,...,z_n)$ 和 $f(z)=z$。\n\n在乘积量化的背景下，这是一个非常重要的属性，因为在推理过程中，算法按部分计算距离。**这意味着，使用不具有此属性的指标进行乘积量化会出现更多问题，例如余弦距离**\n\n### 演示\n\n乘积量化的主要优点是对存储为短 PQ 码的数据库向量进行大规模压缩。对于某些应用程序，这样的压缩率甚至可能高于 95%！然而，除了 PQ 码之外，还需要存储包含各子空间量子化向量的 k×n 矩阵 d。\n\n>Product quantization is a lossy-compression method, so the higher the compression is, the more likely that the prediction accuracy will decrease.\n\n建立一个有效的表示系统需要训练多个聚类算法。除此之外，在推理过程中，k*n 的偏距需要以蛮力的方式计算，并为每个数据库向量求和，这可能需要一些时间。\n\n![Product Quantization 性能](/img/2024-04-01-Product_Quantization/pho9.jpg)\n\n#### Faiss 执行\n\n><a href=\"https://github.com/facebookresearch/faiss\">Faiss</a> (Facebook AI Search Similarity) is a Python library written in C++ used for optimised similarity search. This library presents different types of indexes which are data structures used to efficiently store the data and perform queries.\n\n基于来自 Faiss 文档的信息，我们将看到如何使用 PQ。\n\nPQ 是在 IndexPQ 类中实现的。对于初始化，我们需要提供3个参数：\n\n- d：数据维度\n- M： 每个向量的分割数（与上面使用的 n 相同的参数）\n- nbits: 编码单个集群 ID 所需的位数。这意味着一个子空间中的总簇数等于 $k = 2^{nbit}$。\n\n对于等子空间维数分裂，参数 dim 必须被 M 整除。\n\n存储单个向量所需的总字节数等于：\n\n$bytes = \\lceil \\frac {M*nbits}{8} \\rceil$\n\n>As we can see in the formula above, for more efficient memory usage the value of M * nbits should be divisible by 8.\n\n![IndexPQ 的 Faiss 实现](/img/2024-04-01-Product_Quantization/pho10.jpg)\n\n## 结论\n\n我们已经研究了一种在信息检索系统中非常流行的算法，它可以有效地压缩大量数据。其主要缺点是推理速度缓慢。尽管如此，该算法在现代大数据应用中得到了广泛应用，特别是与其他最近邻搜索技术相结合时。\n\n## 参考\n\n- <a href=\"https://vividfree.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2017/08/05/understanding-product-quantization\">理解 product quantization 算法</a>\n- <a href=\"https://towardsdatascience.com/similarity-search-product-quantization-b2a1a6397701\">Similarity Search, Part 2: Product Quantization</a>\n\n所有图像均来自 《Similarity Search, Part 2: Product Quantization》\n","tags":["向量数据库"]},{"title":"量化索引：Scalar Quantization 标量量化","url":"/2024/02/19/2024-02-19-scalar-quantization/","content":"\n>本文转载：https://yongyuan.name/blog/scalar-quantization.html\n本意为了归纳总结向量索引相关的知识，方便日后翻阅，自己做了些许的修改~\n\n## 背景\n\n在工作中遇到这样一个场景：通过多模态学习到的 64 维 video embedding，在搜索竞拍的时候，需要实时取到前 K（K>=300）个结果对应得的 video embedding，由于模型比较大，这个 video embedding，不支持实时计算，而是在视频上传时候，就被计算好。工程架构对存储和读取性能是有要求的，既不能直接将这 64 维 embedding 直接写到 kiwi（redis改造后的数据库）里面。\n\n这个问题，可以简化为：有没有一种量化方法，将一个 d 维 float 型向量，encode 为一个 d 维 int8 型的向量，这个 d 维 int8 型的向量经过 decode 后，与原始向量的误差尽可能小？这样一来，存储空间降低为原来的 1/4 倍，并且读取 int8 的性能比 float 型会快很多。答案是肯定的，这就是本篇博文要介绍总结的 Scalar Quantization。\n\nScalar Quantization，即标量量化。关于 Scalar Quantization，网上资料比较多（<a href=\"https://www.google.com.hk/search?q=Scalar+Quantization&newwindow=1&safe=strict&biw=1389&bih=766&sxsrf=ALeKk01QFkem3Lrzgoe3vrfd5uyeVr2RPQ%3A1624178770171&ei=UgDPYOjkCMWxr7wP98CqkA0&oq=Scalar+Quantization&gs_lcp=Cgdnd3Mtd2l6EAMyBwgjEOoCECcyBwgjEOoCECcyBwgjEOoCECcyBwgjEOoCECcyBwgjEOoCECcyBwgjEOoCECcyBwgjEOoCECcyBwgjEOoCECcyBwgjEOoCECcyBwgjEOoCECdQ06k-WOSrPmDwrD5oAxACeACAAckBiAHJAZIBAzItMZgBAKABAaABAqoBB2d3cy13axqwAQrAAQE&sclient=gws-wiz&ved=0ahUKEwjo1ZW16axxAhxFy4sBHxegCtIQ4dUDCBI&uact=5\">Google</a>）但小白菜在查过很多资料后，发觉能把 Scalar Quantization 向量量化过程讲清楚，并且还能剖析 faiss 中实现的 Scalar Quantization。为了方便后面的同学理解，小白菜结合自己对 Scalar Quantization 原理与实现，做了整理。\n\n## Scalar Quantization 原理\n\nScalar Quantization 标量量化，分为 3 个过程：\n\n- training 过程，主要是训练 encode 过程，需要的一些参数，这些的参数，主要是每 1 维对应的最大值、最小值；\n- encode 过程，将 float 向量量化为 int8 向量（int8 是其中一种数据压缩形式，还有 4 比特之类的，这里主要以 8 比特说明原理）\n- decode 过程，将 int8 向量解码为 float 向量；\n\n为了更好的说明 Scalar Quantization 的原理，小白菜画了 Scalar Quantization 标量量化原理框图，如下图所示：\n\n![Scalar Quantization 标量量化原理框图（copyright@yongyuan.name）](/img/2024-02-19-Scalar_Quantization/pho1.jpg)\n\n整个 Scalar Quantization 过程，其实是很容易理解的，下面对训练、编码和解码做些说明。\n\n### 训练过程\n\nScalar Quantization 训练过程，如上图最左边所示，从样本中随机采样出 N 个样本后，训练过程主要是得到 N 个样本中每 1 维的最大值、最小值。得到最大值、最小值后，将它们保存下来即可。实际在训练的时候，N 能大的时候，尽量大点。\n> N 个样本中每 1 维的最大值、最小值：如上图所示，将 64 维度向量切成 64 份，求 N 个向量，在第 i 维度的最大值、最小值。\n\n### 编码过程\n\nScalar Quantization 在编码的时候，对于一个 d 维的待编码的 float 型向量 $x=\\lbrace x_1,x_2,…,x_d \\rbrace$，编码过程主要包含如下步骤：\n\n- 对每 1 维，求 $value_i=\\frac{x_i-min_i}{max_i-min_i}$；\n- 对每 1 维，如果 $value_i<0$，则 $value_i$ 重置为 0；如果 $value_i>1$，则 $value_i$ 重置为 1。这里主要是对边界情况做异常处理，理论情况下，是不会出现$value_i<0$ 或者 $value_i>0$ 的情况；\n- 对每 1 维，对应的编码 $code_i=int(255*value_i)$。为什么 255？可以思考下；\n\n> 归一化：对于每个维度，将原始值映射到 [0, 1] 范围内\n截断：将归一化后的值截断到 [0, 1] 范围内\n量化：将截断后的值乘以 255 并进行取整，得到最终的编码值\n\"255\"：8 位整数，量化范围为 [0, 255]\n\n整个过程，如上图中的中间图所示。这样就完成了 float 型向量 $x=\\lbrace x_1,x_2,…,x_d \\rbrace$ 的编码，将向量的每 1 维，都变成了一个用 int8 表示的整型数据，也就是对应的 Scalar Quantization 的编码。\n\n### 解码过程\n\nScalar Quantization 解码过程，是解码的逆过程。解码过程步骤如下：\n\n- 对每 1 维，$x_i=min_i+\\frac{(code_i+0.5)*(max_i-min_i)}{255}$，通过该式子，即可完成对第i维的解码。留个问题：为啥 $code_i$ 需要加上 0.5？\n\n> **加 0.5 的作用是将这两种误差平均到每个取值区间内**\n例如，对于取值区间 [0, 1]，如果不对编码值加 0.5，那么所有落在该区间内的浮点型数据都会被映射到同一个离散值 0。这会导致量化误差过大。而加 0.5 后，所有落在该区间内的浮点型数据都会被映射到 0 或 1，并将量化误差平均到这两个离散值上。\n\n## Scalar Quantization 实现\n\nScalar Quantization 的训练、编码、解码实现，可以参考小白菜的实现<a href=\"https://github.com/willard-yuan/cvt/tree/master/scalar_quantization\">scalar_quantization</a>。训练过程，就是计算各维最大值、最小值，自己实现的话，具体可以看 <a href=\"https://github.com/willard-yuan/cvt/blob/master/scalar_quantization/train/src/sq_train.cpp#L68\">L68-L97</a> 。使用faiss的话，如下：\n\n```cpp\nfaiss::IndexScalarQuantizer SQuantizer(d, faiss::ScalarQuantizer::QT_8bit, faiss::METRIC_L2);\nSQuantizer.train(num_db, xb);\n// SQuantizer.add(num_db, xb);    \nfaiss::write_index(&SQuantizer, model_path.c_str());\n```\n\n在 `sq_train.cpp` 里面，对比了自己实现的训练过程结果和 faiss 训练出来的结果，训练出来的参数结果，两者是一致的。\n\nfaiss encode 的实现，如 <a href=\"https://github.com/facebookresearch/faiss/blob/master/faiss/impl/ScalarQuantizer.cpp#L328\">L328</a> 所示：\n\n```cpp\nvoid encode_vector(const float* x, uint8_t* code) const final {\n    for (size_t i = 0; i < d; i++) {\n        float xi = 0;\n        if (vdiff != 0) {\n            xi = (x[i] - vmin) / vdiff;\n            if (xi < 0) {\n                xi = 0;\n            }\n            if (xi > 1.0) {\n                xi = 1.0;\n            }\n        }\n        Codec::encode_component(xi, code, i);\n    }\n}\n```\n\n其中 vdiff = max - min。faiss decode 的实现，如 <a hef=\"https://github.com/facebookresearch/faiss/blob/master/faiss/impl/ScalarQuantizer.cpp#L344\">L344</a> 所示：\n\n```cpp\nvoid decode_vector(const uint8_t* code, float* x) const final {\n    for (size_t i = 0; i < d; i++) {\n        float xi = Codec::decode_component(code, i);\n        x[i] = vmin + xi * vdiff;\n    }\n}\n```\n\n针对小白菜 Scalar Quantization，小白菜实现的编解码过程，同时提供了 faiss 实现的接口调用，也提供了自己实现的接口调用，具体可以阅读 <a href=\"https://github.com/willard-yuan/cvtk/blob/master/scalar_quantization/scalar_quantization/int8_quan.cc\">int8_quan.cc</a>。\n\n另外，关于 Faiss 实现的 decode 接口，由于采用了多线程方式，在实际使用的时候，**当请求解码的数据量不够大的时候，多线程的方式，性能反而下降**，具体可以看这里提到的<a href=\"https://github.com/facebookresearch/faiss/issues/1530\">Issue: Scale quantization decodes does not fast</a>。","tags":["向量数据库"]},{"title":"HDF5 文件转 vecs 文件","url":"/2024/02/06/2024-02-06-hdf5-wen-jian-zhuan-vecs-wen-jian/","content":"\n## HDF5 文件的结构\n\n一个 HDF5 格式的文件是一个包含两个对象的容器，一个是**数据集**（datasets），另一个是**组**（groups）。数据集的结构非常类似于 Numpy 的 **array**，组的结构非常类似于 python 的字典，它像一个文件夹一样，它可以包含数据集和其它的组。总结起来：**组像字典一样工作，数据集像 NumPy 数组一样工作**。\n\n拿 HDF5 格式数据集 **gist-960-euclidean.hdf5** 为例（<a href=\"http://ann-benchmarks.com/gist-960-euclidean.hdf5\">下载地址</a>），整个文件有一个根组，就是下图的\"/\"。\n\n![HDF5 文件结构示意图](/img/2024-02-06-HDF5文件转vecs文件/pho1.jpg)\n\n根组下有四个键，分别为 **distances**、**neighbors**、**test** 和 **train**，类比于上图中的 A、B 和 C。\n\n- **distances** 对应的是 shape 为 (**1000**, **100**) 的数据集（类比于 Numpy 的 **array**），为每个查询向量最近的 100 个向量距该查询向量的距离，数据类型为 **float32**\n- **neighbors** 对应的是 shape 为 (**1000, 100**) 的数据集，为每个查询向量最近的 100 个向量，数据类型为 **int32**\n- **test** 对应的是 shape 为 (**1000000, 960**) 的数据集，这是基数据（原始数据），一共 1000000 个向量，每个向量的维度为 960 维，数据类型为 **float32**\n- **train** 对应的是 shape 为 (**1000, 960**) 的数据集，只是查询数据，一共 1000 个向量，向量的维度为 960 维，数据类型为 **float32**\n\n## vecs 文件的结构\n\n![vecs 文件结构示意图](/img/2024-02-06-HDF5文件转vecs文件/pho2.jpg)\n\n在常用的公开数据集中，**数据集文件、查询文件**往往使用 fvecs 格式存储。而**真值集（即查询的答案）文件**使用 ivecs 格式存储。其实这两种格式十分相似。\n\n### fvecs\n\n数据集、查询集采用fvecs格式，其实他们是完全相同的东西。在数据集中，存储的是所有向量，而查询集中，存储的同样是向量，只是向量数量会少一些。\n\nfvecs 采用**二进制**来存储，直接打开便是乱码。\n\n下面用一张图来表示 fvecs 的大致格式：\n\n![fvecs 文件格式示意图](/img/2024-02-06-HDF5文件转vecs文件/pho3.jpg)\n\n每一“行”中，**第一个数表示数据的维度 dim，后面跟着的 dim 个数便是向量各维度的值**。(注：fvecs 中的 f 指 **float32**)\n\n因此，一“行”表示的便是一个向量。\n\n### ivecs\n\nivecs 其实和 fvecs 的格式是一样的，只不过它存储的不是向量，而是每一条查询的答案。\n\n就是说，ivecs 里的每一“行”里，**第一个数据是查询答案的数量 n，后面 n 个数是答案向量的 id**。(注：ivecs 中的 i 指 **int32**)\n\n## HDF5 转 vecs 脚本\n\n```python\n'''\nAuthor: pudding\nDate: 2024-02-02 10:15:39\n'''\nimport argparse\nimport os\nimport h5py\nimport numpy as np\nimport struct\n\nimport sklearn.preprocessing\n\ndef load_hdf5_file(filename):\n    print('loading：'+ filename)\n    hdf5_f = h5py.File(filename, 'r')\n    print('load done !')\n    return hdf5_f\n\ndef to_fvecs(filename, data):\n    with open(filename, 'wb') as fp:\n        for y in data:\n            # 将 y.size（dim） 以 C++ 的 unsigned int 的形式写入二进制文件\n            d = struct.pack('I', y.size)\n            fp.write(d)\n            for x in y:\n                # 将 x（vector）以 C++ 的 float 的形式写入二进制文件\n                a = struct.pack('f', x)\t\n                fp.write(a)\n\ndef to_ivecs(filename, data):\n    with open(filename, 'wb') as fp:\n        for y in data:\n            d = struct.pack('I', y.size)\n            fp.write(d)\n            for x in y:\n                a = struct.pack('I', x)\n                fp.write(a)\n\n\ndef run(file_path):\n    dataset = load_hdf5_file(file_path)\n\n    dimension = int(dataset.attrs[\"dimension\"]) if \"dimension\" in dataset.attrs else len(dataset[\"train\"][0])\n    print('======== HDF5 Basic Information ========')\n    print('dataset dimension：'+ str(dimension))\n    filename = file_path.split('/')[-1]\n    dataname = filename.split('.')[0]\n\n    X_train = np.array(dataset[\"train\"])\n    X_test = np.array(dataset[\"test\"])\n    distance = dataset.attrs[\"distance\"]\n\n    # if distance == \"angular\":\n    #     X_train = sklearn.preprocessing.normalize(X_train, axis=1, norm=\"l2\")\n    #     X_test /= np.linalg.norm(X_test)\n    \n    print(\"Dataname：\" + dataname)\n    print(\"distance：\", distance)\n    print(\"got a train set of size (%d * %d)\" % (X_train.shape[0], dimension))\n    print(\"got %d queries\" % len(X_test))\n\n    print('======== HDF5 to vesc ========')\n    dataset_dir = os.path.join('./vecs', dataname)\n    if not os.path.exists(dataset_dir):\n        os.makedirs(dataset_dir)\n    \n    to_fvecs(os.path.join(dataset_dir, dataname+'_base.fvecs'), X_train)\n    to_fvecs(os.path.join(dataset_dir, dataname+'_query.fvecs'), X_test)\n\n    to_ivecs(os.path.join(dataset_dir, dataname+'_groundtruth.ivecs'), dataset['neighbors'])\n\n    print(\"dataset['train'] to \"+ str(os.path.join(dataset_dir, dataname+'_base.fvecs')))\n    print(\"dataset['test'] to \"+ str(os.path.join(dataset_dir, dataname+'_query.fvecs')))\n    print(\"dataset['neighbors'] to \"+ str(os.path.join(dataset_dir, dataname+'_groundtruth.ivecs')))\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Run the script with file path input\")\n    parser.add_argument(\"--file_path\", type=str, required=True, help=\"Path to the input file\")\n    args = parser.parse_args()\n\n    run(args.file_path)\n```\n","tags":["向量数据库"]},{"title":"一文让你应对 Linux 进程 \"D\" 状态","url":"/2024/01/16/2024-01-16-linux-jin-cheng-d-zhuang-tai/","content":"\n## 环境\n\n红帽企业 linux 4、5、6、7、8、9\n\n## 问题\n\n- 什么是 \"D\" 状态（或 dstate 或 d-state）?\n- 什么是进程的 \"D\" 状态\n\n## 解决\n\n<ul>\n  <li>Linux 遵循传统 UNIX 的标准，将其平均负荷计算为指定时间间隔内可运行或正在运行的进程（R 状态）的平均数量，以及处于不可中断睡眠（D 状态）中的进程数量。</li>\n  <li>\"D\" 状态（TASK_UNINTERRUPTIBLE）是发生在内核代码路径中的一种状态，在这种状态下，在处理任务时执行不能被中断。我们希望这应该是一个短暂的过程，且在正常操作中，内核线程应该快速地从 TASK_UNINTERRUPTIBLE 状态中出来。\n    <ul>\n      <li><b>\"D\" 状态进程通常被阻塞等待资源</b>，磁盘 IO 和锁是进程可能阻塞的几种常见资源。</li>\n      <li>一个例子可能是与硬件通信的 low level 驱动程序，可能从 NIC 固件检索网络数据包数据或访问硬盘驱动器上的数据块--读写 IO。</li>\n      <li>通常，这种情况发生得非常快，并且线程保持这种状态的时间非常短（因此通常不会观察到，尤其是在用户空间中）。</li>\n      <li>\"D\" 状态名称有历史原因，因为最初认为这种状态是进程处于“磁盘等待”状态。但现在，与“磁盘 IO”分离的网络、锁和其他资源可能导致进程处于不可中断的等待状态。有关进程状态的更多背景信息，请参阅 \"<a href=\"https://access.redhat.com/sites/default/files/attachments/processstates_20120831.pdf\">了解 Linux 进程状态</a>\"。具体来说，我们总结了 \"D\" 状态过程如下：“不可中断睡眠状态是不会立即处理信号的状态。它只有在等待资源变得可用或者在等待期间发生超时(如果在进程进入睡眠时指定了超时)时才会被唤醒。”</li>\n    </ul>\n  </li>\n  <li>当线程进入 \"D\" 状态并且未能在合理的时间内退出该状态时，就会出现问题。这个进程现在被“卡住”，任何等待它的进程（可能在它后面的队列中访问相同的硬件）或依赖它的进程也同样被卡住。\n    <ul>\n      <li>虽然“合理的时间”是主观的，但如果一个任务在 D 状态下停滞太久，那么 \"<a href=\"https://access.redhat.com/solutions/31453\">INFO: task <process>:<pid> blocked for more than ... seconds</a>\" 的消息就会输出，通知系统管理员需要调查或可能需要<a href=\"https://access.redhat.com/solutions/39188\">系统调优</a>的潜在情况。</li>\n    </ul>\n  </li>\n  <li>要查看哪个进程/线程保持在 \"D\" 状态：\n    <ul>\n      <li>获取处于 \"D\" 状态的线程列表：\n        <code>ps auxH | awk '$8 ~ /^D/{print}'</code>\n      </li>\n      <li>显示每个线程<code>sudo cat /proc/&lt;PID&gt;/stack</code> 的堆栈：<br>\n        <code>for D_PID in $(ps auxH | awk '$8 ~ /^D/{print $2}');do ps -Llp $D_PID;sudo cat /proc/$D_PID/stack;echo;done</code>\n      </li>\n    </ul>\n  </li>\n</ul>\n\n## 根本原因\n\n- 发现处于 D 状态的进程是相当普遍和正常的\n- 在大多数情况下，这是由于对 I/O 资源（通常是本地或远程存储、网络文件系统等）的访问中断造成的\n- 如果一个进程在 D 状态停滞太久，那么内核中的“<a href=\"https://access.redhat.com/solutions/31453\">停滞任务</a>”逻辑将被启用\n\n## 诊断步骤\n\n- 检查 ps 输出中是否有处于 D 状态的线程，可以使用类似于以下内容的内容：<code>ps auxH | awk '$8 ~ /^D/{print}'</code>\n- 负载可能很高而且还在增加（可能有成百甚至到数千，1 分钟负载始终高于 5 分钟，5 分钟始终高于 15 分钟，暗示报告的负载不断增加）；机器的响应能力与这个高数字不匹配（机器还能响应命令，但是如果所有核心都被占据之后，可能系统就不再响应）\n- 解决问题的第一步（假设前两个步骤得到了验证）是隔离导致这种情况的资源（最有可能的存储/文件系统），例如查看处于 d 状态（当前工作）的进程的共同使用的文件或者目录等\n- 一旦确定了所涉及的资源，就应采取措施恢复对它的访问；根据具体情况，可能会重新获得对在线文件系统/存储的访问，或者可能需要重新启动机器才能完全恢复（最有可能的情况）\n\n\n> 参考链接\n> - <a href>What is \"D\" state (or dstate, d-state)?</a>\n> - <a href=\"https://mp.weixin.qq.com/s?__biz=MzI0OTIzOTMzMA==&mid=2247485072&idx=1&sn=c9bd418f4dcb9ce2cffd9dfb20461640&chksm=e995c4dddee24dcbc6450633da0627cf65ec92ca61e4e487b774882c5a51db0210a79f3f890a&scene=21#wechat_redirect\">一文让你应对Linux 进程“D”状态</a>","tags":["Linux"]},{"title":"线程上下文切换与进程上下文切换的区别","url":"/2023/12/14/2023-12-14-xian-cheng-shang-xia-wen-qie-huan-yu-jin-cheng-shang-xia-wen-qie-huan-de-qu-bie/","content":"\n上下文切换是操作系统在多任务环境中管理多个线程或进程的基本操作。它涉及到保存一个线程或进程的当前执行上下文，并恢复另一个线程或进程的执行上下文。这允许操作系统在不同的线程之间快速切换，给人一种并发执行的错觉。\n\n有两种类型的上下文切换：“线程上下文切换”和“进程上下文切换”。让我们来看看它们之间的区别。\n\n## 什么是线程上下文切换？\n\n线程上下文切换指的是保存正在进行的线程的当前执行上下文，并恢复另一个线程的执行上下文以允许它在运行的过程。在多线程环境中，单个进程中的多个线程可以并发执行，操作系统执行线程上下文切换以在不同线程之间切换执行。下面是线程上下文切换的关键特征：\n\n- **粒度（Granularity）**：线程上下文切换操作的粒度比进程上下文切换更细。它们涉及在同一进程内的线程之间切换，与进程上下文切换相比，允许更快的切换和更低的开销。\n\n- **执行上下文（Execution Context）**：在线程上下文切换期间，保存当前线程的执行上下文，包括程序计数器、堆栈指针和寄存器值。然后恢复另一个线程的上下文，允许它从停止的地方继续执行。\n\n- **共享内存（Shared Memory）**：进程中的线程共享相同的内存空间。因此，在线程上下文切换期间，不需要切换内存地址空间或更新内存管理结构。内存保持完整，线程可以直接访问共享数据，而不需要任何额外的开销。\n\n## 什么是进程上下文切换？\n\n另一方面，进程上下文切换涉及到保存正在运行的进程的当前执行上下文和恢复另一个进程的执行上下文。它允许操作系统在不同的独立进程之间切换，每个进程都有自己的内存空间和资源。以下是进程上下文切换的关键特征:\n\n- **粒度（Granularity）**：进程上下文切换操作的粒度比线程上下文切换操作的粒度更粗。它们涉及在不同进程之间切换，这些进程通常有自己的内存空间和资源分配。由于需要内存管理更新和潜在的缓存刷新，进程上下文切换通常比线程上下文切换更加昂贵和耗时。\n\n- **执行上下文（Execution Context）**：在进程上下文切换期间，保存当前进程的执行上下文，包括程序计数器、堆栈指针、寄存器值和内存管理结构。然后还原另一个进程的执行上下文，允许它从中断的地方继续执行。\n\n- **共享内存（Shared Memory）**：进程有其独立的内存空间，其中可能包括虚拟地址空间、页表和内存保护机制。在进程上下文切换期间，内存管理结构需要更新，以反映新进程的内存空间，与线程上下文切换相比，这会带来额外的开销。\n\n- **保护和隔离（Protection and Isolation）**：进程上下文切换在进程之间提供更高级别的保护和隔离。每个进程在自己的内存空间中运行，提供更好的安全性和故障隔离。进程上下文切换确保进程不能直接访问或干扰彼此的内存或资源。\n\n## 线程上下文切换和进程上下文切换\n\n线程上下文切换和进程上下文切换：\n\n| 特征 | 线程上下文切换 | 进程上下文切换 |\n|--|--|--|\n| 定义 | 保存正在运行的线程的当前状态(上下文)并加载另一个线程的保存状态以供执行的过程 | 保存正在运行的进程的当前状态(上下文)并加载另一个进程的保存状态以供执行的进程 |\n| 粒度 | 在进程的线程级别上发生，一个进程中可以存在多个线程 | 在进程级别发生，每个进程可以有一个或多个线程。 |\n| 执行环境 | 在同一个进程中，线程上下文切换发生在相同的内存空间中，并共享相同的资源 | 进程上下文切换涉及不同的进程，它们有自己的内存空间和资源 |\n| 开销 | 线程上下文切换通常比进程上下文切换具有更低的开销，因为它们涉及在同一进程内的线程之间进行切换 | 由于需要在不同进程之间进行切换，因此进程上下文切换的开销较高，需要对内存和资源映射进行更广泛的更改 |\n| 调度 | 线程上下文切换通常由操作系统的线程调度程序管理 | 进程上下文切换由操作系统的进程调度程序管理 |\n| 时间复杂性 | 线程上下文切换通常具有较低的时间复杂性，因为它们涉及在同一进程内的线程之间进行切换 | 由于需要为不同的进程执行更广泛的上下文保存和恢复操作，进程上下文切换的时间复杂度较高 |\n| 对系统资源的影响 | 线程上下文切换对系统资源的影响相对较小，因为进程中的线程共享许多资源 | 进程上下文切换对系统资源的影响更大，因为不同的进程有自己的内存空间和资源分配 |\n| 通讯与同步 | 同一进程中的线程可以使用共享内存或同步原语轻松地进行通信和同步 | 进程通常使用进程间通信机制(如管道、套接字或消息队列)彼此进行通信和同步 |\n| 例子 | 在 Web 服务器中的不同线程之间切换以同时处理多个客户端请求。 | 在多任务操作系统上运行不同应用程序的不同进程之间切换 |\n\n## 结论\n\n1. 线程上下文切换涉及在同一进程内的线程之间切换执行，而进程上下文切换涉及在不同独立进程之间切换执行。\n2. 线程上下文切换速度更快，开销更低，因为它们不需要更新内存管理结构。\n3. 进程上下文切换较慢，涉及更新内存管理结构，以便在不同的内存空间之间切换，并在进程之间提供更好的隔离\n\n> 参考链接\n> - https://www.tutorialspoint.com/difference-between-thread-context-switch-and-process-context-switch","tags":["性能测试"]},{"title":"线程和进程的区别","url":"/2023/12/14/2023-12-14-xian-cheng-he-jin-cheng-de-qu-bie/","content":"\n**进程**（process）和**线程**（thread）彼此相关，非常相似，因为它们是独立的执行顺序。进程和线程的基本区别在于，进程发生在不同的内存空间，而线程在相同的内存空间中执行。\n\n通读本文，希望你能找出在操作系统上下文中进程与线程的不同之处。让我们从线程和进程的一些基本知识开始。\n\n## 什么是进程？\n\n**进程**是一个活动的程序，也就是说，一个正在执行的程序。它不仅仅是程序代码，因为它包括程序计数器、进程堆栈、寄存器、程序代码等。与此相比，程序代码只是文本部分。\n\n当计算机程序被触发执行时，它并不是直接运行，而是首先确定程序执行所需的步骤，而遵循这些步骤执行的过程称为进程。\n\n进程可以分为两种类型，即**克隆进程**和**父进程**。克隆进程也称为子进程，是由另一个进程创建的进程，而主进程是负责创建其他进程，以同时执行多个任务的进程，称为父进程。\n\n## 什么是线程？\n\n**线程**是可由调度程序独立管理的轻量级进程。它使用并行性提高了应用程序的性能。线程与其对等线程共享数据段、代码段、文件等信息，同时包含自己的寄存器、堆栈、计数器等。\n\n线程基本上是大型进程的一个子部分。在进程中，进程中的所有线程都是相互关联的。典型的线程包含一些信息，如数据段、代码段等。这些信息将在执行期间共享给它们的对等线程。\n\n线程最重要的特性是它们与它们所属的进程中的对等线程共享内存、数据、资源等。此外，进程中的所有线程都需要进行同步，以避免意外的结果。\n\n## 进程与线程的区别\n\n下表突出显示了进程和线程之间的主要区别：\n\n| 比较 | 进程 | 线程 |\n|--|--|--|\n| 定义 | 进程是一个正在执行的程序，也就是活动的程序 | 线程是可由调度程序独立管理的轻量级进程 |\n| 上下文切换时间 | 进程需要更多的时间进行上下文切换，因为它们比较繁重 | 线程需要更少的时间进行上下文切换，因为它们比进程轻 |\n| 内存共享 | 进程是完全独立的，不共享内存 | 进程是完全独立的，不共享内存。 |\n| 通信耗时 | 进程之间的通信比线程之间的通信需要更多的时间 | 线程之间的通信比进程之间的通信需要更少的时间 |\n| 阻塞处理 | 如果一个进程被阻塞，其余进程可以继续执行 | 如果用户级线程被阻塞，它的所有对等线程也会被阻塞 |\n| 资源消耗 | 进程比线程需要更多的资源 | 线程通常比进程需要更少的资源 |\n| 依赖性 | 各个过程是相互独立的 | 线程是进程的一部分，因此是依赖的 |\n| 数据和代码共享 | 进程具有独立的数据和代码段 | 线程与其对等线程共享数据段、代码段、文件等 |\n| 创建时间 | 进程创建需要更多的时间 | 线程创建所需的时间更少 |\n| 终止时间 | 进程需要更多的时间来终止 | 进程需要更多的时间来终止 |\n\n## 结论\n\n进程和线程之间最显著的区别在于，进程被定义为由计算机完成的任务，而线程是可由调度程序独立管理的轻量级进程。\n\n> 参考链接\n> - https://www.tutorialspoint.com/difference-between-process-and-thread\n","tags":["性能测试"]},{"title":"面向开发人员的向量嵌入：基础知识","url":"/2023/12/13/2023-12-13-vector-embeddings-for-developers/","content":"\n> 本文是一篇英文翻译转载文章，主要介绍了向量嵌入的一些基础知识。<br>\n原英文链接：https://www.pinecone.io/learn/vector-embeddings-for-developers/<br>\n\n你可能还不知道，但是向量已经嵌入无处不在。它们是许多机器学习和深度学习算法的基石，从搜索到人工智能助手等应用程序都是用这些算法。如果你正在考虑在这些领域中构建自己的应用程序，那么未来你可能会遇到向量嵌入。在这篇文章中，我们将尝试介绍向量嵌入是什么以及如何使用它们。\n\n## 我们要解决什么问题？\n\n在构建传统应用程序时，数据结构表示为可能来自数据库的对象。这些对象具有与你正在构建的应用程序相同的属性（或数据库中的列）。\n\n随着时间的推移，这些对象的属性数量不断增强，以至于你可能需要更加谨慎地选择完成给定任务所需的属性。你甚至可能最终构建这些对象的专门表示来解决特定的任务，而不必支付必须处理非常“胖”的对象开销。这个过程被称为特征工程（Feature Engineering）——通过只挑选与手头任务相关的基本特征来优化应用程序。\n\n当你处理**非结构化**数据时，你将不得不经历相同的特征工程过程。然而，非结构化数据可能有更多相关特征，而执行手动特征工程注定是不可行的。\n\n在这些情况下，我们可以使用**向量嵌入**作为一种形式的自动特征工程。我们不再从数据中手动挑选所需的特征，而是应用一个预先训练好的机器学习模型，该模型将生成一个更紧凑的数据表示，同时保留数据的有意义之处。\n\n## 什么是向量嵌入？\n\n在我们深入研究向量嵌入之前，让我们先讨论一下向量。向量是一种具有大小和方向的数据结构。例如，我们可以把向量看作空间中的一个点，“方向”是从 (0,0,0) 到向量空间中该点的箭头。\n\n![向量](/img/2023-12-13-vector_embeddings_for_developers/pho1.png)\n\n作为开发人员，可能更容易把向量想象成一个包含数值的数组。例如：\n\n```py\nvector = [0,-2,...4]\n```\n\n但我们在一个空间中观察一组向量时，我们可以说是有些向量彼此接近，而有些则相距甚远。一些向量似乎可以聚集在一起，而其他向量可以稀疏地分布在空间中：\n\n![向量分布](/img/2023-12-13-vector_embeddings_for_developers/pho2.png)\n\n我们将很快探索向量之间的这些关系是如何有用的。\n\n向量是机器学习算法的理想数据结构——现代 CPU 和 GPU 都进行了优化，以执行处理它们所需的数学运算。但是我们的数据很少用矢量表示。这就是向量嵌入发挥作用的地方。这种技术允许我们获取几乎任何数据类型，并将其表示为向量。\n\n但是这不仅仅是把数据转换为向量那么简单。我们希望确保能够在转换后的数据上执行任务，而不会丢失数据的原始含义。例如，如果我们要比较两个句子——我们不仅要比较它们所包含的单词，而且要比较它们是否意味着同一件事。为了保持数据的含义，我们需要了解如何在向量之间的关系有意义的地方生成向量。\n\n要做到这一点，我们需要一个所谓的**嵌入模型**。许多现代嵌入模型都是通过将大量的标记数据传递给神经网络来建立的。你可能以前听说过神经网络——它们是用来解决各种复杂问题的流行算法。用非常简单的术语来说，神经网络是由函数连接的节点层组成的；然后我们训练这些神经网络来执行各种任务。\n\n我们通过监督式学习训练神经网络——向神经网络提供由成对输入和标记输出组成的大量训练数据。或者，我们可以应用自我监督或非监督式学习，其中任何一个都不需要标记输出。这些值通过网络激活和操作的每一层进行转换。通过每次迭代训练，神经网络修改每一层的激活。最终，它可以预测给定输入的输出标签应该是什么——即使它以前从来未见过这种特定输入。\n\n嵌入模型基本上是去掉最后一层的神经网络。我们得到的不是输入的特定标记值，而是向量嵌入。\n\n嵌入模型的一个很好的例子是流行的 <a href=\"https://en.wikipedia.org/wiki/Word2vec\">word2vec</a>，它经常用于各种基于文本的任务。让我们看看<a href=\"https://projector.tensorflow.org/\"> TensorFlow 的投影仪工具</a>产生的可视化，它使嵌入更容易可视化。\n\n![TensorFlow's projector tool](/img/2023-12-13-vector_embeddings_for_developers/pho3.png)\n\n尽管这种可视化只表示嵌入的三个维度，但它可以帮助我们理解嵌入模型是如何工作的。可视化中突出显示了多个数据点，每个数据点表示一个单词的向量嵌入。顾名思义，word2vec 嵌入了单词。相邻的词语在语义上是相似的，而相距较远的词语在词义上是不同的。\n\n经过训练，嵌入模型可以将原始数据转换为向量嵌入。这意味着它知道在向量空间中放置新的数据点。\n\n![word2vec 流程](/img/2023-12-13-vector_embeddings_for_developers/pho4.png)\n\n正如我们在 word2vec 中看到的，在模型的上下文中，紧密相连的向量具有上下文相似性，而相距较远的向量彼此不同。这就是赋予向量意义的东西——它与向量空间中其他向量的关系取决于嵌入模型如何“理解”它所训练的领域。\n\n## 我能用向量嵌入做什么？\n\n向量嵌入是一个非常通用的工具，可以应用于许多领域。一般来说，应用程序会使用一个向量嵌入作为它的查询，并产生其他类似的向量嵌入，其相应的值。每个领域的应用程序之间的差异就是这种相似性的重要性。\n\n下面是一些例子：\n\n- 语义搜索：传统的搜索引擎通过搜索关键字的重叠来工作。通过利用向量嵌入，语义搜索可以超越关键词匹配，基于查询的语义进行查询。\n- 问答应用程序：通过训练一个嵌入式模型，其中包含成对的问题和相应的答案，我们可以创建一个应用程序来回答以前从未见过的问题。\n- 图像搜索：向量嵌入非常适合作为图像检索任务的基础。有多种现成的模型，如 CLIP、 ResNet 等。不同的模型可以处理不同类型的任务，比如图像相似性、目标检测等等。\n- 音频搜索：通过将音频转换成一组激活(音频光谱图) ，我们生成可用于音频最近邻搜索的向量嵌入。\n- 推荐系统：我们可以创建嵌入的结构化数据，关联到不同的实体，如产品，文章，等。在大多数情况下，你必须创建自己的嵌入模型，因为它是特定于你的特定应用程序的。有时，当找到图像或文本描述时，这可以与非结构化嵌入方法结合使用。\n- 异常检测：我们可以创建嵌入异常检测使用标记传感器信息的大数据集，识别异常事件。","tags":["向量数据库"]},{"title":"像光一样搜索——HNSW算法介绍","url":"/2023/11/20/2023-11-20-hnsw/","content":"\n> 本文是一篇英文翻译转载文章，主要介绍了HNSW算法。<br>\n原英文链接：https://dataman-ai.medium.com/search-like-light-speed-1-hnsw-c5b0d4665926<br>\n参考中文转载链接：https://luxiangdong.com/2023/11/06/hnsw/\n\n我喜欢《玩具总动员》中的太空巡逻员“巴斯光年”，我也喜欢他的口号“飞向无限，飞向更远!”当我搜索信息时，我也喜欢快速找到正确的信息。这一切都是关于高速互联网和足够的带宽吗？不完全是！**事实上，近乎即时搜索结果的算法是至关重要的。**信息检索的速度是计算机科学中的一个重要课题。随着文本、图像或音频数据的高维嵌入式大语言模型（LLM），信息检索的速度成为数据科学的优先话题。\n\n在这篇文章中，我将谈论: \n- NLP中的向量嵌入（Embeddings）\n- KNN（K-Nearest Neighbors）无法跟上速度\n- 近似最近邻（ANN）感觉就像光速\n- 快速搜索的初始算法\n- 理解分层导航小世界图算法（HNSW）\n- 代码示例：Embedding 新闻文章\n- 代码示例：FAISS 用于 HNSW 搜索\n\n## NLP 中的向量嵌入\n\n向量嵌入是自然语言处理中的一个基本概念，是对词、句子、文档、图像、音频或视频数据等对象的数字表示。这些向量嵌入被设计用来捕获它们所表示的对象的语义和上下文信息。\n\n让我们首先描述词嵌入。2014年，一个突破性的创意 Word2Vec 出现在 NLP 中，它将单词或短语转换或“嵌入”为数值型的高维向量，称为词嵌入。这些词嵌入捕获单词之间的语义和上下文关系，使机器能够理解并使用人类语言。例如图 1 显示了三维空间中的高维向量：“铁（iron）”这个词与“火药（gunpowder）”、“金属（metals）”和“钢铁（steel）”这样的词很接近，但与“有机（organic）”、“糖（suugar）”或“谷物（grain）”等不相关的词相去甚远。\n\n![图 1 文字嵌入](/img/2023-11-20-hnsw/pho1.png)\n\n词嵌入可以表示单词之间的相似或不相似。这是一项了不起的创新。既然单词可以嵌入，为什么句子不能呢？这就是句子嵌入的诞生。句子嵌入捕捉整个句子的语义和上下文，使机器能够理解和比较句子。生成句子嵌入的常见方法是 Doc2Vec。强大的基于大语言模型（LLM）的词嵌入成为 NLP 的标准，如BERT（基于 Transformer 的双向编码器表示）、ELMo（来自语言模型的嵌入）、Llama（大型语言模型元AI），以及OpenAI的多个模型。\n\n既然文本可以作为向量嵌入，为什么不能嵌入图像呢？这就产生了图像嵌入。卷积神经网络（CNNs）和视觉几何组（VGG）常被用于生成图像嵌入。图像嵌入使图像检索和分类成为可能。\n\n既然图像可以作为载体嵌入，为什么我们不能嵌入音频呢？你是对的！音频嵌入可以捕捉音频数据的声学特征，并可以进行音频分类和检索。那么视频嵌入呢？它们捕捉视频分类所需的图像特征流。地理空间嵌入如何？当然。像经纬度坐标这样的地理空间数据可以嵌入到高维向量中进行信息检索。\n\n嵌入是的一切变得简单。如果你有一篇文章，需要找到类似的文章，你只需要计算你的文章向量和其他文章向量之间的“距离”。“距离”最近的向量就是你的搜索结果。我们可以用 K-最近邻法（KNN）对吧？然而，速度是个问题。KNN 的搜索将使光年皱眉，对于巴斯光年来说，完成一次简单的搜索需要……需要不知道多少年。研究的挑战不是最近的邻居在“哪里”，而是“如何”找到他们。\n\n## K-最近邻（KNNs）无法跟上速度\n\n假如你有一本新书，你想在图书馆内找到类似的书。k-最近邻（KNN）将浏览书架上的每一本书，并将它们从最相似到最不相似的顺序排序，以确定最相似的书。你有足够的耐心去完成这样一项繁琐的工作吗？相反，人工神经网络会先对图书馆中的书籍进行预分类和索引。要找到与你的新书相似的书，你所需要做的就是去正确的楼层，正确的区域，正确的通道找到相似的书。此外，**你通常不需要对排名前 10 位的类似书籍进行精确排序，比如 100%、99% 或 95%的匹配度**。这就是近似邻（ANN）的思想。\n\n![-](/img/2023-11-20-hnsw/pho2.png)\n\n让我们来了解一下为什么人工神经网络可以更有效地搜索。\n\n## 近似最近邻（ANN）感觉像光速\n\nANN（Approximate Nearest Neighbors）对大数据进行预索引，以方便快速搜索。在索引期间，构建数据结构以促进更快的查询。当你想找到一个查询点的近似最近邻居时，你可以将该点提供给 ANN 算法。ANN 算法首先从数据集中识别一组可能接近查询点的候选点，然后使用预构建的数据接结构选择候选点。这一步骤大大减少了需要检索接近性的数据点的数量。在候选点被选中之前，ANN 会计算每个候选点与查询点之间的实际距离（如欧几里得距离、余弦相似度）。然后根据与查询点的距离/相似度对候选点集排序。排名靠前的候选点作为近似最近邻返回。在某些情况下，你还可以设置一个距离阈值，只返回该阈值内的候选点。人工神经网络背后的关键思想是，**为了显著降低计算成本，它牺牲了找到绝对最近邻的保证。这些算法的目标是在计算效率和准确性直接取得平衡。**\n\n然而，在高维空间中，过去的实验表明 ANN 并不比 KNN 节省多少时间（见[4]）。有几种创新的人工神经网络算法适用于高维空间：\n\n### 最先进的快速搜索算法\n\n这些不同的人工神经网络算法是用不同的方法，形成便于有效检索的**数据结构**。有三种类型的算法：基于图的、基于哈希的和基于树的：\n\n**基于图的算法创建数据的图形表示**：其中每个数据点是一个节点，边表示数据点之间的接近性或相似性。最引人注目的是层次导航小世界图（HNSW）\n\n**基于哈希的算法**：使用哈希函数将数据点映射到哈希值或桶。流行的算法包括：位置敏感哈希（LSH）、多索引哈希（MIH）和乘积量化\n\n**基于树的算法**：将数据集划分为树状结构，以便快速搜索。流行的是 kd树、环树和随机投影树（RP树）。对于低纬空间（≤10），基于树的算法是非常有效的\n\n有几个流行的代码库：\n\n- <a href=\"https://github.com/scikit-learn/scikit-learn\">Scikit-learn</a>：它的 NearestNeighbors 类提供了一个简单的接口，可以使用 LSH 等技术进行精确和近似的最近邻搜索。\n- <a href=\"https://github.com/nmslib/hnswlib\">Hnwlib</a>：它是HNSW的Python包装器。\n- <a href=\"https://github.com/facebookresearch/faiss\">faiss</a>：该库支持多种 ANN 算法，包括 HNSW, IVFADC（带ADC量化的倒置文件）和IVFPQ（带产品量化的倒置文件）。\n- <a href=\"https://github.com/spotify/annoy\">Annoy（Approximate Nearest Neighbors Oh Yeah）</a>：Annoy是一个 c++ 库，也提供了 Python 接口。\n- <a href=\"https://github.com/nmslib/nmslib\">NMSLIB（非度量空间库）</a>：它是用 c++ 编写的，并具有 Python 包装器。它可以执行 HNSW、LSH、MIH 或随机投影树等算法。\n\n使用上述代码库，你可以超级快速地执行搜索查询。还有一些库的变体你需要注意。这里我只提到其中的三个：\n\n第一个是 <a href=\"https://github.com/lmcinnes/pynndescent\">PyNNDescent</a>。PyNNDescent 是一个 Python 库，用于基于 NN-descent 的搜索算法，它是 LSH 的一个变体。\n\n第二个是 <a href=\"http://pixelogik.github.io/NearPy/\">NearPy</a>。它支持多个距离度量和哈希族。\n\n第三个是 <a href=\"https://github.com/storpipfugl/pykdtree\">PyKDTree</a>。PyKDTree 是一个 Python 库，用于基于 kd 树的最近邻（KNN）搜索。虽然 kd 树更常用于精确搜索，但 PyKDTree 也可以通过一些启发式优化用于近似搜索。\n\n此外，如果您询问哪些算法和库执行速度最好，您只需要了解 <a href=\"https://github.com/erikbern/ann-benchmarks\">**ANN-benchmark**</a> 库，专门为对人工神经网络搜索算法进行基准测试而设计。它提供了一个标准化的框架来评估算法，如 Annoy、FLANN、scikit-learn (LSHForest, KDTree, BallTree)、PANNS、NearPy、KGraph、NMSLIB(非度量空间库)、hnswlib、RPForest、FAISS、nndescent、PyNNDescent 等等。\n\n但是“巴斯光年”不仅仅关注最近邻在哪里，还想高效地找到他们。那让我们学习第一个算法——HNSW。HNSW 通常可以在几毫秒内从数百万个数据点中找到最近邻。\n\n## 了解 HNSW（分层导航小世界图）\n\nHNSW 是一种用于高维空间中进行高效人工神经网络搜索的数据结构和算法。它是**跳表（Skip Lists）**和**小世界（SWG）**结构的拓展，可以高效地找到近似的最近邻。如果我们先学习跳表和小世界图，学习 HNSW 就会很简单。\n\n跳表是一种用于维护已排序的元素集的数据结构，它允许进行高效的搜索、插入和删除操作。它由 William Pugh 在 1989 年发明。图（2）显示了数字 [3,6,7,9,12,17,19,21,25,26] 的排序链表。假设我们想找到目标 19。当值小于目标值时，我们向右移动。找到它需要 6 个步骤。\n\n![图（2）排序链表](/img/2023-11-20-hnsw/pho3.png)\n\n现在，如果列表中的每个其他节点都有一个指向前面第二个节点的指针，如图（3）所示，可以将这些指针视为“高速公路”。数学规则是“当数值小于目标时向右移动”。需要4个步骤才能达到19。\n\n![图（3）跳表，指向前面第二个节点](/img/2023-11-20-hnsw/pho4.png)\n\n这些高速公路加快了搜索速度。我们可以增加更多。现在，如果列表中每三个其他节点都有一个指向前面第三个节点的指针，如图（4）所示，那么只需要 3 步就可以到达 19。\n\n你可能会问，如何选择这些点作为”高速公路“？它们可以是预先确定的，也可以是随机的。这些节点的随机选择是 Small World 和 NHSW 中数据构建的重要步骤，我将在后面介绍。\n\n![图（4）跳表再升级，指向前面第三个节点](/img/2023-11-20-hnsw/pho5.png)\n\n由跳表的思路延伸到 Small World，我们来看看是怎么做的。\n\n## 从跳表到 Small World\n\n小世界网络是一种特殊的网络，在这种网络中，你可以迅速联系到网络中的其他人或点。这有点像“凯文·培根的六度”(Six Degrees of Kevin Bacon)游戏，在这个游戏中，你可以通过一系列其他演员，在不到六个步骤的时间里，将任何演员与凯文·培根联系起来。\n\n想象一下，你有一群朋友排成一个圆圈，如图（5）所示。每个朋友都与坐在他们旁边的人直接相连。我们称它为“原始圆”。\n\n现在，这就是奇迹发生的地方。你可以随机选择将其中一些连接人改变成圆圈中的其他人，就像图（5）中的红色连接线一样。这就像这些连接的“抢椅子”游戏。有人跳到另一把椅子上的几率用概率 p 表示。如果 p 很小，移动的人就不多，网络看起来就很像原来的圆圈。但如果 p 很大，很多人就会跳来跳去，网络就会变得有点混乱。当您选择正确的 p 值(不太小也不太大)时，红色连接是最优的。网络变成了一个小世界网络。你可以很快地从一个朋友转到另一个朋友（这就是“小世界”的特点）。\n\n![图（5）Small World 网络](/img/2023-11-20-hnsw/pho6.png)\n\n现在让我们学习从小世界网络到可导航小世界的过渡。\n\n## 从 Small World 到 HNSW\n\n现在我们要扩展到高维空间。图中的每个节点都是一个高维向量。在高维空间中，搜索速度会变慢。这是不可避免的“维度的诅咒”。HNSW 是一种高级数据结构，用于优化高维空间中的相似性搜索。\n\n让我们看看 HNSW 如何构建图的层次结构。HNSW 从图（6）中的第 0 层这样的基础图开始。它通常是使用随机初始化来构造的数据点。\n\n![图（6）HNSW](/img/2023-11-20-hnsw/pho7.png)\n\nHNSW 在层次结构中的基础层之上构造附加层。每个层将有更少的顶点和边的数量。可以把高层中的顶点看作是跳跃列表中访问“高速公路”的点。你也可以将这些顶点视为游戏“Six Degrees of Kevin Bacon”中的演员 Kevin Bacon，其他顶点可以在不到六步的时间内连接到该顶点。\n\n一旦构建了上面的层次结构，数据点就被编入索引，并准备进行查询搜索。假设查询点是橘色数据点。为了找到一个近似最近邻，HNSW 从入门级（第 2 层）开始，并通过层次结构向下遍历以找到最近的顶点。在遍历的每一步，算法会计算从查询点到当前节点邻居的距离，然后选择距离最小的邻居节点作为下一个基本节点。查询点到最近邻居之间的距离是常用的度量，如欧几里得距离或余弦相似度。当满足某个停止条件（例如距离计算次数）时，搜索终止。\n\n现在让我们看看 HNSW 是如何构造层的。\n\n### HNSW 如何构建数据机构\n\nHNSW 首先初始化一个空图作为数据结构的基础。该图表示一个接一个插入数据点的空间。HNSW 将数据点组织成多层。每一层表示数据结构中不同级别的粒度。层的数量是预先定义的，通常取决于数据的特征。\n\n每个数据点会被随机分配到一个层。最高的层是最粗略的表示，随着层的向下移动，表示就会变得更精细。这个任务是用一个特定的概率分布来完成的，这个概率分布叫做**指数衰减概率分布（exponential decaying probability distribution）**。这种分布使得数据点到达更高层的可能性大大降低。如果你还记得跳跃列表中随机选择的数据点作为“高速公路”，这里的一些数据点是随机选择到最高层的。在后面的代码示例中，我们将看到每层中的数据点数量，并且数据点的数量在更高层中呈指数级减少。\n\n为了在每一层内有效地构建连接，HNSW 使用贪婪搜索算法。它从顶层开始，试图将每个数据点连接到同一层内最近的邻居。一旦建立了一层中的连接，HNSW 将使用连接点作为搜索的起点继续向下扩展到下一层。构建过程一直持续到处理完所有层，并且完全构建了数据结构。\n\n让我们简单总结一下 HNSW 中数据结构的构造。让我也参考 Malkov 和 Yashunin[3] 中的符号，并在附录中解释 HNSW 算法。你可能会发现它们有助于更明确地理解 HNSW 的算法。HNSW 声明一个空结构并逐个插入数据元素。它保持每个数据点每层最多有 M 个连接的属性，并且每个数据点的连接总数不超过最大值（Mmax）。在每一层中，HNSW 找到与新数据点最近的 K 个邻居。然后，它根据距离更新候选数据点集和找到的最近邻居列表（W）。如果 W 中的数据点数量超过了动态候选列表（ef）的大小，则该函数从 W 中删除最远的数据点。\n\n接下来，我将向你展示代码示例。该笔记本可通过<a href=\"https://github.com/dataman-git/codes_for_articles/blob/master/HNSW.ipynb\">此链接</a>获得。\n\n### 代码示例\n\n接下来，让我们使用库 FAISS 执行 HNSW 搜索。我将使用 NLP 中包含新闻文章的流行数据集。然后，我使用“SentenceTransformer”执行 Embeddings。然后，我将向你展示如何使用 HNSW 通过查询搜索类似的文章。\n\n#### data\n\n总检察长的新闻文章语料库由 <a href=\"http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html\">A.Gulli</a>，是一个从2000多个新闻来源收集100多万篇新闻文章的大型网站。Zhang、Zhao和LeCun在论文中构建了一个较小的集合，其中采样了“世界”、“体育”、“商业”和“科学”等新闻文章，并将其用作文本分类基准。这个数据集“ag_news”已经成为一个经常使用的数据集，可以在Kaggle、PyTorch、Huggingface和Tensorflow中使用。让我们从 Kaggle <a href=\"https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset\">下载数据</a>。训练样本和测试样本分别有 12 万篇和 7600 篇新闻文章。\n\n```py\nimport pandas as pd\nimport numpy as np\nimport faiss\npd.set_option('display.max_colwidth', None)\npath = \"/mnt/disk8/djw/anaconda_project/content/gdrive/data\"\n\ntrain = pd.read_csv(path + \"/train.csv\")\ntrain.shape\ntrain.head(5)\n```\n输出形状为(120000,3)，列为['Class Index','Title','Description']。我们对“描述”栏感兴趣。以下是排名前五的记录：\n\n![排名前五的记录](/img/2023-11-20-hnsw/pho7.png)\n\n#### 数据嵌入\n\n出于说明的目的，我只使用10,000条记录进行Embeddings。\n\n```py\nsentences = train['Description'][0:10000]\n```\n\n您需要 pip 安装\"sentence_transformers\"库。\n\n```py\n!pip install sentence_transformers\nfrom sentence_transformers import SentenceTransformer\n```\n\n然后让我们使用预训练模型\"bert-base-nli-mean-tokens\"来声明模型。在<a href=\"https://www.sbert.net/docs/pretrained_models.html\">本页</a>上有许多预先训练好的模型。\n\n```py\nmodel = SentenceTransformer('bert-base-nli-mean-tokens')\n```\n\n然后我们将“句子”编码为“sentence_embeddings”。\n```py\nsentence_embeddings = model.encode(sentences)\nprint(sentence_embeddings.shape)\nsentence_embeddings[0:5]\n```\n\n输出是10,000个列表。每个列表或向量的维数为768。下面是前 5 个 Embeddings 的输出。\n\n![Embeddings](/img/2023-11-20-hnsw/pho8.png)\n\n这有助于保存Embeddings以备将来使用。\n\n```py\nwith open(path + '/AG_news.npy', 'wb') as file:\n    np.save(file, sentence_embeddings)\n```\n\n在上面的代码中，我使用了“npy”文件扩展名，这是 NumPy 数组文件的常规扩展名。下面是加载数据的代码:\n\n```py\nwith open (path + '/AG_news.npy', 'rb') as f:\n    sentence_embeddings = np.load(f, allow_pickle=True)\n```\n\n有了这些 Embeddings，我们就可以在HNSW数据结构中组织它们了。\n\n#### 使用FAISS构建NHSW数据结构索引\n\n您需要像下面这样 pip 安装 FAISS 库：\n\n```py\n!pip install faiss-cpu --no-cache\n```\n\n我将使用 HNSWFlat(dim, m) 类来构建 HNSW。它需要预先确定的参数 dim 表示向量的维数，m 表示数据元素与其他元素连接的边数。\n\n```py\nimport faiss\nm = 32\ndim = 768\nindex = faiss.IndexHNSWFlat(dim, m)\n```\n\n如上所述，HNSW 指数的创建分为两个不同的阶段。在初始阶段，该算法使用概率分布来预测最上层的新数据节点。在随后的阶段中，将收集每个数据点的最近邻居，然后使用一个表示为 m（在我们的示例中为 m = 16）的值进行剪枝。整个过程迭代，从插入层开始，一直到底层。\n\n在 HNSW 中有两个重要的参数 \"efConstruction\" 和 \"efSearch\"。这两个参数控制着索引结构构建的效率和有效性。它们帮助您在 HNSW 索引结构中的索引构造和近邻搜索操作的速度和质量之间取得平衡。\n\n1. \"efConstruction\": 这个参数在 HNSW 指数的构建过程中使用。它控制构建指数结构的速度和结构的质量之间的平衡。\"efConstruction\" 值决定了在构建阶段需要考虑多少候选项。较\n高的 \"efConstruction\" 值将产生更精确的指数结构，但也会使构建过程变慢\n\n2. \"efSearch\": 这个参数用于在 HNSW 索引中查找查询点的最近邻居。\"efSearch\" 值控制搜索速度和搜索质量之间的平衡。较高的 \"efSearch\" 值将导致更精确和穷举搜索，但也会更慢。\n\n我们为 \"efConstruction\" 和 \"efSearch\" 设置了 40 和 16:\n\n```py\nindex.hnsw.efConstruction = 40 \nindex.hnsw.efSearch = 16  \n```\n\n我们已经声明了上面的数据结构。现在我们准备将数据 \"sentence_embeddings\" 一个接一个地插入到数据结构中：\n\n```py\nindex.add(sentence_embeddings)\n```\n\n一旦完成，我们可以检查 HNSW 数据结构中有多少数据元素：\n\n```py\nindex.ntotal\n```\n\n输出为 10000。它是 \"sentence_embeddings\" 中的数据点数。接下来，HNSW 建造了多少层？让我们来检查最大级别：\n\n```py\n# the HNSW index starts with no levels\nindex.hnsw.max_level\n```\n\n最大级别为 2.0。这意味着有第 0、1、2 层。接下来，您可能想知道每层中数据元素的数量。让我们来看看：\n\n```py\nlevels = faiss.vector_to_array(index.hnsw.levels)\nnp.bincount(levels)\n```\n\n输出为 array([0,9713,280,7])。\"0\" 没有意义，你可以忽略它。它说第 0 层有 9713 个数据元素，第 1 层有 280 个元素，第 2 层只有 7 个元素。注意，9713 + 280 + 7 = 10000。您是否发现，较高层的数据元素数量比前几层呈指数级减少？这是因为数据元素的层分配采用指数衰减概率分布。\n\n#### FAISS为HNSW搜索示例\n\n假设我们的搜索查询是“经济繁荣与股市（economic booming and stock market）”。我们希望找到与我们的搜索查询相关的文章。我们将首先嵌入搜索查询：\n\n```py\nqry1 = model.encode([\"economic booming and stock market\"])\n```\n\n使用代码 index.search()，搜索过程非常简单。这里 k 是最近邻居的个数。我们将其设置为 5，即返回 5 个邻居。index.search()函数返回两个值 \"d\" 和 \"I\"。\n\n- \"d\": 查询向量与 k 个最近邻之间的距离列表。默认的距离度量是欧几里得度量。\n- \"i\": 索引中 k 个最近邻居的位置对应的索引列表。这些索引可以用来查找数据集中的实际数据点。\n\n```py\n%%time\nk=5\nd, I = index.search(qry1, k)\nprint(I)\nprint(d)\n```\n\n索引列表的输出是[[6412 6394 9103 3813 1467]]。我们将使用这些索引打印出搜索结果。\n\n注意，我使用 \"%%time\" 来度量执行时间。它输出\n\nCPU times: user 812 ms, sys: 42.6 ms, total: 855 ms\n\n这意味着搜索只需要几百毫秒。这确实是令人难以置信的快!\n\n距离输出列表为：[[155.64159 169.03458 183.2863  190.07074 194.54048]]\n\n```py\nfor i in I[0]:\n  print(train['Description'][i])\n```\n\n![输出](/img/2023-11-20-hnsw/pho10.png)\n\n这些文章都是关于经济和股票市场的新闻。搜索速度以毫秒计非常快。这不仅仅是结果在哪里的问题，而是如何快速得到结果的问题，不是吗?\n\n您可以通过<a href=\"https://github.com/dataman-git/codes_for_articles/blob/master/HNSW.ipynb\">此链接</a>下载笔记本进行上述搜索。\n\n## 总结\n\n我希望这篇文章能帮助你理解近似近邻（ANN），以及它是如何提供高效搜索的。本文介绍了不同的人工神经网络算法，包括基于图的 HNSW，基于哈希的 LSH 或乘积量化，以及基于树的 KD-Trees。是如何构建它的数据结构并逐个插入数据元素的。这篇文章演示了如何使用 FAISS 库构建用于查询搜索的 HNSW。\n\n## 附录\n\n在 Malkov 和 Yashunin [3]的论文中，算法 1 到 5 伪代码中介绍了 HNSW 算法。伪代码给出了算法的具体定义。我在伪代码中加入了以下的描述，可能会帮助一些读者更轻松地理解 HNSW。算法 1、算法 2、算法 3 和算法 4 中的任意一个，都可被用来构建数据结构。但一旦数据结构完成，任何未来的查询搜索只使用算法 5。\n\n- 算法1:\"INSERT\"函数构造数据结构\n- 算法2:\"SEARCH-LAYER\"函数计算 KNN 并存储邻居\n- 算法3:\"SEARCH-NEIGHBORS-SIMPLE\"函数是一种选择邻居的简单方法\n- 算法4:\"SELECT-NEIGHBORS-HEURISTIC\"函数是一种更复杂的选择邻居的方法\n- 算法5:\"KNN-SEARCH\"函数进行查询搜索\n\n### 算法一：INSERT()\n\n```py\nAlgorithm 1: INSERT()\n\nINSERT(hnsw, q, M, Mmax, efConstruction, mL)\nInput: multilayer graph hnsw, new element q, number of established\nconnections M, maximum number of connections for each element\nper layer Mmax, size of the dynamic candidate list efConstruction, nor-\nmalization factor for level generation mL\nOutput: update hnsw inserting element q\n\n1 W ← ∅ // list for the currently found nearest elements\n2 ep ← get enter point for hnsw\n3 L ← level of ep // top layer for hnsw\n4 l ← ⌊-ln(unif(0..1))∙mL⌋ // new element’s level\n5 for lc ← L … l+1\n6 W ← SEARCH-LAYER(q, ep, ef=1, lc)\n7 ep ← get the nearest element from W to q\n8 for lc ← min(L, l) … 0\n9 W ← SEARCH-LAYER(q, ep, efConstruction, lc)\n10 neighbors ← SELECT-NEIGHBORS(q, W, M, lc) // alg. 3 or alg. 4\n11 add bidirectionall connectionts from neighbors to q at layer lc\n12 for each e ∈ neighbors // shrink connections if needed\n13 eConn ← neighbourhood(e) at layer lc\n14 if │eConn│ > Mmax // shrink connections of e\n// if lc = 0 then Mmax = Mmax0\n15 eNewConn ← SELECT-NEIGHBORS(e, eConn, Mmax, lc)\n// alg. 3 or alg. 4\n16 set neighbourhood(e) at layer lc to eNewConn\n17 ep ← W\n18 if l > L\n19 set enter point for hnsw to q\n20 return hnsw\n```\n\n它在多层图中插入一个新元素 q，保证每个元素每层最多有 M 个连接，并且每个元素的连接总数不超过 Mmax。该算法还保证了连通元素之间的距离不大于某个最大距离，并且每层的连通数是均衡的。具体步骤如下:\n\n01. W ← ∅：初始化一个空列表 W 来存储当前找到的最近的元素。\n02. ep ← get enter point for hnsw：获取多层图 HNSW 的进入点（即初始点）\n03. L ← level of ep：获取进入点 ep 的级别。\n04. l ← ⌊-ln(unif(0..1))∙mL⌋：为新元素 q 生成一个介于 0 和 mL 之间的随机级别，其中 mL 是级别生成的归一化因子。\n05. for lc ← L … l+1：循环从 L 到 l + 1 的层。\n06. W ← SEARCH-LAYER(q, ep, ef=1, lc)：使用进入点 ep 和最大距离 ef=1 在 lc 层中搜索离 q 最近的元素。将找到的元素存储在列表 W 中。\n07. ep ← get the nearest element from W to q：取 W 到 q 最近的元素。\n08. for lc ← min(L, l) … 0：循环遍历从 min(L, l) 到 0 的层。\n09. W ← SEARCH-LAYER(q, ep, efConstruction, lc)：使用进入点 ep 和最大距离 efConstruction 在 lc 层中搜索离 q 最近的元素。将找到的元素存储在列表 w 中。\n10. neighbors ← SELECT neighbors (q, W, M, lc)：选择 W 到 q 最近的 M 个邻居，只考虑 lc 层的元素。\n11. add bidirectionall connectionts from neighbors to q at layer lc： 在 lc 层的 q 和选定的邻居之间添加双向连接。\n12. 12~14：对于每个e∈neighbors，如果需要收缩连接，对于 q 的每个邻居 e，检查 e 的连接数是否超过 Mmax。如果超过，使用SELECT neighbors (e, eConn, Mmax, lc) 选择一组新的邻居来收缩 e 的连接，其中 eConn 是 e 在 lc 层的当前连接集。\n13. eNewConn ← SELECT-NEIGHBORS(e, eConn, Mmax, lc)：为 e 选择一组新的邻居，只考虑 lc 层的元素，保证连接数不超过 Mmax。\n14. set neighbourhood(e) at layer lc to eNewConn：将层lc 的 e 的连接集更新为新的集合 eNewConn。\n15. ep ← W：设置 hnsw 的进入点为 q。\n16. if l > L，将 hnsw 的起始点设为 q，因为新元素 q 现在是图的一部分。\n17. 返回更新后的多层图 hnsw。\n\n### 算法二：SEARCH-LAYER()\n\n该算法对 HNSW 数据结构进行 k 近邻搜索，以查找特定层 lc 中与查询元素 q 最近的 k 个元素。然后，根据查询元素 q 与候选元素 C 和 e 之间的距离更新候选元素集合 C 和找到的最近邻居列表 W，最后，如果 W 中的元素个数超过动态候选列表 ef 的大小，则函数移除从 W 到 q 的最远元素。\n\n```py\nAlgorithm 2: SEARCH-LAYER()\n\nSEARCH-LAYER(q, ep, ef, lc)\nInput: query element q, enter points ep, number of nearest to q ele-\nments to return ef, layer number lc\nOutput: ef closest neighbors to q\n1 v ← ep // set of visited elements\n2 C ← ep // set of candidates\n3 W ← ep // dynamic list of found nearest neighbors\n4 while │C│ > 0\n5 c ← extract nearest element from C to q\n6 f ← get furthest element from W to q\n7 if distance(c, q) > distance(f, q)\n8 break // all elements in W are evaluated\n9 for each e ∈ neighbourhood(c) at layer lc // update C and W\n10 if e ∉ v\n11 v ← v ⋃ e\n12 f ← get furthest element from W to q\n13 if distance(e, q) < distance(f, q) or │W│ < ef\n14 C ← C ⋃ e\n15 W ← W ⋃ e\n16 if │W│ > ef\n17 remove furthest element from W to q\n18 return W\n```\n\n以下是上述代码的步骤：\n\n01. 初始化变量 v 为当前的入口点 ep。\n02. 初始化集合 C 为当前候选集合。\n03. 初始化一个空列表 W 来存储找到的最近邻。\n04. 循环直到候选集合 C 中的所有元素都被计算完毕。\n05. 从候选元素集合 C 中提取离查询元素 q 最接近的元素 c。\n06. 获取从找到的最近邻 W 到查询元素 q 的列表中最远的元素 f。\n07. 如果 c 到 q 的距离大于 f 到 q 的距离：\n08. 然后打破这个循环。\n09. 对于 lc 层 c 邻域内的每个元素 e：\n10. 如果 e 不在访问元素 v 的集合中，则：\n11. 将 e 添加到访问元素 v 的集合中。\n12. 设 f 为从 W 到 q 的最远的元素。\n13. 如果 e 和 q 之间的距离小于等于 f 和 q 之间的距离，或者 W 中的元素个数大于等于 ef（动态候选列表的大小），则：\n14. 将候选集 C 更新为 C∈e。\n15. 将发现的最近邻居 W 的列表更新为 W∈e。\n16. 如果W中的元素个数大于等于 ef，则:\n17. 移除从 W 到 q 的最远的元素。\n18. 返回找到的最近邻居 W 的列表。\n\n### 算法三：SELECT-NEIGHBORS-SIMPLE()\n\n这是一个简单的近邻选择算法，它以一个基本元素 q、一组候选元素 c 和若干近邻 m 作为输入。它从候选元素 c 的集合中返回 m 个离 q 最近的元素。\n\n```py\nAlgorithm 3: SELECT-NEIGHBORS-SIMPLE()\n\nSELECT-NEIGHBORS-SIMPLE(q, C, M)\nInput: base element q, candidate elements C, number of neighbors to\nreturn M\nOutput: M nearest elements to q\nreturn M nearest elements from C to q\n```\n\n步骤如下：\n\n01. 初始化一个空集 R 来存储选中的邻居。\n02. 初始化一个工作队列 W 来存储候选元素。\n03. 如果设置了 extendCandidates 标志（即true），则通过将 C 中每个元素的邻居添加到队列 W 来扩展候选列表。\n04. 而 W 的大小大于 0，R 的大小小于 M：\n05. 从 W 到 q 中提取最近的元素 e。\n06. 如果 e 比 R 中的任何元素更接近 q，把 e 加到 R 中。\n07. 否则，将 e 添加到丢弃队列 Wd 中。\n08. 如果设置了 keepPrunedConnections 标志（即true），则从 Wd 添加一些丢弃的连接到R。\n09. 返回 R。\n\n### 算法四：SELECT-NEIGHBORS-HEURISTIC()\n\n这是一个更复杂的近邻选择算法，它接受一个基本元素 q、一组候选元素 c、一些邻居 m、一个层数 lc 和两个标志 extend candidates 和 keepPrunedConnections 作为输入。它返回启发式选择的 m 个元素。\n\n```py\nAlgorithm 4: SELECT-NEIGHBORS-HEURISTIC()\n\nSELECT-NEIGHBORS-HEURISTIC(q, C, M, lc, extendCandidates, keep-\nPrunedConnections)\nInput: base element q, candidate elements C, number of neighbors to\nreturn M, layer number lc, flag indicating whether or not to extend\ncandidate list extendCandidates, flag indicating whether or not to add\ndiscarded elements keepPrunedConnections\nOutput: M elements selected by the heuristic\n1 R ← ∅\n2 W ← C // working queue for the candidates\n3 if extendCandidates // extend candidates by their neighbors\n4 for each e ∈ C\n5 for each eadj ∈ neighbourhood(e) at layer lc\n6 if eadj ∉ W\n7 W ← W ⋃ eadj\n8 Wd ← ∅ // queue for the discarded candidates\n9 while │W│ > 0 and │R│< M\n10 e ← extract nearest element from W to q\n11 if e is closer to q compared to any element from R\n12 R ← R ⋃ e\n13 else\n14 Wd ← Wd ⋃ e\n15 if keepPrunedConnections // add some of the discarded\n// connections from Wd\n16 while │Wd│> 0 and │R│< M\n17 R ← R ⋃ extract nearest element from Wd to q\n18 return R\n```\n\n步骤如下：\n\n01. 初始化三个队列：R 用于选择的邻居，W 用于工作的候选，Wd 用于丢弃的候选。\n02. 设置 R 的大小为 0，W 的大小为 C 的大小。\n03. 如果 extendCandidates 被设置（即，true）：\n04. 对于 C 中的每个元素 e：\n05. 对于第 lc 层 e 的每一个邻居 eadj：\n06. 如果 eadj 不在 W 中，则在 W 中添加它。\n07. 而 W 的大小大于 0，R 的大小小于 M：\n08. 从 W 到 q 中提取最近的元素 e。\n09. 如果 e 比 R 中的任何元素更接近 q，把 e 加到 R 中。\n10. 否则，将 e 加到 Wd。\n11. 如果设置了 keepPrunedConnections（即true）：\n12. 而 Wd 的大小大于 0，R 的大小小于 M：\n13. 从 Wd 到 q 中提取最近的元素 e。\n14. 如果 e 比 R 中的任何元素更接近 q，就把 e 加到 R 中。\n15. 返回 R。\n\n### 算法五：K-NN-SEARCH()\n\n这个搜索算法与算法1基本相同。\n\n```py\nAlgorithm 5: K-NN-SEARCH()\n\nK-NN-SEARCH(hnsw, q, K, ef)\nInput: multilayer graph hnsw, query element q, number of nearest\nneighbors to return K, size of the dynamic candidate list ef\nOutput: K nearest elements to q\n1 W ← ∅ // set for the current nearest elements\n2 ep ← get enter point for hnsw\n3 L ← level of ep // top layer for hnsw\n4 for lc ← L … 1\n5 W ← SEARCH-LAYER(q, ep, ef=1, lc)\n6 ep ← get nearest element from W to q\n7 W ← SEARCH-LAYER(q, ep, ef, lc =0)\n8 return K nearest elements from W to q\n```\n\n步骤如下：\n\n01. 初始化一个空集合 W（当前最近元素的集合），并将进入点 ep 设置为网络的顶层。\n02. 设置进入点 ep 的级别设置为顶层 L。\n03. 对于每一层 lc，从 L 到 1（即从顶层到底层）:\n04. 使用查询元素 q 和当前最近的元素 W 搜索当前层，并将最近的元素添加到 W 中。\n05. 将进入点 ep 设置为 W 到 q 最近的元素。\n06. 使用查询元素 q 和当前最近的元素 W 搜索下一层，并将最近的元素添加到 W 中。\n07. 返回 W 中最接近的 K 个元素作为输出。\n\n## 参考文献\n\n- [1] Pugh, W. (1990). Skip lists: A probabilistic alternative to balanced trees. Communications of the ACM, 33(6), 668–676. doi:10.1145/78973.78977. S2CID 207691558.\n- [2] Xiang Zhang, Junbo Zhao, & Yann LeCun. (2015). Character-level Convolutional Networks for Text Classification\n- [3] Yu. A. Malkov, & D. A. Yashunin. (2018). Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs.\n- [4] Aristides Gionis, Piotr Indyk, Rajeev Motwani, et al. 1999. Similarity search in high dimensions via hashing. In Vldb, Vol. 99. 518–529.","tags":["向量数据库"]},{"title":"linux_centos 安装 cmake","url":"/2023/11/06/2023-11-06-cmake-an-zhuang/","content":"\n## 卸载已安装的 cmake\n\n```c\ncmake --version\n\n# 若已安装版本以满足我们需求，则不需要更新安装\n# 如果已安装版本不符合我们需求，则下卸载旧版\n\nyum remove -y cmake\n```\n\n## 下载 cmake\n\n前往官网 <a href=\"https://cmake.org/\">CMake</a> 下载我们需要的版本，我们 <a href=\"https://cmake.org/files/v3.26/\">下载最新稳定版3.26.4</a> 并安全验证。\n\n```c\ncurl -OL https://cmake.org/files/v3.26/cmake-3.26.4-SHA-256.txt\ncurl -OL https://cmake.org/files/v3.26/cmake-3.26.4.tar.gz\n\n-- 安全验证：\n[root@pudding cmake]# sha256sum -c cmake-3.26.4-SHA-256.txt\n# 其他版本未找到日志已忽略\ncmake-3.26.4.tar.gz: OK\nsha256sum: WARNING: 16 listed files could not be read\n```\n\n## 解压，编译安装\n\n```c\ntar zxvf cmake-3.26.4.tar.gz && cd cmake-3.26.4\n\n./bootstrap && gmake && gmake install\n```\n\n### 缺少 c/c++ 编译环境：\n\n```c\n[root@pudding cmake-3.26.4]# ./bootstrap && gmake && gmake install\n---------------------------------------------\nCMake 3.26.4, Copyright 2000-2023 Kitware, Inc. and Contributors\n---------------------------------------------\nError when bootstrapping CMake:\nCannot find appropriate C compiler on this system.\nPlease specify one using environment variable CC.\nSee cmake_bootstrap.log for compilers attempted.\n\n---------------------------------------------\nLog of errors: /home/work/cmake-3.26.4/Bootstrap.cmk/cmake_bootstrap.log\n---------------------------------------------\n```\n\n**安装 gcc|g++**\n\n```c\nsudo yum -y install gcc gcc-c++ kernel-devel\n\ngcc --version\ng++ --version\n```\n\n## 建立软链接\n\n```c\n[root@pudding cmake-3.26.4]# /usr/local/bin/cmake --version\ncmake version 3.26.4\n\nCMake suite maintained and supported by Kitware (kitware.com/cmake).\n[root@pudding cmake-3.26.4]# ln -s /usr/local/bin/cmake /usr/bin\n[root@pudding cmake-3.26.4]# cmake --version\ncmake version 3.26.4\n\nCMake suite maintained and supported by Kitware (kitware.com/cmake).\n```","tags":["Linux"]},{"title":"linux 安装 python 3.10","url":"/2023/10/26/2023-10-26-linux-an-zhuang-python-3.10/","content":"\n## 相关工具安装\n\n```shell\nyum -y groupinstall \"Development tools\"\nyum -y install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel\nyum install libffi-devel -y\n```\n\n## openssl 安装\n\n```shell\ncd /home/\n\nwget http://www.openssl.org/source/openssl-1.1.1.tar.gz\n\ntar -zxvf openssl-1.1.1.tar.gz\n\ncd openssl-1.1.1/\n\nmkdir /usr/local/openssl\n\n./config --prefix=/usr/local/openssl --openssldir=/usr/local/openssl\n\nmake && make install\n```\n\n## python 3.10 安装\n\n```shell\ncd /home\n\nwget https://www.python.org/ftp/python/3.10.8/Python-3.10.8.tgz\n\ntar -zxvf Python-3.10.8.tgz\n\ncd Python-3.10.8\n\nmkdir /usr/local/python310\n\n./configure --prefix=/usr/local/python310 --with-openssl=/usr/local/openssl --with-openssl-rpath=auto\n\nmake && make install\n```\n\n## 设置软链接\n\n```shell\nsudo ln -s /usr/local/python310/bin/python3.10 /usr/bin/python310\nsudo ln -s /usr/local/python310/bin/pip3.10 /usr/bin/pip310\n```\n\n## 一些 pip 源\n\n```josn\nhttps://pypi.tuna.tsinghua.edu.cn/simple\nhttps://pypi.mirrors.ustc.edu.cn/simple\nhttp://pypi.douban.com/simple/\nhttp://mirrors.aliyun.com/pypi/simple/\n```","tags":["Python"]},{"title":"向量检索简介","url":"/2023/10/11/2023-10-11-xiang-liang-jian-suo-jian-jie/","content":"\n1. 向量检索在推荐系统，图片检索，语义检索中均有⼤量应用\n2. 向量检索的核心是 ANN（Approximate Nearset Neighbor）问题\n3. 旨在向量空间中找到与查询向量近似最近邻的向量\n\n## 1 何为相似\n\n评估两个向量的相似程度有多种指标（Metrics）\n\n- 欧式距离（Euclidean Distance）\n- 余弦相似度（Cosine Similarity）\n- 杰卡德相似度（Jaccard Similariy）\n\n### 1.1 欧氏距离（Euclidean Distance）\n\n**即欧氏空间中，两个向量的距离**\n\n$$\\sum_{i=1}^{n} (x_i - y_i)^2 = \\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2 + \\ldots + (x_n - y_n)^2}$$\n\n### 1.2 余弦相似度（Cosine Similarity）\n\n**两个向量间的角距离**\n\n$$cos(θ)=\\frac{x \\cdot y}{||x|| \\cdot ||y||}$$\n\n### 1.3 杰卡德相似度（Jaccard Similariy）\n\n**两个向量交集占并集的比例**\n\n$$J(A,B)=\\frac{|A∩B|}{|A∪B|}$$\n\n不同的评价指标从不同的⾓度分析数据\n\n## 2 向量索引算法\n\n最直接的方法是查询向量遍历向量空间中所有的向量计算距离暴力解，缺点是计算复杂度过高。\n\n**为了加快查找的速度，几乎所有的 ANN 方法都是通过对全空间分割，将其分割成很多⼩的子空间，在搜索的时候，通过某种方式，快速锁定在某⼀（多）个子空间，然后在该（多个）子空间里做遍历。**\n\n目前主流方法分为四大类：\n\n### 2.1 基于树的方法\n\n**KD 树**\n\n下面是 KD 树对全空间的划分过程，以及用树这种数据结构：\n\n![KD树的子划分（左）和树结构（右）](/img/2023-10-11-向量检索简介/pho1.png)\n\nKD 树选择从哪一维度进行开始划分的标准，采用的策略是：求每一个维度的方差，然后选择方差最大的那个维度开始划分。\n\n**为何要选择方差作为维度划分选取的标准？**\n\n- 因为方差的大小可以反映数据的波动性。方差大表示数据波动性越大，选择方差最大作为划分空间标准的好处在于，可以使得所需的划分面数据最小，反映到树数据结构上，可以使得我们构建的 KD 树的树深度尽可能的小。\n\n一般而言，在空间维度比较低的时候，KD树是比较高效的，当空间维度较高时，可以用小面即将介绍的哈希方法或者矢量量化方法。\n\n### 2.2 哈希方法\n\n通过哈希函数将连续的实值散列化为 0、1 的离散值，将向量以相似性为度量指标进行分割，将向量归类到不同的桶（cell）中。\n\n查找时，查询向量通过哈希函数后，也会归类到相似向量的桶中，以缩小检索范围。\n\n工程中的经典方法是**局部敏感哈希（Local Sensitive Hashing, LSH）**，即相近的样本点对比较远的样本点更容易发生碰撞。\n\n![Local Sensitive Hashing](/img/2023-10-11-向量检索简介/pho2.png)\n\n**LSH 中重要的参数：**\n\n- K，每一个哈希表的哈希函数（空间划分）数目\n- L，哈希表（每一个哈希表有 K 个哈希函数）的数目\n- T，近邻哈希桶的数目，即 the number of probes\n\n为了增加 LSH 召回率精度，在查询向量落入桶周围时，再选几个近邻的桶，以增加召回率。\n\n通常 K T 之间要做取舍，哈希函数数目 K 越大，相应地，近邻哈希桶的数目的数目 T 也应该设置的越大，反之 K 越小，L 也可以相应的减小。\n\n### 2.3 矢量量化方法\n\n乘积量化（Product Quantization，PQ）是 Herve Jegou 在 2011 年提出的一种非常经典实用的矢量量化索引的方法，在工业界向量索引中已得到广泛的应用，并作为主要的向量索引方法，在 Fasis 中有非常高效的实现。乘积量化的核心思想是分段（划分子空间）和聚类，或者说具体应用到 ANN 近似最近邻搜索上，KMeans 是 PQ 乘积量化子空间数目为 1 的特例。PQ 乘积量化生成码本和量化的过程可以用如下图示来说明：\n\n![PQ 乘积量化生成码本和量化的过程](/img/2023-10-11-向量检索简介/pho3.png)\n\n在训练阶段，针对 N 个训练样本，假设样本维度是 128 维，我们将其划分为 4 个子空间，则每一个子空间的维度为 32 维，然后我们在每一个子空间中，对子向量采用 K-Means 对其进行聚类（图中示意聚类为 256 类），这样每一个子空间都能得到一个码本。这样训练样本的每个子段，都可以用子样本仅使用的最短的一个编码得以表示，从而达到量化的目的。对于待编码的样本，将它进行相同的切分，然后在每个子空间里逐一找到距离它们最近的类中心，然后用类中心的 id 来表示它们，即完成了待编码样本的编码。\n\n查询阶段有两种计算距离方式：\n\n1. 对称距离，用于查询向量对应的类中心代表查询向量的位置，各个类中心代表各个类中所有点的位置，计算类中心间的距离。该方式计算快，但损失精度大。\n2. 非对称距离，用于查询向量本身位置，各个类中心代表各个类中所有点的位置，计算查询向量到每个类中心的位置。该方式计算较快，且损失精度较低。\n\n同时对特征进行编码后，可以用一个相对比较短的编码来表示样本，对于内存的消耗要显著减少。\n\n倒排 PQ 乘积量化（IVFPQ）是 PQ 乘积量化的进一步加速版。\n\n其算法思想是，在 PQ 乘积量化之前，增加了一个粗量化过程。先对 N 个训练样本采用 KMeans 进行聚类，这里聚类的数目一般不超过 1024。在得到了聚类中心后，针对每一个样本查询向量，在对应的聚类中心再进行 PQ。\n\n**IVFPQ 中的主要参数：**\n- nProbe：IVF 中聚类中心数，聚类中心越多，分类越精细，查询越慢\n- N：将向量平均分为 N 个子向量，子向量段数越多，分类越精细，查询越慢\n- K：将每个子向量聚类为 $2^K$ 个聚类中心，聚类中心越多，分类越精细，查询越慢\n\n### 2.4 基于图索引量化方法\n\nHierarchical Navigable Small World Graphs（HNSW）是 Yury A. Malkov 提出的一种基于图索引的方法，它是 Yury A. Malkov 在他本人之前工作 NSW 上的一种改进，通过采用分层状结构，将边按特征半径进行分层，是每个顶点在所有层中平均度数边为常数，从而将 NSW 的计算复杂度由多重对数（Ploylogarithmic）复杂度降低到了对数（logarithmic）复杂度。\n\n![Hierarchical结构](/img/2023-10-11-向量检索简介/pho4.png)\n\n每一个插入的元素对应的最大 layer 由指数衰减概率分布函数给出\n\n```c\nmult_ = 1/log(1.0 * M_);\nrevSize_ = 1.0/mult_;\nstd:uniform_real_distribution<double> distribution(0.0,1.0);\ndouble r = -log(distribution(level generator_)) * revSize_\n```\n\n- 从最大层 layer 开始贪心遍历，寻找局部最小值（最近邻）\n- 将当前层找到的最近邻作为进入点（entry point）在下一层寻找局部最小。\n\n从若干输入点（随机抽取或分割算法）开始迭代整个近邻图。整个搜索过程可以类比在地图上某个位置空间的过程：我们可以把地球当作最顶层，五大洲作为第一层，国家作为第三层，省份作为第四层……，现在如果要找海淀五道口，我们可以通过顶层以逐步递减的特征半径对其进行路由（第一层地球->第二层亚洲->第三层中国->第四层北京->海淀区），到了第 0 层后，再在局部区域做更细致的搜索。\n\n**HNSW 索引的主要参数：**\n\n- M：每个向量在图中的邻居数，M越大，图中每个顶点邻居越多，图越精细，建索引时间越长，查询时间越久，召回率越高，推荐范围 5~100\n- ef_construction：构建图时，每个顶点候选的最近邻居，值越大，图越精细，建索引时间越长，查询越久，召回率越高，推荐范围 100~2000\n- num_candidates：查询时，要返回的总候选最近向量数，值越大，召回率越大，查询时间越久，值不能超过 10000\n- ef_search：搜索时，每个顶点候选的最近邻居数，值越大，查询时间越久，召回率越高，推荐范围 100~2000\n\n## 3 Faiss 向量检索库\n\n### 3.1 基础索引类型\n\n|索引类型|索引简介|全量检索|内存占用|召回率|查询速率|适用场景|\n|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n|IndexFlatL2|计算L2距离暴力搜索|是|中等|准确结果|低|百万数据量|\n|IndexFlatIP|计算内积暴力搜索|是|中等|准确结果|低|百万数据量|\n|IndexHNSWFlat|使用HNSW图结构加速搜索|否|高|高|中|千万数据量|\n|IndexIVFFlat|使⽤聚类缩⼩检索范围|否|中等|高|中|千万数据量|\n|IndexLSH|使用哈希方法将向量二进制化加速搜索|否|低|高|中|千万数据量|\n|IndexScalarQuantizer|使⽤标量量化将向量降维加速搜索|是|中等|中等|中|千万数据量|\n|IndexPQ|使⽤乘积量化将向量降维加速搜索|是|低|中等|高|千万数据量|\n|IndexIVFScalarQuantizer|先使用聚类在使用标量量化降维|是|中等|中等|高|千万数据量|\n|IndexIVFPQ|先使用聚类再使用乘积量化降维|否|低|低|高|亿级数据量|\n|IndexIVFPQR|先使用聚类再使用乘积量化降维最后重排序|否|低|低|中|亿级数据量|\n\n### 3.2 Faiss 索引选取\n\n向量检索主要是检索速度和召回率之间的权衡\n\nL2 距离暴力搜索一定可以得到精准结果，但由于全库遍历的 L2 计算，速度过慢，一般作为评估召回率的基准\n\n目前的主流算法均从以下方面或结合优化检索速度：\n- 缩小搜索范围（IVF|LAS|HNSW）\n- 向量降维以减少内存使用（PQ|SQ）\n\n但这也不可避免地在不同程度上牺牲了检索精度，每种算法的参数也决定了速度与精度间的平衡\n\n#### 3.2.1 需要精确结果\n\n- 使用 IndexFlatL2 或 IndexFlatIP，不需要压缩数据或训练，常作为其他索引检索结果的基准\n- 支持 GPU 加速\n\n#### 3.3.2 需要考虑内存限制\n\n**内存充裕**\n\n- IndexHNSWFlat 是最优选，速度与精度俱佳，然而十分消耗内存，不训练且不支持删除\n- 支持 GPU 加速\n\n**需要考虑**\n\n- 可以先聚类，再使用 FlatL2 或 FlatIP\n- 支持 GPU 加速\n\n**内存有限**\n\n- 使用 OPQ 降低向量维度\n- 使用 PQ 量化向量\n- 支持 GOU 加速（OPQ 降维在 CPU 中进行，但不是性能瓶颈）\n\n#### 3.3.3 需要考虑数据集大小\n\n**低于 1 百万**\n\n- IVF 使用 K-means 聚类\n- 支持 CPU 加速\n\n**1 百万 - 1千万**\n\n- IVF 使用 HNSW 聚类，需要 30 × 65536 到 256 × 65536 个向量训练\n- 不支持 GPU 加速\n\n**1 千万 - 1 亿**\n\n- 依然使用 HNSW 聚类，需要 30 × 262144 ($2^{18}$) 到 256 × 262144 ($2^{18}$) 个向量训练\n- 只在 GPU 上训练，其他步骤在 CPU 进行，参考 <a href=\"https://gist.github.com/mdouze/46d6bbbaabca0b9778fca37ed2bcccf6\"> train_ivf_with_gpu.ipynb</a>\n- 使用二级聚类，<a href=\"https://gist.github.com/mdouze/1b2483d72c0b8984dd152cd81354b7b4\">demo_two_level_clustering.ipynb</a>\n\n**1 亿 - 10 亿**\n\n同上 65536 替换成 1048576 ($2^{20}$)\n\n## 参考链接\n- <a href=\"https://towardsdatascience.com/9-distance-measures-in-data-science-918109d069fa\">Distance Measures in Data Science</a>\n- <a href=\"https://github.com/FALCONN-LIB/FALCONN/wiki/LSH-Primer\">Locality-Sensitive Hashing: a Primer</a>\n- <a href=\"https://inria.hal.science/inria-00514462/document\">Product Quantizer</a>\n- <a href=\"https://arxiv.org/abs/1603.09320\">Hierarchical Navigable Small World Graphs</a>\n- <a href=\"https://github.com/facebookresearch/faiss\">faiss</a>\n","tags":["向量数据库"],"categories":["向量数据库"]},{"title":"向量相似性解释","url":"/2023/10/09/2023-10-09-vector-similarity-explained/","content":"\n在自然语言处理和计算机视觉等领域，向量嵌入已被证明是一个高校的工具。比较项链嵌入并确定它们的相似性是语义检索、推荐系统和异常检测等等的重要组成部分。\n\n在本文中，我们将更深入地了解这些相似度量是如何工作的，以直观地了解在特定用例的上下文中两个向量嵌入相似意味着什么。例如，在自然语言处理中，如果表示词义的两个向量如果在相似的上下文中使用或有着相似的含义，那么它们可能是“接近”的；在推荐系统的背景下，如果表示用户偏好的两个向量有共同的兴趣或者之前做出了相同的选择，那么它们可能是相似的。\n\n在下面的表格中，您可以看到我们将在本文中讨论的相似性度量，以及影响度量的向量的属性。\n\n**Table 1: Similarity metrics**\n\n| Similarity Metric | Vector properties considered |\n|:---:|:---:|\n| Euclidean distance | Magnitudes and direction |\n| Cosine similarity | Only direction |\n| Dot product similarity | Magnitudes and direction |\n\n## Euclidean distance\n\n欧几里得距离（Euclidean distance）是多维空间中两个向量之间的直线距离。\n\n![图1: 二维欧几里得度量测量](/img/2023-10-09-vector_similarity_explained/pho1.png)\n\n它被计算为向量相应分量之间差值平方和的平方根。以下是计算两个向量 a 和 b 之间的欧几里得距离的方程：\n\n$$ d(a,b) = \\sqrt{(a_1-b_1)^2+(a_2-b_2)^2+...+(a_n-b_n)^2} $$\n\n要计算两个向量 a 和 b 之间的欧几里德距离，该方程首先计算两个向量的第一个分量 $(a_1-b_1)$ 之间的差，然后计算第二个分量 $(a_2-b_2)$ 之间的差，依此类推，直到它到达第 n 个分量 $(a_n-b_n)$。然后将差值平方并相加，并取总和的平方根得出最终距离。\n\n该度量对向量大小以及向量在空间中的相对位置敏感。这意味着具有大值的向量将比具有小值的向量具有更大的欧几里得距离，即使这些向量在其他方面相似。这可以正式表达如下：\n\n$$d(ɑx,ɑy)=ɑd(x,y)$$\n\n欧几里德距离是一个非常直观的相似性度量，因为它反映了被比较的向量的每个值之间的距离: 如果欧几里德距离非常小，则向量中每个坐标的值非常接近。对于点积或余弦来说，通常情况并非如此。\n\n在大多数情况下，您不会直接将其用于深度学习模型，而是与使用更基本的向量编码方法（例如LSH（局部敏感哈希））创建的模型一起使用。换句话说，当模型没有使用特定的损失函数进行训练时，欧几里德距离是一个自然的选择。\n\n由于欧几里得距离对大小敏感，因此当嵌入包含与事物的计数或测量有关的信息时，它会很有帮助。例如，在目标是推荐与用户之前购买的商品相似的推荐系统中：欧几里得距离可以用来衡量商品购买时间嵌入量之间的绝对差异。\n\n## Dot product Similarity\n\n两个向量的点积相似度（Dot product Similarity）度量是通过将向量对应分量的乘积相加来计算的。向量 a 和 b 的点积计算如下：\n\n$$ a \\cdot b = \\displaystyle \\sum^{n}_{i=1}{a_ib_i} = a_1b_1+a_2b_2+...+a_nb_n $$\n\n其中 a 和 b 是要比较的向量，$a_i$ 和 $b_i$ 是向量的分量。点积是通过将向量分量相乘并将结果相加来计算的。\n\n如下所示，点积也可以表示为向量的大小与它们之间的角度的余弦的乘积：\n\n$$ a \\cdot b = |a||b|cosɑ $$\n\n![图2: 二维点积测量](/img/2023-10-09-vector_similarity_explained/pho2.png)\n\n点积是标量值，这意味着它是单个数字而不是向量。如果向量之间的角度小于 90 度，则点积为正；如果向量之间的角度大于 90 度，则点积为负；如果向量正交，则点积为零。\n\n点积会受到向量长度和方向的影响。当两个向量长度相同但方向不同时，如果两个向量指向相同方向，则点积较大；如果两个向量指向相反方向，则点积较小。想象由箭头表示的两个向量，向量 a 和向量 b 。如果向量 a 和 b 彼此指向相同方向，则 a 和 b 的点积将大于 a 和 b 指向相反方向时的点积。\n\n您可能会遇到许多使用点积进行训练的大型语言模型 (LLM)。\n\n在基于协同过滤和矩阵分解的推荐系统中，每个用户和每个项目（例如电影）都有一个嵌入，并且学习模型分析用户嵌入和项目嵌入之间的点积来预测用户对这个项目的评分。现在，如果两个产品的嵌入方向相同但大小不同，这可能意味着这两个产品是关于同一主题的，但幅度较大的一个产品比另一个产品更好/更受欢迎。\n\n## Cosine Similarity\n\n余弦相似度（Cosine Similarity）是两个向量之间角度的度量。它是通过向量的点积除以它们的大小的乘积来计算的。该度量不受向量大小的影响，而仅受向量之间的角度的影响。这意味着具有大值或小值的向量只要指向相同的方向，就会具有相同的余弦相似度。以下是计算向量a和b的余弦相似度的方法：\n\n$$ sim(a,b)= \\frac{a \\cdot b}{||a|| \\cdot ||b||} $$\n\n其中 a 和 b 是要比较的向量，“•”代表点积，||a|| 和||b|| 代表向量的长度。余弦相似度介于 -1 和 1 之间，其中 1 表示角度为 0（向量尽可能接近），0 表示正交，-1 表示向量指向相反方向。\n\n![图 3：二维余弦相似度测量](/img/2023-10-09-vector_similarity_explained/pho3.png)\n\n首先，该方程通过将向量的分量相乘并将结果相加来计算向量的点积。然后将点积除以向量幅值的乘积，向量幅值的乘积是通过对向量分量的平方和求平方根来计算的。\n\n如果模型是使用余弦相似度进行训练的，则您可以使用余弦相似度或标准化并使用点积。请注意，它们在数学上是等效的。在某些情况下，归一化和使用点积更好，而在某些情况下，使用余弦相似度更好。\n\n余弦相似度的一个示例用例是解决语义搜索和文档分类问题，因为它允许您比较向量的方向（即文档的整体内容）。同样，旨在根据用户过去的行为向用户推荐项目的推荐系统可以使用这种相似性度量。\n\n当您的数据中向量的大小很重要并且在确定相似性时应考虑到时，余弦相似度可能不适合。例如，它不适合根据像素强度比较图像嵌入的相似度。\n\n## 总结 \n\n在为索引选择相似度量时，请记住我们在本文介绍中提到的一般原则: 使用用于训练嵌入模型的相似度量。否则，您应该尝试各种其他的相似性度量，看看是否可以产生更好的结果（例如，如果您不知道嵌入模式中使用了什么相似性度量，或者创建向量的方法在生成过程中没有这样的度量）。\n\n## 参考链接\n- <a href=\"https://www.pinecone.io/learn/vector-similarity/\">Vector Similarity Explained</a>\n","tags":["向量数据库"]},{"title":"什么是向量嵌入","url":"/2023/09/22/2023-09-22-vector-embeddings/","content":"\n## 简介\n\n向量嵌入是机器学习中最有趣、最有用的概念之一。它们是许多 NLP、推荐和搜索算法的核心。如果你曾经使用过推荐算法、语音助手、语音翻译器等工具，那么你可能就已经遇到过依赖嵌入的系统。\n\n和大多数软件算法一样，机器学习算法也需要数据集。有时，我们的数据集包含数值列或可以转换为数值的值（序数、分类等）。其他时候，我们会遇到一些更抽象的东西，比如整个文本文档。我们可以创建向量嵌入，将抽象的数据集转换为数字列表，便于后续操作。整段文本或其他任何对象都可以简化为一个向量。\n\n![向量嵌入模型](/img/2023-09-22-vector_embeddings/pho1.png)\n\n但向量有一些特殊之处，使得它们如此有用。这种表示使得人类感知的语义相似性转化为向量空间的邻近性成为可能。\n\n换句话说，当我们将现实世界的对象和概念（例如图像、录音、新闻文章、用户资料、天气预报和政治观点）表示为向量嵌入时，这些对象和概念的语义相似性可以通过它们作为向量空间中的点彼此之间的距离来量化。因此，向量嵌入表示适用于常见的机器学习任务，例如聚类、推荐和分类。\n\n![Source: DeepAI](/img/2023-09-22-vector_embeddings/pho2.png)\n\n例如，在聚类任务中，聚类算法将相似的点分配到同一聚类，同时保持不同聚类的点尽可能不相似。在推荐任务中，当对未见过的对象进行推荐时，推荐系统会寻找与该对象最相似的对象，通过它们与向量嵌入的相似度来衡量。在分类任务中，我们通过对最相似对象的标签进行主要投票来对未见过的对象的标签进行分类。\n\n## 创建向量嵌入\n\n创建向量嵌入的一张方法是使用领域知识来设计向量值。这就是所谓的特征工程。例如，在医学成像中，我们利用医学专业知识来量化一组特征，例如图像中捕捉语义的形状、颜色和区域。然而，工程向量嵌入需要领域知识，但是扩展成本太高。\n\n我们通常训练模型将对象转化为向量，而不是设计向量嵌入。深度神经网络是训练此类模型的常见工具。由此产生的嵌入通常是高纬度的（高达两千维）和密集的（所有值都不为零）。对于文本数据来说，Word2Vec、GLoVE 和 BERT 等模型将单词、句子或段落转换为向量嵌入。\n\n可以使用卷积神经网络（CNN）等模型嵌入图像，CNN 的示例包括 VGG 和 Inception。可以使用音频视觉表示上的图像嵌入变换将音频记录转换为向量（例如，使用其频谱图）。\n\n## 例如: 用卷积神经网络嵌入图像\n\n思考以下示例，其中原始图像表示为灰度像素。这相当于 0 到 255 范围内的整数值的矩阵（或表）。其中 0 对应黑色，255 对应白色。下图描绘了灰度图像及其对应的矩阵。\n\n![Source: Serena Young](/img/2023-09-22-vector_embeddings/pho3.png)\n\n左侧子图像描绘灰度像素，中间子图像包括像素灰度值，最右侧子图像定义矩阵。请注意，矩阵值定义了一个向量嵌入，其中它的第一个左边是矩阵左上角的单元格，然后从左到右直到对应于右下角矩阵单元格的最后一个坐标。\n\n这种嵌入技术能更好地维护图像中像素领域地语义信息。然而，它们对诸如移位、缩放、裁剪和其他图像处理操作之类地转换非常敏感。因此，它们通常作为原始输入，以学习更健壮地嵌入。\n\n卷积神经网络（CNN）是一类深度学习框架，通常应用于将图像转换为嵌入的视觉数据。\n\nCNN 通过分层的小型局部子输入（称为感受野）来处理输入。每个网络层中的每个神经元处理来自前一层的特定感受野。每层要么在感受野上应用卷积，要么减小输入大小，这称为子采样。\n\n下图描绘了一个典型的 CNN 结构。注意感受野，在每一层被描绘成子方块，作为前一层中单个神经元的输入。还要注意，子采样操作会减小层大小，而卷积操作会扩展层大小。生成的向量嵌入通过全连接层接收。\n\n![Source: Aphex34，CC BY-SA 4.0](/img/2023-09-22-vector_embeddings/pho4.png)\n\n学习网络权重（即嵌入模型）需要大量标记图像。权重的优化方式是，与具有不同标签的图像相比，具有相同标签的图像嵌入得更近。一旦我们学习了 CNN 嵌入模型，我们就可以将图像转换为向量，并使用 K 最近邻索引来储存它们。现在，给定一个新的未见过的图像，我们可以使用 CNN 模型对其进行转换，检索其 K 个最相似的向量，从而得到相应的相似图像。\n\n尽管本文使用图像和 CNN 作为示例，但我们可以为任何类型的数据创建向量嵌入，并且可以使用多种模型/方法来创建它们。\n\n## 使用向量嵌入\n\n嵌入可以将对象表示为一个包含其语义信息的密集向量，这一事实使得嵌入在机器学习应用中非常有用。\n\n相似性搜索是向量嵌入最常见的用途之一。KNN 和 ANN 等搜索算法要求我们计算向量之间的距离以确定相似度。向量嵌入可用于计算这些距离。最近邻搜索又可用于诸如去复制、推荐、异常检测、反向图像搜索等任务。\n\n即使我们不直接在应用程序中使用嵌入，许多流行的 ML 模型和方法也在内部依赖它们。例如，在编码器-解码器架构中，编码器生成的嵌入包含解码器生成结果所需的信息。这种架构广泛应用于机器翻译和字幕生成等应用中。\n\n## 参考链接\n- <a href=\"https://www.pinecone.io/learn/vector-embeddings/\">What are Vector Embeddings</a>\n","tags":["向量数据库"]},{"title":"什么是向量数据库","url":"/2023/09/16/2023-09-16-vector-database/","content":"\n我们正处于 AI 智能革命的中期。向量数据库引导了伟大的创新，并正在颠覆任何与之相关的行业，但是它也带了新的挑战。对于涉及大型语言模型、生成式人工智能和语义搜索的应用程序来说，高效的数据处理变得比以往任何时候都更加重要。\n\n所有这些新兴的应用程序都依赖于**向量嵌入（vector embeddings）**。这是一种数据表示形式，其中包含语义信息，这有助于人工智能获得、理解并维持能够应用在复杂任务上的长期记忆。\n\n**嵌入**是由人工智能模型（如大型语言模型）生成的，并且具有大量属性或特性，这使得它们难以被表示。在人工智能和机器学习的背景下，这些特征代表了数据的不同维度，如何“精准”地表示它们，这取决于数据库的理解模式、关系和底层结构。\n\n这就是为什么我们需要专门为处理此类数据而设计的专用数据库。像 Pinecone 这样的**向量数据库**通过为嵌入提供优化的存储和查询功能来满足这一要求。向量数据库不仅传统标量数据库所没有的专门处理向量嵌入的能力，还具有独立向量索引的能力。\n\n使用向量嵌入的挑战在于，传统的基于标量的数据库无法跟上此类数据的复杂性和规模，所以难以捕捉关键语义并进行实时分析。这恰巧就是向量数据库的优势——它们专门为高效、灵活地处理此类数据而生。\n\n借助向量数据库，我们可以为人工智能添加更高级的功能，比如语义信息检索、长期记忆等等。下图能够让我们更好地理解向量数据库在此类应用中的作用：\n\n![向量数据库的应用](/img/2023-09-16-vector_database/image1.png)\n\n让我们来分析一下：\n1. 首先，我们使用**嵌入模型**为我们想要索引的**内容**创建**向量嵌入**。\n2. 参考创建嵌入的原始内容，将向量**嵌入**写入到**向量数据库**中。\n3. 当**应用程序**发出查询时，我们使用相同的**嵌入模型**为查询创建嵌入，并使用这些嵌入在**数据库**中查询类似的向量嵌入。如前所述，这些类似的嵌入与用于创建它们的原始**内容相关联**。\n\n## 向量索引和向量数据库的区别是什么\n\n像 FAISS（Facebook AI 相似性搜索）这样的独立向量索引可以显著改善向量嵌入的搜索和检索，但它们缺乏数据库所具备的基础能力，例如存储。另一方面，向量数据库是专门为管理向量嵌入而构建的，与使用独立向量索引相比具有以下优势：\n\n1. **数据管理**：向量数据库提供简单易用的数据存储功能，例如插入、删除和更新数据。这使得管理和维护向量数据比使用 FAISS 等独立向量索引更容易，后者需要额外的工作才能与存储解决方案集成。\n\n2. **元数据存储和过滤**：向量数据库可以存储与每个向量条目关联的元数据。然后，用户可以使用附加的元数据过滤器来查询数据库，以进行更细粒度的查询。\n\n3. **可扩展性**：向量数据库能够随着数据量和用户需求的增长而扩展，为分布式和并行处理提供更好的支持。独立向量索引可能需要定制解决方案来实现类似级别的可扩展性（例如在 Kubernetes 集群或其他类似系统上部署和管理它们）。\n\n4. **实时更新**：向量数据库通常支持实时数据更新，允许对数据进行动态更改，而独立向量索引可能需要完整的重新索引过程来合并新数据，这可能非常耗时且计算成本高昂。\n\n5. **备份和收集**：对于向量数据库来说，处理备份数据库中存储的所有数据是常规操作。Pinecone 还允许用户选择特定的索引，采用“集合”的形式进行数据备份。\n\n6. **生态系统集成**：向量数据库可以更轻松地与数据处理生态系统的其他组件集成，例如 ETL 管道（如 Spark）、分析工具（如Tableau 和 Segment）和可视化平台（如 Grafana），从而简化数据管理工作流程。它还可以与其他人工智能相关工具（例如LangChain、LlamaIndex 和 ChatGPT 的插件）轻松集成。\n\n7. **数据安全和访问控制**：向量数据库通常提供内置数据安全功能和访问控制机制来保护敏感信息，这在独立的向量索引解决方案中可能无法实现。\n\n简而言之，向量数据库解决了独立向量指数的局限性（例如可扩展性挑战、繁琐的集成过程以及缺乏实时更新和内置安全措施），从而为处理向量嵌入提供了一个优越的解决方案，确保更有效和更精简的数据管理经验。\n\n## 向量数据库是如何工作的\n\n我们都或多或少地了解传统数据库的工作原理，它们在行和列中存储字符串、数字和其他类型的标量数据。但是，向量数据库对向量进行操作，因此其优化和查询的方式和传统数据库有很大的不同。\n\n在传统数据库中，我们通常在数据库中检索与查询值完全匹配的行；但在向量数据库中，我们应用相似性度量来查找与我们的查询**最相似**的向量。\n\n向量数据库使用不同算法的组合，这些算法都参与了近似最近邻 (ANN) 搜索。这些算法通过散列、量化或基于图的搜索来优化搜索。\n\n这些算法组合成一个流水线，可以快速准确地检索所查询向量的邻居。由于向量数据库提供**近似**结果，因此主要权衡是精度和速度。结果越准确，查询的速度就越慢。然而，一个好的系统可以提供近乎完美的精度超快搜索。\n\n这是向量数据库的常见流程：\n\n![向量数据库常见流程](/img/2023-09-16-vector_database/image2.png)\n\n1. **索引（indexing）**：向量数据库使用 PQ、LSH 或 HNSW 等算法对向量进行索引（更多内容见下文）。此步骤将向量映射到能够更快搜索的数据结构中。\n\n2. **查询（querying）**：向量数据库将索引查询向量与数据集中的索引向量进行比较，以找到最近的邻居（应用该索引使用的相似性度量）\n\n3. **后期处理（post processing）**：在某些情况下，向量数据库从数据集中检索最终的最近邻，并对它们进行后处理以返回最终结果。该步骤可以包括使用不同的相似性度量对最近邻居重新排序。\n\n下面，我们将更详细地讨论这些算法，并解释它们如何提升向量数据库的整体性能。\n\n### 算法\n\n有很多算法可以促进向量索引的创建。他们的共同目标是通过创建可快速遍历的数据结构来实现快速查询。它们通常会将原始向量的表示形式转换为压缩形式，以优化查询过程。\n\n然而，作为 Pinecone 的用户，您无需担心这些各种算法的复杂性和选择。Pinecone 旨在处理幕后的所有复杂性和算法决策，确保您轻松获得最佳性能和结果。通过利用 Pinecone 的专业知识，您可以专注于真正重要的事情——提取有价值的见解并提供强大的 AI 解决方案。\n\n以下部分将探讨几种算法及其处理向量嵌入的独特方法。\n\n#### 随即投影\n\n**随机投影背后的基本思想是使用随机投影矩阵**将高维向量投影到低维空间。我们创建一个随机数矩阵。矩阵的大小将是我们想要的目标低维值。然后我们计算输入向量和矩阵的点积，这会产生一个投影矩阵，其维度比原始向量少，但仍保留它们的相似性。\n\n![随记投影算法](/img/2023-09-16-vector_database/image3.png)\n\n当我们查询时，我们使用相同的投影矩阵将查询向量投影到低维空间。然后，将投影查询向量与数据库中的投影向量进行比较，寻找最近邻。由于数据的维数降低了，因此搜索过程比搜索整个高维空间要快得多。\n\n请记住，随机投影是一种近似方法，投影质量取决于投影矩阵的属性。一般来说，投影矩阵越随机，投影的质量就越好。但生成一个真正随机的投影矩阵的计算成本可能很高，尤其是对于大型数据集。\n\n#### 乘积量化\n\n另一种建立索引的方法是乘积量化(product quulization，PQ) ，这是一种用于高维向量（如向量嵌入）的有损数据压缩技术。它获取原始向量，将其分解成更小的块，通过为每个块创建一个代表性的”编码”来简化每个块的表示，然后将所有块放回到一起——而不会丢失对相似性操作至关重要的信息。PQ 的过程可以分为四个步骤: 拆分、训练、编码和查询。\n\n![乘积量化算法](/img/2023-09-16-vector_database/image4.png)\n\n1. **拆分**：向量被分成多个片段。\n2. **训练**：我们为每个片段建立一个“编码本”。简单地说，就是该算法会生成一个可以分配给向量的潜在“编码”池。实际上，这个“编码本”是由对每个向量片段的执行 K 均值算法而创建的聚类中心点组成。我们在片段编码本中值数量与 K 均值算法中使用的值的数量相同。\n3. **编码**：算法为每个片段分配指定的编码。实际上，我们在训练完成后会在编码本中找到与每个向量段最接近的值。该片段的 PQ 编码将是编码本中相应值的标识符。我们可以使用任意数量的 PQ 编码，这意味着我们可以从编码本中选择多个值来表示每个段。\n4. **查询**：当我们查询时，算法会将查询向量分解成多个子向量，并使用相同的编码本对它们进行量化。然后，使用索引编码来查找最接近查询向量的向量。\n\n编码本中代表向量的数目是表示的准确性和搜索编码本的计算成本之间的权衡。编码本中的具有代表性的向量越多，子空间中向量的表示就越精准，但是搜索编码本的计算成本就越高。反之，编码本中的代表向量越少，表示的精度越低，但计算成本越低。\n\n#### 局部敏感哈希\n\n局部敏感哈希（LSH）是一种在近似最近邻搜索上下文中建立索引的技术。它不仅优化了查询速度，还能提供一个近似的、非详尽的结果。LSH 使用一组哈希函数将相似的向量映射道“桶”中，如下图所示：\n\n![局部敏感哈希算法](/img/2023-09-16-vector_database/image5.png)\n\n为了找到给定查询向量的最近邻，我们使用与将相似向量“存储”到哈希表中相同的哈希函数。查询向量被散列到特定的表中，然后与同一表中的其他向量进行比较，以找到最接近的匹配。这种方法比搜索整个数据集要快得多，因为每个哈希表中的向量比整个空间中的向量要少得多。\n\n但是 LSH 是一种近似方法，近似的质量取决于哈希函数的属性。一般来说，使用的哈希函数越多，近似质量就越好。但是，使用大量哈希函数的计算成本可能很高，并且 LSH 对于大型数据集可能不可行。\n\n#### 分层可导航小世界（HNSW）\n\nHNSW 创建了一个分层的树状结构，其中树的每个节点代表一组向量。节点直接的边代表向量之间的相似度。该算法首先创建一组节点，每个节点都具有少量的向量；这可以是随即完成，也可以通过使用 k 均值等算法对向量进行聚类来完成，其中每个聚类都成为一个节点。\n\n![聚类节点](/img/2023-09-16-vector_database/image6.png)\n\n然后，该算法检查每个节点的向量，并在该节点和具有最相似向量的节点之间绘制一条边。\n\n![聚类树](/img/2023-09-16-vector_database/image7.png)\n\n当我们查询 HNSW 索引时，它使用此图在树中导航，访问最有可能包含与查询向量最接近的向量的节点。\n\n#### 相似度量\n\n在前面讨论的算法的基础上，我们需要了解相似度量在向量数据库中的作用。这些度量是向量数据库如何比较和识别给定查询的最相关结果的基础。\n\n相似性度量是用于确定向量空间中两个向量相似程度的数学方法。在向量数据库中使用相似性度量来比较存储在数据库中的向量，并找出与给定查询向量最相似的向量。\n\n可以使用多种相似性度量，包括：\n\n- **余弦相似度**：计算向量空间中两个向量之间夹角的余弦。取值范围是 -1 到 1，其中 1 表示相同的向量，0 表示正交向量，-1 表示完全相反的向量。\n- **欧式距离**：计算向量空间内两个向量之间的直线距离。它的范围是从 0 到无穷大，其中 0 表示相同的向量，越大的值表示越不相似的向量。\n- **点积**：计算两个向量的大小玉他们之间夹角的乘积。范围为 -∞ 到 ∞，其中正值表示指向相同方向的向量，0 表示正交向量，负值表示指向相反方向的向量。\n\n相似性度量的选择会对从向量数据库获得的结果产生影响。还需要注意的是，每种相似性度量都有其自身的优点和缺点，因此根据用例和需求选择正确的相似性度量非常重要。\n\n#### 过滤\n\n数据库中存储的每个向量还包括元数据。除了能够查询相似的向量之外，向量数据库还可以基于元数据查询过滤结果。为此，向量数据库通常维护两个索引: 向量索引和元数据索引。然后，在向量搜索本身之前或之后执行元数据过滤，但是在这两种情况下，都会导致查询过程变慢。\n\n![预过滤](/img/2023-09-16-vector_database/image8.png)\n\n![后过滤](/img/2023-09-16-vector_database/image9.png)\n\n过滤过程可以在向量搜索本身之前或之后执行，但每种方法都有其自身的挑战，可能会影响查询性能：\n1. **预过滤**：在这种方法中，元数据过滤是在向量搜索之前完成的。虽然这有助于减少搜索空间，但也可能导致系统忽略与元数据过滤条件不匹配的相关结果。此外，广泛的元数据过滤可能会由于增加的计算开销而减慢查询过程。\n2. **后过滤**：在这种方法中，元数据过滤是在向量搜索之后完成的。这可以确保考虑所有相关结果，但因为搜索完成后需要过滤掉不相关的结果，可能会带来额外的开销并减慢查询过程，\n\n为了优化过滤过程，向量数据库使用各种技术，例如利用高级元数据索引方法或使用并行处理来加速过滤任务。平衡搜索性能和过滤精度对于在向量数据库中提供有效和相关的查询结果至关重要。\n\n### 数据库操作\n\n与向量索引不同，向量数据库配备了一组功能，使其更适于大规模生产环境。让我们看一下操作数据库所涉及的组件的总体概述。\n\n![数据库操作](/img/2023-09-16-vector_database/image10.png)\n\n### 性能与容错\n\n性能与容错密切相关。我们拥有的数据越多，需要的节点就越多，出现错误和失败的可能性也就越大。与其他类型的数据库一样，我们希望确保即使某些底层节点发生故障，查询也能尽快执行。这可能是由于硬件故障、网络故障或其他类型的技术错误造成的。这种故障可能导致停机，甚至查询结果不正确。\n\n为了确保高性能和容错能力，向量数据库使用分片和副本：\n\n1. **分片**：将数据分片，并存储到多个节点。有不同的方法来划分数据，例如可以通过不同数据簇的相似性进行分片，以便将相似的向量存储在同一分片中。当进行查询时，它会被发送到所有分片，并检索和组合结果。这称为“分散-聚集”模式。\n2. **副本**：跨不同节点创建数据的多个副本。这确保即使特定节点发生故障，其他节点也能够替代它。一致性模型主要有两种：最终一致性和强一致性。最终一致性允许不同数据副本之间出现临时不一致，这将提高可用性并减少延迟，但可能会导致冲突甚至数据丢失；强一致性要求在写入操作被视为完成之前更新所有数据副本，这种方法提供了更强的一致性，但可能会导致更高的延迟。\n\n### 监控\n\n为了有效地管理和维护向量数据库，我们需要一个强大的监控系统来跟踪数据库的性能、健康状况和整体状态。监控对于发现潜在问题、优化性能和确保生产顺利运行至关重要。监控向量数据库的一些方面包括以下内容：\n\n1. **资源使用情况**：监视资源使用情况，如 CPU、内存、磁盘空间和网络活动，可以识别可能影响数据库性能的潜在问题或资源限制。\n2. **查询性能**：查询延迟、吞吐量和错误率可能表明需要解决的潜在系统问题。\n3. **系统运行状况**：整个系统健康状况监视包括各个节点的状态、复制过程和其他关键组件。\n\n### 访问控制\n\n访问控制是管理和规范用户对数据和资源的访问的过程。它是数据安全的重要组成部分，确保只有授权用户才能查看、修改向量数据库中存储的敏感数据或与之交互。\n\n访问控制很重要，原因如下：\n\n1. **数据保护**：由于人工智能应用程序经常处理敏感和机密信息，实施严格的访问控制机制有助于保护数据免遭未经授权的访问和潜在的泄露。\n2. **合规性**：许多行业，例如医疗保健和金融，都受到严格的数据隐私法规的约束。实施适当的访问控制有助于组织遵守这些法规，保护他们免受法律和财务影响。\n3. **问责制和审计**：访问控制机制使组织能够在向量数据库中维护用户活动的记录。此信息对于审核目的至关重要，当发生安全漏洞时，它有助于追踪任何未经授权的访问或修改。\n4. **可扩展性和灵活性**：随着组织的成长和发展，他们的访问控制需求可能会发生变化。强大的访问控制系统允许无缝修改和扩展用户权限，确保数据安全在组织的整个发展过程中保持完整。\n\n### 备份和收藏\n\n当所有其他方法都失败时，向量数据库提供了依赖定期创建备份的能力。这些备份可以存储在外部存储系统或基于云的存储服务上，确保数据的安全性和可恢复性。如果发生数据丢失或损坏，这些备份可用于将数据库恢复到之前的状态，从而最大限度地减少停机时间和对整个系统的影响。\n\n### API 和 SDKs\n\n这就是橡胶与道路相遇的地方：与数据库交互的开发人员希望通过易于使用的 API、使用熟悉且舒适的工具集来完成此操作。通过提供用户友好的界面，向量数据库 API 层简化了高性能向量搜索应用程序的开发。\n\n除了 API 之外，向量数据库通常还会提供包装 API 的特定于编程语言的 SDK。SDK 使开发人员可以更轻松地在应用程序中与数据库进行交互。这使得开发人员能够专注于他们的特定用例，例如语义文本搜索、生成问答、混合搜索、图像相似性搜索或产品推荐，而不必担心底层基础设施的复杂性。\n\n## 概况\n\n向量嵌入在自然语言处理、计算机视觉和其他人工智能应用等领域呈指数级增长，导致了向量数据库作为计算引擎的出现，使我们能够与应用程序中的向量嵌入进行有效交互。\n\n向量数据库是专门用来处理生产场景中管理向量嵌入时出现的问题的数据库。因此，与传统的基于标量的数据库和独立的向量索引相比，它们具有明显的优势。\n\n在这篇文章中，我们回顾了向量数据库的关键方面，包括它的工作原理、它使用的算法以及使其为生产场景做好操作准备的附加功能。我们希望这可以帮助您了解向量数据库的内部工作原理。\n\n## 参考链接\n- <a href=\"https://www.pinecone.io/learn/vector-database/\">What is a Vector Database?</a>\n","tags":["向量数据库"]},{"title":"pycharm-2023.1 closing project window stuck","url":"/2023/09/11/2023-09-11-pycharm-2023.1-closing-project-stuck/","content":"\n## 问题描述\n\npycharm 切换项目/重启，一直卡在 closing project\n\n## 原因分析\n\nhttps://youtrack.jetbrains.com/issue/PY-59980/PyCharm-2023.1-issue-closing-project-window-stuck-PyPIPackageUtil.lambdaparsePyPIListFromWeb\n\n## 解决方案\n\n1. 升级 pycharm 到 2023.3\n2. pycharm 主页 HELP -> Find Action -> 输入 Registry -> 禁用 ide.await.scope.completion","tags":["那些年遇到的坑"],"categories":["pycharm"]},{"title":"yum 卡住","url":"/2023/08/31/2023-08-31-yum-qia-zhu/","content":"\n## 问题描述\n\n执行 yum 卡住，Ctrl + c 也退不出来\n只能 kill -9 退出\n\n## 原因分析\n\n在Linux中，通过rpm/yum安装应用时没有任何响应，执行“ps -ef | grep rpm”发现之前执行过的rpm/yum命令全被挂起，故障原因是rpm数据库异常，解决方法是重建rpm数据库。\n\n## 解决方案\n\n```bash\n# 删除rpm数据库\nrm -f /var/lib/rpm/__db.00*\n\n# 重建rpm数据库\nrpm -vv --rebuilddb\n\n# 清理yum资源锁\nrm -f /var/lib/rpm/.rpm.lock\nrm -f /var/lib/rpm/.dbenv.lock\n\n# 清理yum缓存\nyum clean all\n# 或删除cache目录\n# rm -rf /var/cache/yum/*\n```","tags":["Linux","那些年遇到的坑"]},{"title":"虚拟机 Linux 使用 perf stat 提示 cycles not supported","url":"/2023/07/07/2023-07-07-perf-stat-wen-ti/","content":"\n## 问题描述\n\n项目希望评估算法的 CPU 开销，使用 linux 常用的 perf 工具。\n查看 perf stat 只显示 cpu-clock, context-switches, cpu-migrations\n剩余 cycles, instructions, branches, branch-misses 均为 not supported\n\n![problem_test](/img/2023-07-07-perf_stat问题/pho1.jpg)\n\n## 原因分析\n该参数使用物理机可测量，猜测问题出在虚拟化。\n\n## 解决方案\n关闭 VMware 虚拟机电源，找到硬件配置选项中 CPU\n\n勾选☑️虚拟化CPU性能计数器重启问题解决","tags":["Linux","性能测试","Perf"]},{"title":"浏览器中如何快速下载SVG图片","url":"/2023/07/07/2023-07-07-liu-lan-qi-ru-he-kuai-su-xia-zai-svg-tu-pian/","content":"\n## 操作步骤\n\n### 1. 右击浏览器页面，选择检查，打开浏览器的调试工具。找到你想下载的 svg 图片的 xmnls，复制元素。\n\n![svg1](/img/2023-07-07-浏览器如何快速下载svg图片/svg1.jpg)\n\n### 2. 新建 txt 文件，将刚才复制的元素复制到文本中，更改文件后缀为 svg 即可。\n\n**注意：**\n\n有的 svg 元素报错下来可能只有 id，没有 xmlns=\"http://www.w3.org/2000/svg\" 这段代码\n\n此时，需要将包含 id 的整段代码，更换为 xmlns=\"http://www.w3.org/2000/svg\"","tags":["性能测试","火焰图"],"categories":["性能测试"]},{"title":"性能测试——火焰图","url":"/2023/07/07/2023-07-07-huo-yan-tu/","content":"\n## 0. perf 简介\n\nPerf 是一个用于访问处理器性能监视单元 (PMU) 以及记录和显示软件事件（例如页错误）的界面。它支持系统范围的监视、按线程的监视和 KVM 虚拟化 Guest 监视。\n\n可以在报告中储存生成的信息。例如，此报告包含有关指令指针的信息，或线程执行的代码的信息。\n\nPerf 由两部分组成：\n<ul>\n  <li>集成到 Linux 内核的代码，负责向硬件发出指令。</li>\n  <li>perf 用户空间实用程序，可让您使用内核代码并帮助您分析收集的数据。</li>\n</ul>\n\n## 1. 安装 perf\n\n```bash\ncat /etc/redhat-release\nCentOS Linux release 7.6.1810 (Core)\n\nsudo yum install perf\n...\n```\n\n## 2. perf 的使用\n\n### 2.1 perf 分析流程\n\nPerf 进行性能分析的方式通常有两种：\n\n<ul>\n  <li>使用 perf stat 等命令对特定的事件计数器进行计算，并在程序结束后打印数值</li>\n  <li>使用 perf record 等命令以若干的事件为触发间隔对系统进行采样，将数据保存至 perf.data 文件以供后续分析</li>\n  <li>也就是说，perf stat 命令只能记录事件发生的次数，perf record 在此基础之上可以记录事件发生时详细的数据(比如 IP、堆栈等等)。</li>\n</ul>\n\nperf record 流程图：\n\n![perf record 流程图](/img/2023-07-07-火焰图/perf_record.png)\n\n在虚拟机上演示：\n```bash\nperf stat ls\n\n Performance counter stats for 'ls':\n\n          1.643793      task-clock (msec)         #    0.750 CPUs utilized\n                 0      context-switches          #    0.000 K/sec\n                 0      cpu-migrations            #    0.000 K/sec\n               265      page-faults               #    0.161 M/sec\n   <not supported>      cycles\n   <not supported>      instructions\n   <not supported>      branches\n   <not supported>      branch-misses\n\n       0.002190790 seconds time elapsed\n\nperf record ls\nperf.data\n[ perf record: Woken up 1 times to write data ]\n[ perf record: Captured and wrote 0.016 MB perf.data (7 samples) ]\n```\n\n## 2.2 perf 事件支持\n\n通过 perf list 可以查看当前支持的所有时间包括硬件事件、软件事件、硬件cache事件、PMU事件以及预设Tracepoint事件\n\n![perf list](/img/2023-07-07-火焰图/perf_2.png)\n\n## 2.3 perf stat（统计特定类型的事件）\n\n要统计某个事件（例如 perf list 显示的事件）的发生次数，请使用：\n\n```bash\nperf stat -e EVENT -a\n```\n\n要一次性统计多种类型的事件，请列出这些事件并以逗号分隔。例如，要统计 cpu-cycles 和 instructions，请使用：\n\n```bash\nperf stat -e cpu-cycles,instructions -a\n```\n\n要停止会话，请按 Ctrl+C。\n\n还可以统计某个事件在特定时间范围内发生的次数：\n\n```bash\nperf stat -e EVENT -a -- sleep TIME\n```\n\n请将 TIME 替换为以秒为单位的值。\n\n## 2.4 perf record（记录特定于特定命令的事件）\n\n1、可通过各种方式来对特定于特定命令的事件采样：\n\n1）要创建新调用的命令的报告，请使用：\n\n```bash\nperf record COMMAND\n```\n\n然后正常使用启动的进程。退出该进程时，Perf 会话也会停止。\n\n2）要在运行新调用的命令时创建整个系统的报告，请使用：\n\n```bash\nperf record -a COMMAND\n```\n\n3）要创建已运行的进程的报告，请使用：\n\n```bash\nperf record -p PID\n```\n\n请将 PID 替换为进程 ID。要停止会话，请按 Ctrl–C。\n\n2、现在，可使用以下命令查看收集到的数据 (perf.data)：\n\n```bash\nperf report\n```\n\n这会打开一个伪图形界面。要获得帮助，请按 H。要退出，请按 Q。\n\n3、如果您偏向于使用图形界面，请尝试 Perf 的 GTK+ 界面：\n\n```bash\nperf report --gtk\n```\n\n但请注意，GTK+ 界面的功能很有限。\n\n## 火焰图\n\n火焰图是用图形化的方式来展现perf等工具采集的性能数据，对数据进行统计和分析，方便找出性能热点。\n\n```bash\ngit clone https://github.com/brendangregg/FlameGraph.git\n```\n\n在 <a herf=\"https://github.com/brendangregg/FlameGraph.git\">GitHub 项目：FlameGraph</a> 主页有生成火焰图的详细说明。\n\n克隆项目：\n```bash\ngit clone https://github.com/brendangregg/FlameGraph.git\n```\n\n![FlameGraph list](/img/2023-07-07-火焰图/perf_3.png)\n\n## 一个实例：\n\n### 1.st 生成 perf.data\n```bash\nperf record -F 99 -a -g -- sleep 60 \n\n上述代码中 perf record 表示记录，\n-F 99 表示每秒99次，\n-p 13204 是进程号，即对哪个进程进行分析，\n-g 表示记录调用栈，\nsleep 30 则是持续30秒，-a 表示记录所有cpu调用。更多参数可以执行\n```\n\n这条指令的意思是，对CPU所有进程以 99Hz 采集,它的执行频率是 99Hz（每秒99次），如果 99 次都返回同一个函数名，那就说明 CPU 这一秒钟都在执行同一个函数，可能存在性能问题。执行60秒后会弹出如下图提示表示采集完成，在当前目录会生成一个perf.data的文件。\n\nperf.data 文件生成后，表示采集完成。**最好是在火焰图的目录下进行采集，方便转换成SVG图形。**\n\n### 2.st 生成火焰图\n\n```bash\n//生成脚本文件\nperf script -i perf.data &> perf.unfold\n\n//生成火炬图\n./FlameGraph/stackcollapse-perf.pl perf.unfold &> perf.folded\n./FlameGraph/flamegraph.pl perf.folded > perf.svg\n```\n\n执行完成后生成 perf.svg 图片，可以下载到本地，用浏览器打开 perf.svg，如下图\n\n![perf.svg](/img/2023-07-07-火焰图/perf_4.png)\n\n## 火焰图的含义\n\n火焰图是基于 perf 结果产生的 SVG 图片，用来展示 CPU 的调用栈。\n\n![perf_5.svg](/img/2023-07-07-火焰图/perf_5.svg)\n\ny 轴表示调用栈，每一层都是一个函数。调用栈越深，火焰就越高，顶部就是正在执行的函数，下方都是它的父函数。\n\nx 轴表示抽样数，如果一个函数在 x 轴占据的宽度越宽，就表示它被抽到的次数多，即执行的时间长。注意，x 轴不代表时间，而是所有的调用栈合并后，按字母顺序排列的。\n\n火焰图就是看顶层的哪个函数占据的宽度最大。只要有\"平顶\"（plateaus），就表示该函数可能存在性能问题。\n\n颜色没有特殊含义，因为火焰图表示的是 CPU 的繁忙程度，所以一般选择暖色调。\n\n## 差分火焰图\n\n\n```bash\n# 第一次Profiling结果\nperf record -ag -F 999 -- sleep 20\nperf script -i perf.data &> A.stacks\n# 第二次Profiling结果\nperf record -ag -F 999 -- sleep 20\nperf script -i perf.data &> B.stacks\n# 下载FlameGraph仓库\ngit clone --depth 1 http://github.com/brendangregg/FlameGraph \n# 折叠A.stacks和B.stacks\n./FlameGraph/stackcollapse-perf.pl A.stacks &> A.folded\n./FlameGraph/stackcollapse-perf.pl B.stacks &> B.folded\n# 基于折叠结果做差\n./FlameGraph/difffolded.pl A.folded B.folded > diff.folded\n# 生成差分火焰图\n./FlameGraph/flamegraph.pl diff.folded > diff.svg\n```\n\n参考资料：\n<ul>\n  <li>\n    <a href=\"https://documentation.suse.com/zh-cn/sles/15-SP3/html/SLES-all/cha-perf.html\">使用 Perf 进行基于硬件的性能监视</a>\n    </li>\n  <li>\n    <a href=\"https://yoc.docs.t-head.cn/linuxbook/Chapter4/perf.html\">Perf 使用说明</a>\n  </li>\n  <li>\n    <a href=\"https://www.cnblogs.com/wx170119/p/11459995.html\">火焰图（Flame Graphs）的安装和基本用法</a>\n  </li>\n  <li>\n    <a href=\"https://zhuanlan.zhihu.com/p/639996512\">差分火焰图，让你的代码优化验证事半功倍</a>\n  </li>\n</ul>","tags":["性能测试","Perf","火焰图"]},{"title":"寻找一种易于理解的一致性算法（扩展版）","url":"/2023/06/25/2023-06-25-raft-zh-cn/","content":"\n## 摘要\n\nRaft 是一种为了管理复制日志的一致性算法。它提供了和 Paxos 算法相同的功能和性能，但是它的算法结构和 Paxos 不同，使得 Raft 算法更加容易理解并且更容易构建实际的系统。为了提升可理解性，Raft 将一致性算法分解成了几个关键模块，例如领导人选举、日志复制和安全性。同时它通过实施一个更强的一致性来减少需要考虑的状态的数量。一项用户研究的结果表明，对于学生而言，Raft 算法比 Paxos 算法更加容易学习。Raft 算法还包括一个新的机制来允许集群成员的动态改变，它利用重叠的大多数来保证安全性。\n\n## 1 介绍\n\n一致性算法允许一组机器像一个整体一样工作，即使其中一些机器出现故障也能够继续工作下去。正因为如此，一致性算法在构建可信赖的大规模软件系统中扮演着重要的角色。在过去的 10 年里，Paxos 算法统治着一致性算法这一领域：绝大多数的实现都是基于 Paxos 或者受其影响。同时 Paxos 也成为了教学领域里讲解一致性问题时的示例。\n\n但是不幸的是，尽管有很多工作都在尝试降低它的复杂性，但是 Paxos 算法依然十分难以理解。并且，Paxos 自身的算法结构需要进行大幅的修改才能够应用到实际的系统中。因此工业界和学术界都对 Paxos 算法感到十分头疼。\n\n努力研究过 Paxos 算法之后，我们开始寻找一种新的一致性算法，可以为构建实际的系统和教学提供更好的基础。与 Paxos 不同，我们的首要目标是可理解性：我们是否可以在实际系统中定义一个一致性算法，并且比 Paxos 算法更容易学习。此外，我们希望该算法方便系统构建者的直觉的发展。重要的不仅仅是算法能够工作，更重要的是能够很清楚地知道它为什么能工作。\n\nRaft 一致性算法就是这些工作的结果。在设计 Raft 算法的时候，我们使用一些特别的技巧来提升它的可理解性，包括算法分解（Raft 主要被分成了领导人选举，日志复制和安全三个模块）和减少状态机的状态（相对于 Paxos，Raft 减少了非确定性和服务器互相处于非一致性的方式）。一份针对两所大学 43 个学生的研究表明 Raft 明显比 Paxos 算法更加容易理解。在这些学生同时学习了这两种算法之后，和 Paxos 比起来，其中 33 个学生能够回答有关于 Raft 的问题。\n\nRaft 算法在许多方面和现有的一致性算法都很相似（主要是 Oki 和 Liskov 的 Viewstamped Replication），但是它也有一些独特的特性：\n\n* **强领导人**：和其他一致性算法相比，Raft 使用一种更强的领导能力形式。比如，日志条目只从领导人发送给其他的服务器。这种方式简化了对复制日志的管理并且使得 Raft 算法更加易于理解。\n* **领导选举**：Raft 算法使用一个随机计时器来选举领导人。这种方式只是在任何一致性算法都必须实现的心跳机制上增加了一点机制。在解决冲突的时候会更加简单快捷。\n* **成员关系调整**：Raft 使用一种共同一致的方法来处理集群成员变换的问题，在这种方法下，处于调整过程中的两种不同的配置集群中大多数机器会有重叠，这就使得集群在成员变换的时候依然可以继续工作。\n\n我们相信，Raft 算法不论出于教学目的还是作为实践项目的基础都是要比 Paxos 或者其他一致性算法要优异的。它比其他算法更加简单，更加容易理解；它的算法描述足以实现一个现实的系统；它有好多开源的实现并且在很多公司里使用；它的安全特性已经被正式定义和证明；它的效率和其他算法比起来也不相上下。\n\n接下来，这篇论文会介绍以下内容：复制状态机问题（第 2 节），讨论 Paxos 的优点和缺点（第 3 节），讨论我们为了可理解性而采取的方法（第 4 节），阐述 Raft 一致性算法（第 5-8 节），评价 Raft 算法（第 9 节），以及一些相关的工作（第 10 节）。\n\n## 2 复制状态机\n\n一致性算法是从复制状态机的背景下提出的（参考英文原文引用37）。在这种方法中，一组服务器上的状态机产生相同状态的副本，并且在一些机器宕掉的情况下也可以继续运行。复制状态机在分布式系统中被用于解决很多容错的问题。例如，大规模的系统中通常都有一个集群领导人，像 GFS、HDFS 和 RAMCloud，典型应用就是一个独立的复制状态机去管理领导选举和存储配置信息并且在领导人宕机的情况下也要存活下来。比如 Chubby 和 ZooKeeper。\n\n![图 1 ](/img/2023-06-25-raft-zh_cn/raft-图1.png)\n\n> 图 1 ：复制状态机的结构。一致性算法管理着来自客户端指令的复制日志。状态机从日志中处理相同顺序的相同指令，所以产生的结果也是相同的。\n\n复制状态机通常都是基于复制日志实现的，如图 1。每一个服务器存储一个包含一系列指令的日志，并且按照日志的顺序进行执行。每一个日志都按照相同的顺序包含相同的指令，所以每一个服务器都执行相同的指令序列。因为每个状态机都是确定的，每一次执行操作都产生相同的状态和同样的序列。\n\n一致性算法的任务是保证复制日志的一致性。服务器上的一致性模块接收客户端发送的指令然后添加到自己的日志中。它和其他服务器上的一致性模块进行通信来保证每一个服务器上的日志最终都以相同的顺序包含相同的请求，即使有些服务器发生故障。一旦指令被正确的复制，每一个服务器的状态机按照日志顺序处理他们，然后输出结果被返回给客户端。因此，服务器集群看起来形成了一个高可靠的状态机。\n\n实际系统中使用的一致性算法通常含有以下特性：\n\n* 安全性保证（绝对不会返回一个错误的结果）：在非拜占庭错误情况下，包括网络延迟、分区、丢包、重复和乱序等错误都可以保证正确。\n* 可用性：集群中只要有大多数的机器可运行并且能够相互通信、和客户端通信，就可以保证可用。因此，一个典型的包含 5 个节点的集群可以容忍两个节点的失败。服务器被停止就认为是失败。它们稍后可能会从可靠存储的状态中恢复并重新加入集群。\n* 不依赖时序来保证一致性：物理时钟错误或者极端的消息延迟只有在最坏情况下才会导致可用性问题。\n* 通常情况下，一条指令可以尽可能快的在集群中大多数节点响应一轮远程过程调用时完成。小部分比较慢的节点不会影响系统整体的性能。\n\n## 3 Paxos 算法的问题\n\n在过去的 10 年里，Leslie Lamport 的 Paxos 算法几乎已经成为一致性的代名词：Paxos 是在课程教学中最经常使用的算法，同时也是大多数一致性算法实现的起点。Paxos 首先定义了一个能够达成单一决策一致的协议，比如单条的复制日志项。我们把这一子集叫做单决策 Paxos。然后通过组合多个 Paxos 协议的实例来促进一系列决策的达成。Paxos 保证安全性和活性，同时也支持集群成员关系的变更。Paxos 的正确性已经被证明，在通常情况下也很高效。\n\n不幸的是，Paxos 有两个明显的缺点。第一个缺点是 Paxos 算法特别的难以理解。完整的解释是出了名的不透明；通过极大的努力之后，也只有少数人成功理解了这个算法。因此，有了几次用更简单的术语来解释 Paxos 的尝试。尽管这些解释都只关注了单决策的子集问题，但依然很具有挑战性。在 2012 年 NSDI 的会议中的一次调查显示，很少有人对 Paxos 算法感到满意，甚至在经验老道的研究者中也是如此。我们自己也尝试去理解 Paxos；我们一直没能理解 Paxos 直到我们读了很多对 Paxos 的简化解释并且设计了我们自己的算法之后，这一过程花了近一年时间。\n\n我们假设 Paxos 的不透明性来自它选择单决策问题作为它的基础。单决策 Paxos 是晦涩微妙的，它被划分成了两种没有简单直观解释和无法独立理解的情景。因此，这导致了很难建立起直观的感受为什么单决策 Paxos 算法能够工作。构成多决策 Paxos 增加了很多错综复杂的规则。我们相信，在多决策上达成一致性的问题（一份日志而不是单一的日志记录）能够被分解成其他的方式并且更加直接和明显。\n\nPaxos算法的第二个问题就是它没有提供一个足够好的用来构建一个现实系统的基础。一个原因是还没有一种被广泛认同的多决策问题的算法。Lamport 的描述基本上都是关于单决策 Paxos 的；他简要描述了实施多决策 Paxos 的方法，但是缺乏很多细节。当然也有很多具体化 Paxos 的尝试，但是他们都互相不一样，和 Paxos 的概述也不同。例如 Chubby 这样的系统实现了一个类似于 Paxos 的算法，但是大多数的细节并没有被公开。\n\n而且，Paxos 算法的结构也不是十分易于构建实践的系统；单决策分解也会产生其他的结果。例如，独立地选择一组日志条目然后合并成一个序列化的日志并没有带来太多的好处，仅仅增加了不少复杂性。围绕着日志来设计一个系统是更加简单高效的；新日志条目以严格限制的顺序增添到日志中去。另一个问题是，Paxos 使用了一种对等的点对点的方式作为它的核心（尽管它最终提议了一种弱领导人的方法来优化性能）。在只有一个决策会被制定的简化世界中是很有意义的，但是很少有现实的系统使用这种方式。如果有一系列的决策需要被制定，首先选择一个领导人，然后让他去协调所有的决议，会更加简单快速。\n\n因此，实际的系统中很少有和 Paxos 相似的实践。每一种实现都是从 Paxos 开始研究，然后发现很多实现上的难题，再然后开发了一种和 Paxos 明显不一样的结构。这样是非常费时和容易出错的，并且理解 Paxos 的难度使得这个问题更加糟糕。Paxos 算法在理论上被证明是正确可行的，但是现实的系统和 Paxos 差别是如此的大，以至于这些证明没有什么太大的价值。下面来自 Chubby 实现非常典型：\n\n> 在Paxos算法描述和实现现实系统中间有着巨大的鸿沟。最终的系统建立在一种没有经过证明的算法之上。\n\n由于以上问题，我们认为 Paxos 算法既没有提供一个良好的基础给实践的系统，也没有给教学很好的帮助。基于一致性问题在大规模软件系统中的重要性，我们决定看看我们是否可以设计一个拥有更好特性的替代 Paxos 的一致性算法。Raft 算法就是这次实验的结果。\n\n## 4 为了可理解性的设计\n\n设计 Raft 算法我们有几个初衷：它必须提供一个完整的实际的系统实现基础，这样才能大大减少开发者的工作；它必须在任何情况下都是安全的并且在大多数的情况下都是可用的；并且它的大部分操作必须是高效的。但是我们最重要也是最大的挑战是可理解性。它必须保证对于普遍的人群都可以十分容易的去理解。另外，它必须能够让人形成直观的认识，这样系统的构建者才能够在现实中进行必然的扩展。\n\n在设计 Raft 算法的时候，有很多的点需要我们在各种备选方案中进行选择。在这种情况下，我们评估备选方案基于可理解性原则：解释各个备选方案有多大的难度（例如，Raft 的状态空间有多复杂，是否有微妙的暗示）？对于一个读者而言，完全理解这个方案和暗示是否容易？\n\n我们意识到对这种可理解性分析上具有高度的主观性；尽管如此，我们使用了两种通常适用的技术来解决这个问题。第一个技术就是众所周知的问题分解：我们尽可能地将问题分解成几个相对独立的，可被解决的、可解释的和可理解的子问题。例如，Raft 算法被我们分成领导人选举，日志复制，安全性和成员变更几个部分。\n\n我们使用的第二个方法是通过减少状态的数量来简化需要考虑的状态空间，使得系统更加连贯并且在可能的时候消除不确定性。特别的，所有的日志是不允许有空洞的，并且 Raft 限制了日志之间变成不一致状态的可能。尽管在大多数情况下我们都试图消除不确定性，但是也有一些情况下不确定性可以提升可理解性。尤其是，随机化方法增加了不确定性，但是他们有利于减少状态空间数量，通过处理所有可能选择时使用相似的方法。我们使用随机化来简化 Raft 中领导人选举算法。\n\n## 5 Raft 一致性算法\n\nRaft 是一种用来管理章节 2 中描述的复制日志的算法。图 2 为了参考之用，总结这个算法的简略版本，图 3 列举了这个算法的一些关键特性。图中的这些元素会在剩下的章节逐一介绍。\n\nRaft 通过选举一个杰出的领导人，然后给予他全部的管理复制日志的责任来实现一致性。领导人从客户端接收日志条目（log entries），把日志条目复制到其他服务器上，并告诉其他的服务器什么时候可以安全地将日志条目应用到他们的状态机中。拥有一个领导人大大简化了对复制日志的管理。例如，领导人可以决定新的日志条目需要放在日志中的什么位置而不需要和其他服务器商议，并且数据都从领导人流向其他服务器。一个领导人可能会发生故障，或者和其他服务器失去连接，在这种情况下一个新的领导人会被选举出来。\n\n通过领导人的方式，Raft 将一致性问题分解成了三个相对独立的子问题，这些问题会在接下来的子章节中进行讨论：\n\n* **领导选举**：当现存的领导人发生故障的时候, 一个新的领导人需要被选举出来（章节 5.2）\n* **日志复制**：领导人必须从客户端接收日志条目（log entries）然后复制到集群中的其他节点，并强制要求其他节点的日志和自己保持一致。\n* **安全性**：在 Raft 中安全性的关键是在图 3 中展示的状态机安全：如果有任何的服务器节点已经应用了一个确定的日志条目到它的状态机中，那么其他服务器节点不能在同一个日志索引位置应用一个不同的指令。章节 5.4 阐述了 Raft 算法是如何保证这个特性的；这个解决方案涉及到选举机制（5.2 节）上的一个额外限制。\n\n在展示一致性算法之后，这一章节会讨论一些可用性的问题和计时在系统中的作用。\n\n**状态**：\n\n所有服务器上的持久性状态\n(在响应 RPC 请求之前，已经更新到了稳定的存储设备)\n\n| 参数 | 解释 |\n| --- | --- |\n| currentTerm | 服务器已知最新的任期（在服务器首次启动时初始化为0，单调递增）|\n| votedFor | 当前任期内收到选票的 candidateId，如果没有投给任何候选人 则为空|\n| log[] | 日志条目；每个条目包含了用于状态机的命令，以及领导人接收到该条目时的任期（初始索引为1） |\n\n所有服务器上的易失性状态\n\n| 参数 | 解释 |\n| --- | --- |\n| commitIndex | 已知已提交的最高的日志条目的索引（初始值为0，单调递增）|\n| lastApplied | 已经被应用到状态机的最高的日志条目的索引（初始值为0，单调递增）|\n\n领导人（服务器）上的易失性状态\n(选举后已经重新初始化)\n\n| 参数 | 解释 |\n| --- | --- |\n| nextIndex[] | 对于每一台服务器，发送到该服务器的下一个日志条目的索引（初始值为领导人最后的日志条目的索引+1）|\n| matchIndex[] | 对于每一台服务器，已知的已经复制到该服务器的最高日志条目的索引（初始值为0，单调递增）|\n\n**追加条目（AppendEntries）RPC**：\n\n由领导人调用，用于日志条目的复制，同时也被当做心跳使用\n\n| 参数 | 解释 |\n| --- | --- |\n| term | 领导人的任期 |\n| leaderId | 领导人 ID 因此跟随者可以对客户端进行重定向（译者注：跟随者根据领导人 ID 把客户端的请求重定向到领导人，比如有时客户端把请求发给了跟随者而不是领导人） |\n| prevLogIndex | 紧邻新日志条目之前的那个日志条目的索引 |\n| prevLogTerm | 紧邻新日志条目之前的那个日志条目的任期 |\n| entries[] | 需要被保存的日志条目（被当做心跳使用时，则日志条目内容为空；为了提高效率可能一次性发送多个） |\n| leaderCommit | 领导人的已知已提交的最高的日志条目的索引 |\n\n<br>\n\n| 返回值 | 解释 |\n| --- | --- |\n| term | 当前任期，对于领导人而言 它会更新自己的任期 |\n| success | 如果跟随者所含有的条目和 prevLogIndex 以及 prevLogTerm 匹配上了，则为 true |\n\n接收者的实现：\n\n1. 返回假 如果领导人的任期小于接收者的当前任期（译者注：这里的接收者是指跟随者或者候选人）（5.1 节）\n2. 返回假 如果接收者日志中没有包含这样一个条目 即该条目的任期在 prevLogIndex 上能和 prevLogTerm 匹配上\n    （译者注：在接收者日志中 如果能找到一个和 prevLogIndex 以及 prevLogTerm 一样的索引和任期的日志条目 则继续执行下面的步骤 否则返回假）（5.3 节）\n3. 如果一个已经存在的条目和新条目（译者注：即刚刚接收到的日志条目）发生了冲突（因为索引相同，任期不同），那么就删除这个已经存在的条目以及它之后的所有条目 （5.3 节）\n4. 追加日志中尚未存在的任何新条目\n5. 如果领导人的已知已提交的最高日志条目的索引大于接收者的已知已提交最高日志条目的索引（`leaderCommit > commitIndex`），则把接收者的已知已经提交的最高的日志条目的索引commitIndex 重置为 领导人的已知已经提交的最高的日志条目的索引 leaderCommit 或者是 上一个新条目的索引 取两者的最小值\n\n**请求投票（RequestVote）RPC**：\n\n由候选人负责调用用来征集选票（5.2 节）\n\n| 参数 | 解释 |\n| --- | --- |\n| term | 候选人的任期号 |\n| candidateId | 请求选票的候选人的 ID |\n| lastLogIndex | 候选人的最后日志条目的索引值 |\n| lastLogTerm | 候选人最后日志条目的任期号 |\n\n<br>\n\n| 返回值 | 解释 |\n| --- | --- |\n| term | 当前任期号，以便于候选人去更新自己的任期号 |\n| voteGranted | 候选人赢得了此张选票时为真 |\n\n接收者实现：\n\n1. 如果`term < currentTerm`返回 false （5.2 节）\n2. 如果 votedFor 为空或者为 candidateId，并且候选人的日志至少和自己一样新，那么就投票给他（5.2 节，5.4 节）\n\n**所有服务器需遵守的规则**：\n\n所有服务器：\n\n* 如果`commitIndex > lastApplied`，则 lastApplied 递增，并将`log[lastApplied]`应用到状态机中（5.3 节）\n* 如果接收到的 RPC 请求或响应中，任期号`T > currentTerm`，则令 `currentTerm = T`，并切换为跟随者状态（5.1 节）\n\n跟随者（5.2 节）：\n\n* 响应来自候选人和领导人的请求\n* 如果在超过选举超时时间的情况之前没有收到**当前领导人**（即该领导人的任期需与这个跟随者的当前任期相同）的心跳/附加日志，或者是给某个候选人投了票，就自己变成候选人\n\n候选人（5.2 节）：\n\n* 在转变成候选人后就立即开始选举过程\n\t* 自增当前的任期号（currentTerm）\n\t* 给自己投票\n\t* 重置选举超时计时器\n\t* 发送请求投票的 RPC 给其他所有服务器\n* 如果接收到大多数服务器的选票，那么就变成领导人\n* 如果接收到来自新的领导人的附加日志（AppendEntries）RPC，则转变成跟随者\n* 如果选举过程超时，则再次发起一轮选举\n\n领导人：\n\n* 一旦成为领导人：发送空的附加日志（AppendEntries）RPC（心跳）给其他所有的服务器；在一定的空余时间之后不停的重复发送，以防止跟随者超时（5.2 节）\n*  如果接收到来自客户端的请求：附加条目到本地日志中，在条目被应用到状态机后响应客户端（5.3 节）\n*  如果对于一个跟随者，最后日志条目的索引值大于等于 nextIndex（`lastLogIndex ≥ nextIndex`），则发送从 nextIndex 开始的所有日志条目：\n\t* 如果成功：更新相应跟随者的 nextIndex 和 matchIndex\n\t* 如果因为日志不一致而失败，则 nextIndex 递减并重试\n* 假设存在 N 满足`N > commitIndex`，使得大多数的 `matchIndex[i] ≥ N`以及`log[N].term == currentTerm` 成立，则令 `commitIndex = N`（5.3 和 5.4 节）\n\n![图 2](/img/2023-06-25-raft-zh_cn/raft-图2.png)\n\n> 图 2：一个关于 Raft 一致性算法的浓缩总结（不包括成员变换和日志压缩）。\n\n| 特性 | 解释 |\n| --- | --- |\n|选举安全特性| 对于一个给定的任期号，最多只会有一个领导人被选举出来（5.2 节）|\n|领导人只附加原则| 领导人绝对不会删除或者覆盖自己的日志，只会增加（5.3 节）|\n|日志匹配原则| 如果两个日志在某一相同索引位置日志条目的任期号相同，那么我们就认为这两个日志从头到该索引位置之间的内容完全一致（5.3 节）|\n|领导人完全特性|如果某个日志条目在某个任期号中已经被提交，那么这个条目必然出现在更大任期号的所有领导人中（5.4 节）|\n|状态机安全特性| 如果某一服务器已将给定索引位置的日志条目应用至其状态机中，则其他任何服务器在该索引位置不会应用不同的日志条目（5.4.3 节）|\n\n![图 3 ](/img/2023-06-25-raft-zh_cn/raft-图3.png)\n\n> 图 3：Raft 在任何时候都保证以上的各个特性。\n\n### 5.1 Raft 基础\n\n一个 Raft 集群包含若干个服务器节点；5 个服务器节点是一个典型的例子，这允许整个系统容忍 2 个节点失效。在任何时刻，每一个服务器节点都处于这三个状态之一：领导人、跟随者或者候选人。在通常情况下，系统中只有一个领导人并且其他的节点全部都是跟随者。跟随者都是被动的：他们不会发送任何请求，只是简单的响应来自领导人或者候选人的请求。领导人处理所有的客户端请求（如果一个客户端和跟随者联系，那么跟随者会把请求重定向给领导人）。第三种状态，候选人，是用来在 5.2 节描述的选举新领导人时使用。图 4 展示了这些状态和他们之间的转换关系；这些转换关系会在接下来进行讨论。\n\n![图 4 ](/img/2023-06-25-raft-zh_cn/raft-图4.png)\n\n> 图 4：服务器状态。跟随者只响应来自其他服务器的请求。如果跟随者接收不到消息，那么他就会变成候选人并发起一次选举。获得集群中大多数选票的候选人将成为领导人。在一个任期内，领导人一直都会是领导人，直到自己宕机了。\n\n![图 5](/img/2023-06-25-raft-zh_cn/raft-图5.png)\n\n> 图 5：时间被划分成一个个的任期，每个任期始于一次选举。在选举成功后，领导人会管理整个集群直到任期结束。有时候选举会失败，那么这个任期就会没有领导人而结束。任期之间的切换可以在不同的时间不同的服务器上观察到。\n\nRaft 把时间分割成任意长度的**任期**，如图 5。任期用连续的整数标记。每一段任期从一次**选举**开始，就像章节 5.2 描述的一样，一个或者多个候选人尝试成为领导人。如果一个候选人赢得选举，然后他就在接下来的任期内充当领导人的职责。在某些情况下，一次选举过程会造成选票的瓜分。在这种情况下，这一任期会以没有领导人结束；一个新的任期（和一次新的选举）会很快重新开始。Raft 保证了在一个给定的任期内，最多只有一个领导人。\n\n不同的服务器节点可能多次观察到任期之间的转换，但在某些情况下，一个节点也可能观察不到任何一次选举或者整个任期全程。任期在 Raft 算法中充当逻辑时钟的作用，任期使得服务器可以检测一些过期的信息：比如过期的领导人。每个节点存储一个当前任期号，这一编号在整个时期内单调递增。每当服务器之间通信的时候都会交换当前任期号；如果一个服务器的当前任期号比其他人小，那么他会更新自己的任期号到较大的任期号值。如果一个候选人或者领导人发现自己的任期号过期了，那么他会立即恢复成跟随者状态。如果一个节点接收到一个包含过期的任期号的请求，那么他会直接拒绝这个请求。\n\nRaft 算法中服务器节点之间通信使用远程过程调用（RPCs），并且基本的一致性算法只需要两种类型的 RPCs。请求投票（RequestVote） RPCs 由候选人在选举期间发起（章节  5.2），然后附加条目（AppendEntries）RPCs 由领导人发起，用来复制日志和提供一种心跳机制（章节 5.3）。第 7 节为了在服务器之间传输快照增加了第三种 RPC。当服务器没有及时的收到 RPC 的响应时，会进行重试， 并且他们能够并行的发起 RPCs 来获得最佳的性能。\n\n### 5.2 领导人选举\n\nRaft 使用一种心跳机制来触发领导人选举。当服务器程序启动时，他们都是跟随者身份。一个服务器节点继续保持着跟随者状态只要他从领导人或者候选人处接收到有效的 RPCs。领导人周期性的向所有跟随者发送心跳包（即不包含日志项内容的附加条目（AppendEntries） RPCs）来维持自己的权威。如果一个跟随者在一段时间里没有接收到任何消息，也就是**选举超时**，那么他就会认为系统中没有可用的领导人,并且发起选举以选出新的领导人。\n\n要开始一次选举过程，跟随者先要增加自己的当前任期号并且转换到候选人状态。然后他会并行地向集群中的其他服务器节点发送请求投票的 RPCs 来给自己投票。候选人会继续保持着当前状态直到以下三件事情之一发生：(a) 他自己赢得了这次的选举，(b) 其他的服务器成为领导人，(c) 一段时间之后没有任何一个获胜的人。这些结果会分别的在下面的段落里进行讨论。\n\n当一个候选人从整个集群的大多数服务器节点获得了针对同一个任期号的选票，那么他就赢得了这次选举并成为领导人。每一个服务器最多会对一个任期号投出一张选票，按照先来先服务的原则（注意：5.4 节在投票上增加了一点额外的限制）。要求大多数选票的规则确保了最多只会有一个候选人赢得此次选举（图 3 中的选举安全性）。一旦候选人赢得选举，他就立即成为领导人。然后他会向其他的服务器发送心跳消息来建立自己的权威并且阻止发起新的选举。\n\n在等待投票的时候，候选人可能会从其他的服务器接收到声明它是领导人的附加条目（AppendEntries）RPC。如果这个领导人的任期号（包含在此次的 RPC中）不小于候选人当前的任期号，那么候选人会承认领导人合法并回到跟随者状态。 如果此次 RPC 中的任期号比自己小，那么候选人就会拒绝这次的 RPC 并且继续保持候选人状态。\n\n第三种可能的结果是候选人既没有赢得选举也没有输：如果有多个跟随者同时成为候选人，那么选票可能会被瓜分以至于没有候选人可以赢得大多数人的支持。当这种情况发生的时候，每一个候选人都会超时，然后通过增加当前任期号来开始一轮新的选举。然而，没有其他机制的话，选票可能会被无限的重复瓜分。\n\nRaft 算法使用随机选举超时时间的方法来确保很少会发生选票瓜分的情况，就算发生也能很快的解决。为了阻止选票起初就被瓜分，选举超时时间是从一个固定的区间（例如 150-300 毫秒）随机选择。这样可以把服务器都分散开以至于在大多数情况下只有一个服务器会选举超时；然后他赢得选举并在其他服务器超时之前发送心跳包。同样的机制被用在选票瓜分的情况下。每一个候选人在开始一次选举的时候会重置一个随机的选举超时时间，然后在超时时间内等待投票的结果；这样减少了在新的选举中另外的选票瓜分的可能性。9.3 节展示了这种方案能够快速的选出一个领导人。\n\n领导人选举这个例子，体现了可理解性原则是如何指导我们进行方案设计的。起初我们计划使用一种排名系统：每一个候选人都被赋予一个唯一的排名，供候选人之间竞争时进行选择。如果一个候选人发现另一个候选人拥有更高的排名，那么他就会回到跟随者状态，这样高排名的候选人能够更加容易的赢得下一次选举。但是我们发现这种方法在可用性方面会有一点问题（如果高排名的服务器宕机了，那么低排名的服务器可能会超时并再次进入候选人状态。而且如果这个行为发生得足够快，则可能会导致整个选举过程都被重置掉）。我们针对算法进行了多次调整，但是每次调整之后都会有新的问题。最终我们认为随机重试的方法是更加明显和易于理解的。\n\n### 5.3 日志复制\n\n一旦一个领导人被选举出来，他就开始为客户端提供服务。客户端的每一个请求都包含一条被复制状态机执行的指令。领导人把这条指令作为一条新的日志条目附加到日志中去，然后并行地发起附加条目 RPCs 给其他的服务器，让他们复制这条日志条目。当这条日志条目被安全地复制（下面会介绍），领导人会应用这条日志条目到它的状态机中然后把执行的结果返回给客户端。如果跟随者崩溃或者运行缓慢，再或者网络丢包，领导人会不断的重复尝试附加日志条目 RPCs （尽管已经回复了客户端）直到所有的跟随者都最终存储了所有的日志条目。\n\n![图 6](/img/2023-06-25-raft-zh_cn/raft-图6.png)\n\n> 图 6：日志由有序序号标记的条目组成。每个条目都包含创建时的任期号（图中框中的数字），和一个状态机需要执行的指令。一个条目当可以安全地被应用到状态机中去的时候，就认为是可以提交了。\n\n日志以图 6 展示的方式组织。每一个日志条目存储一条状态机指令和从领导人收到这条指令时的任期号。日志中的任期号用来检查是否出现不一致的情况，同时也用来保证图 3 中的某些性质。每一条日志条目同时也都有一个整数索引值来表明它在日志中的位置。\n\n领导人来决定什么时候把日志条目应用到状态机中是安全的；这种日志条目被称为**已提交**。Raft 算法保证所有已提交的日志条目都是持久化的并且最终会被所有可用的状态机执行。在领导人将创建的日志条目复制到大多数的服务器上的时候，日志条目就会被提交（例如在图 6 中的条目 7）。同时，领导人的日志中之前的所有日志条目也都会被提交，包括由其他领导人创建的条目。5.4 节会讨论某些当在领导人改变之后应用这条规则的隐晦内容，同时他也展示了这种提交的定义是安全的。领导人跟踪了最大的将会被提交的日志项的索引，并且索引值会被包含在未来的所有附加日志 RPCs （包括心跳包），这样其他的服务器才能最终知道领导人的提交位置。一旦跟随者知道一条日志条目已经被提交，那么他也会将这个日志条目应用到本地的状态机中（按照日志的顺序）。\n\n我们设计了 Raft 的日志机制来维护不同服务器日志之间的高层次的一致性。这么做不仅简化了系统的行为也使其更具有可预测性，同时它也是安全性保证的一个重要组件。Raft 维护着以下的特性，这些特性共同组成了图 3 中的**日志匹配特性（Log Matching Property）**：\n\n* 如果在不同的日志中的两个条目拥有相同的索引和任期号，那么他们存储了相同的指令。\n* 如果在不同的日志中的两个条目拥有相同的索引和任期号，那么他们之前的所有日志条目也全部相同。\n\n第一个特性来自这样的一个事实，领导人最多在一个任期里在指定的一个日志索引位置创建一条日志条目，同时日志条目在日志中的位置也从来不会改变。第二个特性由附加日志 RPC 的一个简单的一致性检查所保证。在发送附加日志 RPC 的时候，领导人会把新的日志条目前紧挨着的条目的索引位置和任期号包含在日志内。如果跟随者在它的日志中找不到包含相同索引位置和任期号的条目，那么他就会拒绝接收新的日志条目。一致性检查就像一个归纳步骤：一开始空的日志状态肯定是满足日志匹配特性的，然后一致性检查在日志扩展的时候保护了日志匹配特性。因此，每当附加日志 RPC 返回成功时，领导人就知道跟随者的日志一定是和自己相同的了。\n\n在正常的操作中，领导人和跟随者的日志保持一致性，所以附加日志 RPC 的一致性检查从来不会失败。然而，领导人崩溃的情况会使得日志处于不一致的状态（老的领导人可能还没有完全复制所有的日志条目）。这种不一致问题会在领导人和跟随者的一系列崩溃下加剧。图 7 展示了跟随者的日志可能和新的领导人不同。跟随者可能会丢失一些在新的领导人中存在的日志条目，他也可能拥有一些领导人没有的日志条目，或者两者都发生。丢失或者多出日志条目可能会持续多个任期。\n\n![图 7](/img/2023-06-25-raft-zh_cn/raft-图7.png)\n\n> 图 7：当一个领导人成功当选时，跟随者可能是任何情况（a-f）。每一个盒子表示是一个日志条目；里面的数字表示任期号。跟随者可能会缺少一些日志条目（a-b），可能会有一些未被提交的日志条目（c-d），或者两种情况都存在（e-f）。例如，场景 f 可能会这样发生，某服务器在任期 2 的时候是领导人，已附加了一些日志条目到自己的日志中，但在提交之前就崩溃了；很快这个机器就被重启了，在任期 3 重新被选为领导人，并且又增加了一些日志条目到自己的日志中；在任期 2 和任期 3 的日志被提交之前，这个服务器又宕机了，并且在接下来的几个任期里一直处于宕机状态。\n\n在 Raft 算法中，领导人是通过强制跟随者直接复制自己的日志来处理不一致问题的。这意味着在跟随者中的冲突的日志条目会被领导人的日志覆盖。5.4 节会阐述如何通过增加一些限制来使得这样的操作是安全的。\n\n要使得跟随者的日志进入和自己一致的状态，领导人必须找到最后两者达成一致的地方，然后删除跟随者从那个点之后的所有日志条目，并发送自己在那个点之后的日志给跟随者。所有的这些操作都在进行附加日志 RPCs 的一致性检查时完成。领导人针对每一个跟随者维护了一个 **nextIndex**，这表示下一个需要发送给跟随者的日志条目的索引地址。当一个领导人刚获得权力的时候，他初始化所有的 nextIndex 值为自己的最后一条日志的 index 加 1（图 7 中的 11）。如果一个跟随者的日志和领导人不一致，那么在下一次的附加日志 RPC 时的一致性检查就会失败。在被跟随者拒绝之后，领导人就会减小 nextIndex 值并进行重试。最终 nextIndex 会在某个位置使得领导人和跟随者的日志达成一致。当这种情况发生，附加日志 RPC 就会成功，这时就会把跟随者冲突的日志条目全部删除并且加上领导人的日志。一旦附加日志 RPC 成功，那么跟随者的日志就会和领导人保持一致，并且在接下来的任期里一直继续保持。\n\n> 如果需要的话，算法可以通过减少被拒绝的附加日志 RPCs 的次数来优化。例如，当附加日志 RPC 的请求被拒绝的时候，跟随者可以(返回)冲突条目的任期号和该任期号对应的最小索引地址。借助这些信息，领导人可以减小 nextIndex 一次性越过该冲突任期的所有日志条目；这样就变成每个任期需要一次附加条目 RPC 而不是每个条目一次。在实践中，我们十分怀疑这种优化是否是必要的，因为失败是很少发生的并且也不大可能会有这么多不一致的日志。\n\n通过这种机制，领导人在获得权力的时候就不需要任何特殊的操作来恢复一致性。他只需要进行正常的操作，然后日志就能在回复附加日志 RPC 的一致性检查失败的时候自动趋于一致。领导人从来不会覆盖或者删除自己的日志（图 3 的领导人只附加特性）。\n\n日志复制机制展示出了第 2 节中形容的一致性特性：Raft 能够接受，复制并应用新的日志条目只要大部分的机器是工作的；在通常的情况下，新的日志条目可以在一次 RPC 中被复制给集群中的大多数机器；并且单个的缓慢的跟随者不会影响整体的性能。\n\n### 5.4 安全性\n\n前面的章节里描述了 Raft 算法是如何选举和复制日志的。然而，到目前为止描述的机制并不能充分的保证每一个状态机会按照相同的顺序执行相同的指令。例如，一个跟随者可能会进入不可用状态同时领导人已经提交了若干的日志条目，然后这个跟随者可能会被选举为领导人并且覆盖这些日志条目；因此，不同的状态机可能会执行不同的指令序列。\n\n这一节通过在领导选举的时候增加一些限制来完善 Raft 算法。这一限制保证了任何的领导人对于给定的任期号，都拥有了之前任期的所有被提交的日志条目（图 3 中的领导人完整特性）。增加这一选举时的限制，我们对于提交时的规则也更加清晰。最终，我们将展示对于**领导人完整特性（Leader Completeness Property）** 的简要证明，并且说明该特性是如何引导复制状态机做出正确行为的。\n\n#### 5.4.1 选举限制\n\n在任何基于领导人的一致性算法中，领导人都必须存储所有已经提交的日志条目。在某些一致性算法中，例如 Viewstamped Replication，某个节点即使是一开始并没有包含所有已经提交的日志条目，它也能被选为领导人。这些算法都包含一些额外的机制来识别丢失的日志条目并把他们传送给新的领导人，要么是在选举阶段要么在之后很快进行。不幸的是，这种方法会导致相当大的额外的机制和复杂性。Raft 使用了一种更加简单的方法，它可以保证在选举的时候新的领导人拥有所有之前任期中已经提交的日志条目，而不需要传送这些日志条目给领导人。这意味着日志条目的传送是单向的，只从领导人传给跟随者，并且领导人从不会覆盖自身本地日志中已经存在的条目。\n\nRaft 使用投票的方式来阻止一个候选人赢得选举，除非这个候选人包含了所有已经提交的日志条目。候选人为了赢得选举必须联系集群中的大部分节点，这意味着每一个已经提交的日志条目在这些服务器节点中肯定存在于至少一个节点上。如果候选人的日志至少和大多数的服务器节点一样新（这个新的定义会在下面讨论），那么他一定持有了所有已经提交的日志条目。请求投票（RequestVote） RPC 实现了这样的限制：RPC 中包含了候选人的日志信息，然后投票人会拒绝掉那些日志没有自己新的投票请求。\n\nRaft 通过比较两份日志中最后一条日志条目的索引值和任期号定义谁的日志比较新。如果两份日志最后的条目的任期号不同，那么任期号大的日志更加新。如果两份日志最后的条目任期号相同，那么日志比较长的那个就更加新。\n\n#### 5.4.2 提交之前任期内的日志条目\n\n如同 5.3 节介绍的那样，领导人知道一条当前任期内的日志记录是可以被提交的，只要它被存储到了大多数的服务器上。如果一个领导人在提交日志条目之前崩溃了，未来后续的领导人会继续尝试复制这条日志记录。然而，一个领导人不能断定一个之前任期里的日志条目被保存到大多数服务器上的时候就一定已经提交了。图 8 展示了一种情况，一条已经被存储到大多数节点上的老日志条目，也依然有可能会被未来的领导人覆盖掉。\n\n![图 8](/img/2023-06-25-raft-zh_cn/raft-图8.png)\n\n> 图 8：如图的时间序列展示了为什么领导人无法决定对老任期号的日志条目进行提交。在 (a) 中，S1 是领导人，部分的(跟随者)复制了索引位置 2 的日志条目。在 (b) 中，S1 崩溃了，然后 S5 在任期 3 里通过 S3、S4 和自己的选票赢得选举，然后从客户端接收了一条不一样的日志条目放在了索引 2 处。然后到 (c)，S5 又崩溃了；S1 重新启动，选举成功，开始复制日志。在这时，来自任期 2 的那条日志已经被复制到了集群中的大多数机器上，但是还没有被提交。如果 S1 在 (d) 中又崩溃了，S5 可以重新被选举成功（通过来自 S2，S3 和 S4 的选票），然后覆盖了他们在索引 2 处的日志。反之，如果在崩溃之前，S1 把自己主导的新任期里产生的日志条目复制到了大多数机器上，就如 (e) 中那样，那么在后面任期里面这些新的日志条目就会被提交（因为 S5 就不可能选举成功）。 这样在同一时刻就同时保证了，之前的所有老的日志条目就会被提交。\n\n为了消除图 8 里描述的情况，Raft 永远不会通过计算副本数目的方式去提交一个之前任期内的日志条目。只有领导人当前任期里的日志条目通过计算副本数目可以被提交；一旦当前任期的日志条目以这种方式被提交，那么由于日志匹配特性，之前的日志条目也都会被间接的提交。在某些情况下，领导人可以安全的知道一个老的日志条目是否已经被提交（例如，该条目是否存储到所有服务器上），但是 Raft 为了简化问题使用一种更加保守的方法。\n\n当领导人复制之前任期里的日志时，Raft 会为所有日志保留原始的任期号, 这在提交规则上产生了额外的复杂性。在其他的一致性算法中，如果一个新的领导人要重新复制之前的任期里的日志时，它必须使用当前新的任期号。Raft 使用的方法更加容易辨别出日志，因为它可以随着时间和日志的变化对日志维护着同一个任期编号。另外，和其他的算法相比，Raft 中的新领导人只需要发送更少日志条目（其他算法中必须在他们被提交之前发送更多的冗余日志条目来为他们重新编号）。\n\n#### 5.4.3 安全性论证\n\n在给定了完整的 Raft 算法之后，我们现在可以更加精确的讨论领导人完整性特性（这一讨论基于 9.2 节的安全性证明）。我们假设领导人完全性特性是不存在的，然后我们推出矛盾来。假设任期 T 的领导人（领导人 T）在任期内提交了一条日志条目，但是这条日志条目没有被存储到未来某个任期的领导人的日志中。设大于 T 的最小任期 U 的领导人 U 没有这条日志条目。\n\n![图 9](/img/2023-06-25-raft-zh_cn/raft-图9.png)\n\n> 图 9：如果 S1 （任期 T 的领导人）在它的任期里提交了一条新的日志，然后 S5 在之后的任期 U 里被选举为领导人，那么至少会有一个机器，如 S3，既拥有来自 S1 的日志，也给 S5 投票了。\n\n1. 在领导人 U 选举的时候一定没有那条被提交的日志条目（领导人从不会删除或者覆盖任何条目）。\n2. 领导人 T 复制这条日志条目给集群中的大多数节点，同时，领导人 U 从集群中的大多数节点赢得了选票。因此，至少有一个节点（投票者、选民）同时接受了来自领导人 T 的日志条目，并且给领导人 U 投票了，如图 9。这个投票者是产生这个矛盾的关键。\n3. 这个投票者必须在给领导人 U 投票之前先接受了从领导人 T 发来的已经被提交的日志条目；否则他就会拒绝来自领导人 T 的附加日志请求（因为此时他的任期号会比 T 大）。\n4. 投票者在给领导人 U 投票时依然保存有这条日志条目，因为任何中间的领导人都包含该日志条目（根据上述的假设），领导人从不会删除条目，并且跟随者只有在和领导人冲突的时候才会删除条目。\n5. 投票者把自己选票投给领导人 U 时，领导人 U 的日志必须和投票者自己一样新。这就导致了两者矛盾之一。\n6. 首先，如果投票者和领导人 U 的最后一条日志的任期号相同，那么领导人 U 的日志至少和投票者一样长，所以领导人 U 的日志一定包含所有投票者的日志。这是另一处矛盾，因为投票者包含了那条已经被提交的日志条目，但是在上述的假设里，领导人 U 是不包含的。\n7. 除此之外，领导人 U 的最后一条日志的任期号就必须比投票人大了。此外，他也比 T 大，因为投票人的最后一条日志的任期号至少和 T 一样大（他包含了来自任期 T 的已提交的日志）。创建了领导人 U 最后一条日志的之前领导人一定已经包含了那条被提交的日志（根据上述假设，领导人 U 是第一个不包含该日志条目的领导人）。所以，根据日志匹配特性，领导人 U 一定也包含那条被提交的日志，这里产生矛盾。\n8. 这里完成了矛盾。因此，所有比 T 大的领导人一定包含了所有来自 T 的已经被提交的日志。\n9. 日志匹配原则保证了未来的领导人也同时会包含被间接提交的条目，例如图 8 (e) 中的索引 2。\n\n通过领导人完全特性，我们就能证明图 3 中的状态机安全特性，即如果服务器已经在某个给定的索引值应用了日志条目到自己的状态机里，那么其他的服务器不会应用一个不一样的日志到同一个索引值上。在一个服务器应用一条日志条目到他自己的状态机中时，他的日志必须和领导人的日志，在该条目和之前的条目上相同，并且已经被提交。现在我们来考虑在任何一个服务器应用一个指定索引位置的日志的最小任期；日志完全特性保证拥有更高任期号的领导人会存储相同的日志条目，所以之后的任期里应用某个索引位置的日志条目也会是相同的值。因此，状态机安全特性是成立的。\n\n最后，Raft 要求服务器按照日志中索引位置顺序应用日志条目。和状态机安全特性结合起来看，这就意味着所有的服务器会应用相同的日志序列集到自己的状态机中，并且是按照相同的顺序。\n\n### 5.5 跟随者和候选人崩溃\n\n到目前为止，我们都只关注了领导人崩溃的情况。跟随者和候选人崩溃后的处理方式比领导人要简单的多，并且他们的处理方式是相同的。如果跟随者或者候选人崩溃了，那么后续发送给他们的 RPCs 都会失败。Raft 中处理这种失败就是简单地通过无限的重试；如果崩溃的机器重启了，那么这些 RPC 就会完整的成功。如果一个服务器在完成了一个 RPC，但是还没有响应的时候崩溃了，那么在他重新启动之后就会再次收到同样的请求。Raft 的 RPCs 都是幂等的，所以这样重试不会造成任何问题。例如一个跟随者如果收到附加日志请求但是他已经包含了这一日志，那么他就会直接忽略这个新的请求。\n\n### 5.6 时间和可用性\n\nRaft 的要求之一就是安全性不能依赖时间：整个系统不能因为某些事件运行的比预期快一点或者慢一点就产生了错误的结果。但是，可用性（系统可以及时的响应客户端）不可避免的要依赖于时间。例如，如果消息交换比服务器故障间隔时间长，候选人将没有足够长的时间来赢得选举；没有一个稳定的领导人，Raft 将无法工作。\n\n领导人选举是 Raft 中对时间要求最为关键的方面。Raft 可以选举并维持一个稳定的领导人,只要系统满足下面的时间要求：\n\n> 广播时间（broadcastTime）  <<  选举超时时间（electionTimeout） <<  平均故障间隔时间（MTBF）\n\n在这个不等式中，广播时间指的是从一个服务器并行的发送 RPCs 给集群中的其他服务器并接收响应的平均时间；选举超时时间就是在 5.2 节中介绍的选举的超时时间限制；然后平均故障间隔时间就是对于一台服务器而言，两次故障之间的平均时间。广播时间必须比选举超时时间小一个量级，这样领导人才能够发送稳定的心跳消息来阻止跟随者开始进入选举状态；通过随机化选举超时时间的方法，这个不等式也使得选票瓜分的情况变得不可能。选举超时时间应该要比平均故障间隔时间小上几个数量级，这样整个系统才能稳定的运行。当领导人崩溃后，整个系统会大约相当于选举超时的时间里不可用；我们希望这种情况在整个系统的运行中很少出现。\n\n广播时间和平均故障间隔时间是由系统决定的，但是选举超时时间是我们自己选择的。Raft 的 RPCs 需要接收方将信息持久化的保存到稳定存储中去，所以广播时间大约是 0.5 毫秒到 20 毫秒，取决于存储的技术。因此，选举超时时间可能需要在 10 毫秒到 500 毫秒之间。大多数的服务器的平均故障间隔时间都在几个月甚至更长，很容易满足时间的需求。\n\n## 6 集群成员变化\n\n到目前为止，我们都假设集群的配置（加入到一致性算法的服务器集合）是固定不变的。但是在实践中，偶尔是会改变集群的配置的，例如替换那些宕机的机器或者改变复制级别。尽管可以通过暂停整个集群，更新所有配置，然后重启整个集群的方式来实现，但是在更改的时候集群会不可用。另外，如果存在手工操作步骤，那么就会有操作失误的风险。为了避免这样的问题，我们决定自动化配置改变并且将其纳入到 Raft 一致性算法中来。\n\n为了让配置修改机制能够安全，那么在转换的过程中不能够存在任何时间点使得两个领导人在同一个任期里同时被选举成功。不幸的是，任何服务器直接从旧的配置直接转换到新的配置的方案都是不安全的。一次性原子地转换所有服务器是不可能的，所以在转换期间整个集群存在划分成两个独立的大多数群体的可能性（见图 10）。\n\n![图 10](/img/2023-06-25-raft-zh_cn/raft-图10.png)\n\n> 图 10：直接从一种配置转到新的配置是十分不安全的，因为各个机器可能在任何的时候进行转换。在这个例子中，集群配额从 3 台机器变成了 5 台。不幸的是，存在这样的一个时间点，两个不同的领导人在同一个任期里都可以被选举成功。一个是通过旧的配置，一个通过新的配置。\n\n为了保证安全性，配置更改必须使用两阶段方法。目前有很多种两阶段的实现。例如，有些系统在第一阶段停掉旧的配置所以集群就不能处理客户端请求；然后在第二阶段在启用新的配置。在 Raft 中，集群先切换到一个过渡的配置，我们称之为共同一致（*joint consensus*)；一旦共同一致已经被提交了，那么系统就切换到新的配置上。共同一致是老配置和新配置的结合：\n\n* 日志条目被复制给集群中新、老配置的所有服务器。\n* 新、旧配置的服务器都可以成为领导人。\n* 达成一致（针对选举和提交）需要分别在两种配置上获得大多数的支持。\n\n共同一致允许独立的服务器在不影响安全性的前提下，在不同的时间进行配置转换过程。此外，共同一致可以让集群在配置转换的过程中依然响应客户端的请求。\n\n集群配置在复制日志中以特殊的日志条目来存储和通信；图 11 展示了配置转换的过程。当一个领导人接收到一个改变配置从 C-old 到 C-new 的请求，他会为了共同一致存储配置（图中的 C-old,new），以前面描述的日志条目和副本的形式。一旦一个服务器将新的配置日志条目增加到它的日志中，他就会用这个配置来做出未来所有的决定（服务器总是使用最新的配置，无论他是否已经被提交）。这意味着领导人要使用  C-old,new 的规则来决定日志条目 C-old,new 什么时候需要被提交。如果领导人崩溃了，被选出来的新领导人可能是使用 C-old 配置也可能是 C-old,new 配置，这取决于赢得选举的候选人是否已经接收到了 C-old,new 配置。在任何情况下， C-new 配置在这一时期都不会单方面的做出决定。\n\n一旦 C-old,new 被提交，那么无论是 C-old 还是 C-new，如果不经过另一个配置的允许都不能单独做出决定，并且领导人完全特性保证了只有拥有 C-old,new 日志条目的服务器才有可能被选举为领导人。这个时候，领导人创建一条关于 C-new 配置的日志条目并复制给集群就是安全的了。再者，每个服务器在见到新的配置的时候就会立即生效。当新的配置在 C-new 的规则下被提交，旧的配置就变得无关紧要，同时不使用新的配置的服务器就可以被关闭了。如图 11，C-old 和 C-new 没有任何机会同时做出单方面的决定；这保证了安全性。\n\n![图 11](/img/2023-06-25-raft-zh_cn/raft-图11.png)\n\n> 图 11：一个配置切换的时间线。虚线表示已经被创建但是还没有被提交的配置日志条目，实线表示最后被提交的配置日志条目。领导人首先创建了 C-old,new 的配置条目在自己的日志中，并提交到 C-old,new 中（C-old 的大多数和  C-new 的大多数）。然后他创建 C-new 条目并提交到 C-new 中的大多数。这样就不存在  C-new 和 C-old 可以同时做出决定的时间点。\n\n在关于重新配置还有三个问题需要提出。第一个问题是，新的服务器可能初始化没有存储任何的日志条目。当这些服务器以这种状态加入到集群中，那么他们需要一段时间来更新追赶，这时还不能提交新的日志条目。为了避免这种可用性的间隔时间，Raft 在配置更新之前使用了一种额外的阶段，在这个阶段，新的服务器以没有投票权身份加入到集群中来（领导人复制日志给他们，但是不考虑他们是大多数）。一旦新的服务器追赶上了集群中的其他机器，重新配置可以像上面描述的一样处理。\n\n第二个问题是，集群的领导人可能不是新配置的一员。在这种情况下，领导人就会在提交了 C-new 日志之后退位（回到跟随者状态）。这意味着有这样的一段时间，领导人管理着集群，但是不包括他自己；他复制日志但是不把他自己算作是大多数之一。当 C-new 被提交时，会发生领导人过渡，因为这时是最早新的配置可以独立工作的时间点（将总是能够在 C-new 配置下选出新的领导人）。在此之前，可能只能从 C-old 中选出领导人。\n\n第三个问题是，移除不在 C-new 中的服务器可能会扰乱集群。这些服务器将不会再接收到心跳，所以当选举超时，他们就会进行新的选举过程。他们会发送拥有新的任期号的请求投票 RPCs，这样会导致当前的领导人回退成跟随者状态。新的领导人最终会被选出来，但是被移除的服务器将会再次超时，然后这个过程会再次重复，导致整体可用性大幅降低。\n\n为了避免这个问题，当服务器确认当前领导人存在时，服务器会忽略请求投票 RPCs。确切地说，当服务器在当前最小选举超时时间内收到一个请求投票 RPC，他不会更新当前的任期号或者投出选票。这不会影响正常的选举，每个服务器在开始一次选举之前，至少等待一个最小选举超时时间。然而，这有利于避免被移除的服务器扰乱：如果领导人能够发送心跳给集群，那么他就不会被更大的任期号废黜。\n\n## 7 日志压缩\n\nRaft 的日志在正常操作中不断地增长，但是在实际的系统中，日志不能无限制地增长。随着日志不断增长，他会占用越来越多的空间，花费越来越多的时间来重置。如果没有一定的机制去清除日志里积累的陈旧的信息，那么会带来可用性问题。\n\n快照是最简单的压缩方法。在快照系统中，整个系统的状态都以快照的形式写入到稳定的持久化存储中，然后到那个时间点之前的日志全部丢弃。快照技术被使用在 Chubby 和 ZooKeeper 中，接下来的章节会介绍 Raft 中的快照技术。\n\n增量压缩的方法，例如日志清理或者日志结构合并树，都是可行的。这些方法每次只对一小部分数据进行操作，这样就分散了压缩的负载压力。首先，他们先选择一个已经积累的大量已经被删除或者被覆盖对象的区域，然后重写那个区域还活跃的对象，之后释放那个区域。和简单操作整个数据集合的快照相比，需要增加复杂的机制来实现。状态机可以实现 LSM tree 使用和快照相同的接口，但是日志清除方法就需要修改 Raft 了。\n\n![图 12](/img/2023-06-25-raft-zh_cn/raft-图12.png)\n\n> 图 12：一个服务器用新的快照替换了从 1 到 5 的条目，快照值存储了当前的状态。快照中包含了最后的索引位置和任期号。\n\n图 12 展示了 Raft 中快照的基础思想。每个服务器独立地创建快照，只包括已经被提交的日志。主要的工作包括将状态机的状态写入到快照中。Raft 也包含一些少量的元数据到快照中：**最后被包含索引**指的是被快照取代的最后的条目在日志中的索引值（状态机最后应用的日志），**最后被包含的任期**指的是该条目的任期号。保留这些数据是为了支持快照后紧接着的第一个条目的附加日志请求时的一致性检查，因为这个条目需要前一日志条目的索引值和任期号。为了支持集群成员更新（第 6 节），快照中也将最后的一次配置作为最后一个条目存下来。一旦服务器完成一次快照，他就可以删除最后索引位置之前的所有日志和快照了。\n\n尽管通常服务器都是独立地创建快照，但是领导人必须偶尔的发送快照给一些落后的跟随者。这通常发生在当领导人已经丢弃了下一条需要发送给跟随者的日志条目的时候。幸运的是这种情况不是常规操作：一个与领导人保持同步的跟随者通常都会有这个条目。然而一个运行非常缓慢的跟随者或者新加入集群的服务器（第 6 节）将不会有这个条目。这时让这个跟随者更新到最新的状态的方式就是通过网络把快照发送给他们。\n\n**安装快照 RPC**：\n\n由领导人调用以将快照的分块发送给跟随者。领导人总是按顺序发送分块。\n\n| 参数 | 解释 |\n|:----:|:----:|\n| term | 领导人的任期号 |\n| leaderId | 领导人的 ID，以便于跟随者重定向请求 |\n| lastIncludedIndex | 快照中包含的最后日志条目的索引值 |\n| lastIncludedTerm | 快照中包含的最后日志条目的任期号 |\n| offset | 分块在快照中的字节偏移量 |\n| data[] | 从偏移量开始的快照分块的原始字节 |\n| done | 如果这是最后一个分块则为 true |\n\n| 结果 | 解释 |\n|:----:|:----:|\n| term | 当前任期号（currentTerm），便于领导人更新自己 |\n\n**接收者实现**：\n\n1. 如果`term < currentTerm`就立即回复\n2. 如果是第一个分块（offset 为 0）就创建一个新的快照\n3. 在指定偏移量写入数据\n4. 如果 done 是 false，则继续等待更多的数据\n5. 保存快照文件，丢弃具有较小索引的任何现有或部分快照\n6. 如果现存的日志条目与快照中最后包含的日志条目具有相同的索引值和任期号，则保留其后的日志条目并进行回复\n7. 丢弃整个日志\n8. 使用快照重置状态机（并加载快照的集群配置）\n\n![图 13 ](/img/2023-06-25-raft-zh_cn/raft-图13.png)\n\n> 图 13：一个关于安装快照的简要概述。为了便于传输，快照都是被分成分块的；每个分块都给了跟随者生命的迹象，所以跟随者可以重置选举超时计时器。\n\n在这种情况下领导人使用一种叫做安装快照的新的 RPC 来发送快照给太落后的跟随者；见图 13。当跟随者通过这种  RPC 接收到快照时，他必须自己决定对于已经存在的日志该如何处理。通常快照会包含没有在接收者日志中存在的信息。在这种情况下，跟随者丢弃其整个日志；它全部被快照取代，并且可能包含与快照冲突的未提交条目。如果接收到的快照是自己日志的前面部分（由于网络重传或者错误），那么被快照包含的条目将会被全部删除，但是快照后面的条目仍然有效，必须保留。\n\n这种快照的方式背离了 Raft 的强领导人原则，因为跟随者可以在不知道领导人情况下创建快照。但是我们认为这种背离是值得的。领导人的存在，是为了解决在达成一致性的时候的冲突，但是在创建快照的时候，一致性已经达成，这时不存在冲突了，所以没有领导人也是可以的。数据依然是从领导人传给跟随者，只是跟随者可以重新组织他们的数据了。\n\n我们考虑过一种替代的基于领导人的快照方案，即只有领导人创建快照，然后发送给所有的跟随者。但是这样做有两个缺点。第一，发送快照会浪费网络带宽并且延缓了快照处理的时间。每个跟随者都已经拥有了所有产生快照需要的信息，而且很显然，自己从本地的状态中创建快照比通过网络接收别人发来的要经济。第二，领导人的实现会更加复杂。例如，领导人需要发送快照的同时并行的将新的日志条目发送给跟随者，这样才不会阻塞新的客户端请求。\n\n还有两个问题影响了快照的性能。首先，服务器必须决定什么时候应该创建快照。如果快照创建的过于频繁，那么就会浪费大量的磁盘带宽和其他资源；如果创建快照频率太低，他就要承受耗尽存储容量的风险，同时也增加了从日志重建的时间。一个简单的策略就是当日志大小达到一个固定大小的时候就创建一次快照。如果这个阈值设置的显著大于期望的快照的大小，那么快照对磁盘压力的影响就会很小了。\n\n第二个影响性能的问题就是写入快照需要花费显著的一段时间，并且我们还不希望影响到正常操作。解决方案是通过写时复制的技术，这样新的更新就可以被接收而不影响到快照。例如，具有函数式数据结构的状态机天然支持这样的功能。另外，操作系统的写时复制技术的支持（如 Linux 上的 fork）可以被用来创建完整的状态机的内存快照（我们的实现就是这样的）。\n\n## 8 客户端交互\n\n这一节将介绍客户端是如何和 Raft 进行交互的，包括客户端如何发现领导人和 Raft 是如何支持线性化语义的。这些问题对于所有基于一致性的系统都存在，并且 Raft 的解决方案和其他的也差不多。\n\nRaft 中的客户端发送所有请求给领导人。当客户端启动的时候，他会随机挑选一个服务器进行通信。如果客户端第一次挑选的服务器不是领导人，那么那个服务器会拒绝客户端的请求并且提供他最近接收到的领导人的信息（附加条目请求包含了领导人的网络地址）。如果领导人已经崩溃了，那么客户端的请求就会超时；客户端之后会再次重试随机挑选服务器的过程。\n\n我们 Raft 的目标是要实现线性化语义（每一次操作立即执行，只执行一次，在他调用和收到回复之间）。但是，如上述，Raft 是可能执行同一条命令多次的：例如，如果领导人在提交了这条日志之后，但是在响应客户端之前崩溃了，那么客户端会和新的领导人重试这条指令，导致这条命令就被再次执行了。解决方案就是客户端对于每一条指令都赋予一个唯一的序列号。然后，状态机跟踪每条指令最新的序列号和相应的响应。如果接收到一条指令，它的序列号已经被执行了，那么就立即返回结果，而不重新执行指令。\n\n只读的操作可以直接处理而不需要记录日志。但是，在不增加任何限制的情况下，这么做可能会冒着返回脏数据的风险，因为响应客户端请求的领导人可能在他不知道的时候已经被新的领导人取代了。线性化的读操作必须不能返回脏数据，Raft 需要使用两个额外的措施在不使用日志的情况下保证这一点。首先，领导人必须有关于被提交日志的最新信息。领导人完全特性保证了领导人一定拥有所有已经被提交的日志条目，但是在他任期开始的时候，他可能不知道哪些是已经被提交的。为了知道这些信息，他需要在他的任期里提交一条日志条目。Raft 中通过领导人在任期开始的时候提交一个空白的没有任何操作的日志条目到日志中去来实现。第二，领导人在处理只读的请求之前必须检查自己是否已经被废黜了（他自己的信息已经变脏了如果一个更新的领导人被选举出来）。Raft 中通过让领导人在响应只读请求之前，先和集群中的大多数节点交换一次心跳信息来处理这个问题。可选的，领导人可以依赖心跳机制来实现一种租约的机制，但是这种方法依赖时间来保证安全性（假设时间误差是有界的）。\n\n## 9 算法实现和评估\n\n我们已经为 RAMCloud 实现了 Raft 算法作为存储配置信息的复制状态机的一部分，并且帮助 RAMCloud 协调故障转移。这个 Raft 实现包含大约 2000 行 C++ 代码，其中不包括测试、注释和空行。这些代码是开源的。同时也有大约 25 个其他独立的第三方的基于这篇论文草稿的开源实现，针对不同的开发场景。同时，很多公司已经部署了基于 Raft 的系统。\n\n这一节会从三个方面来评估 Raft 算法：可理解性、正确性和性能。\n\n### 9.1 可理解性\n\n为了和 Paxos 比较 Raft 算法的可理解能力，我们针对高层次的本科生和研究生，在斯坦福大学的高级操作系统课程和加州大学伯克利分校的分布式计算课程上，进行了一次学习的实验。我们分别拍了针对 Raft 和 Paxos 的视频课程，并准备了相应的小测验。Raft 的视频讲课覆盖了这篇论文的所有内容除了日志压缩；Paxos 讲课包含了足够的资料来创建一个等价的复制状态机，包括单决策 Paxos，多决策 Paxos，重新配置和一些实际系统需要的性能优化（例如领导人选举）。小测验测试一些对算法的基本理解和解释一些边角的示例。每个学生都是看完第一个视频，回答相应的测试，再看第二个视频，回答相应的测试。大约有一半的学生先进行 Paxos 部分，然后另一半先进行 Raft 部分，这是为了说明两者从第一部分的算法学习中获得的表现和经验的差异。我们计算参加人员的每一个小测验的得分来看参与者是否在 Raft 算法上更加容易理解。\n\n我们尽可能的使得 Paxos 和 Raft 的比较更加公平。这个实验偏爱 Paxos 表现在两个方面：43 个参加者中有 15 个人在之前有一些  Paxos 的经验，并且 Paxos 的视频要长 14%。如表格 1 总结的那样，我们采取了一些措施来减轻这种潜在的偏见。我们所有的材料都可供审查。\n\n| 关心 | 缓和偏见采取的手段 | 可供查看的材料 |\n|:----:|:----:|:----:|\n| 相同的讲课质量 | 两者使用同一个讲师。Paxos 使用的是现在很多大学里经常使用的。Paxos 会长 14%。 | 视频 |\n| 相同的测验难度 | 问题以难度分组，在两个测验里成对出现。| 小测验 |\n| 公平评分 | 使用评价量规。随机顺序打分，两个测验交替进行。 | 评价量规（rubric） |\n\n> 表 1：考虑到可能会存在的偏见，对于每种情况的解决方法，和相应的材料。\n\n参加者平均在 Raft 的测验中比 Paxos 高 4.9 分（总分 60，那么 Raft 的平均得分是 25.7，而 Paxos 是 20.8）；图 14 展示了每个参与者的得分。配置t-检验（又称student‘s t-test）表明，在 95% 的可信度下，真实的 Raft 分数分布至少比 Paxos 高 2.5 分。\n\n![图 14](/img/2023-06-25-raft-zh_cn/raft-图14.png)\n\n> 图 14：一个散点图表示了 43 个学生在 Paxos 和 Raft 的小测验中的成绩。在对角线之上的点表示在 Raft 获得了更高分数的学生。\n\n我们也建立了一个线性回归模型来预测一个新的学生的测验成绩，基于以下三个因素：他们使用的是哪个小测验，之前对 Paxos 的经验，和学习算法的顺序。模型预测，对小测验的选择会产生 12.5 分的差别。这显著的高于之前的 4.9 分，因为很多学生在之前都已经有了对于 Paxos 的经验，这相当明显的帮助 Paxos，对 Raft 就没什么太大影响了。但是奇怪的是，模型预测对于先进行 Paxos 小测验的人而言，Raft的得分低了6.3分; 虽然我们不知道为什么，这似乎在统计上是有意义的。\n\n我们同时也在测验之后调查了参与者，他们认为哪个算法更加容易实现和解释；这个的结果在图 15 上。压倒性的结果表明 Raft 算法更加容易实现和解释（41 人中的 33个）。但是，这种自己报告的结果不如参与者的成绩更加可信，并且参与者可能因为我们的 Raft 更加易于理解的假说而产生偏见。\n\n![图 15](/img/2023-06-25-raft-zh_cn/raft-图15.png)\n\n> 图 15：通过一个 5 分制的问题，参与者（左边）被问哪个算法他们觉得在一个高效正确的系统里更容易实现，右边被问哪个更容易向学生解释。\n\n关于 Raft 用户学习有一个更加详细的讨论。\n\n### 9.2 正确性\n\n在第 5 节，我们已经制定了正式的规范，和对一致性机制的安全性证明。这个正式规范使用 TLA+ 规范语言使图 2 中总结的信息非常清晰。它长约400行，并作为证明的主题。同时对于任何想实现 Raft 的人也是十分有用的。我们通过 TLA 证明系统非常机械的证明了日志完全特性。然而，这个证明依赖的约束前提还没有被机械证明（例如，我们还没有证明规范的类型安全）。而且，我们已经写了一个非正式的证明关于状态机安全性是完备的，并且是相当清晰的（大约 3500 个词）。\n\n### 9.3 性能\n\nRaft 和其他一致性算法例如 Paxos 有着差不多的性能。在性能方面，最重要的关注点是，当领导人被选举成功时，什么时候复制新的日志条目。Raft 通过很少数量的消息包（一轮从领导人到集群大多数机器的消息）就达成了这个目的。同时，进一步提升 Raft 的性能也是可行的。例如，很容易通过支持批量操作和管道操作来提高吞吐量和降低延迟。对于其他一致性算法已经提出过很多性能优化方案；其中有很多也可以应用到 Raft 中来，但是我们暂时把这个问题放到未来的工作中去。\n\n我们使用我们自己的 Raft 实现来衡量 Raft 领导人选举的性能并且回答两个问题。首先，领导人选举的过程收敛是否快速？第二，在领导人宕机之后，最小的系统宕机时间是多久？\n\n![图 16](/img/2023-06-25-raft-zh_cn/raft-图16.png)\n\n> 图 16：发现并替换一个已经崩溃的领导人的时间。上面的图考察了在选举超时时间上的随机化程度，下面的图考察了最小选举超时时间。每条线代表了 1000 次实验（除了 150-150 毫秒只试了 100 次），和相应的确定的选举超时时间。例如，150-155 毫秒意思是，选举超时时间从这个区间范围内随机选择并确定下来。这个实验在一个拥有 5 个节点的集群上进行，其广播时延大约是 15 毫秒。对于 9 个节点的集群，结果也差不多。\n\n为了衡量领导人选举，我们反复的使一个拥有五个节点的服务器集群的领导人宕机，并计算需要多久才能发现领导人已经宕机并选出一个新的领导人（见图 16）。为了构建一个最坏的场景，在每一的尝试里，服务器都有不同长度的日志，意味着有些候选人是没有成为领导人的资格的。另外，为了促成选票瓜分的情况，我们的测试脚本在终止领导人之前同步的发送了一次心跳广播（这大约和领导人在崩溃前复制一个新的日志给其他机器很像）。领导人均匀的随机的在心跳间隔里宕机，也就是最小选举超时时间的一半。因此，最小宕机时间大约就是最小选举超时时间的一半。\n\n图 16 中上面的图表明，只需要在选举超时时间上使用很少的随机化就可以大大避免选票被瓜分的情况。在没有随机化的情况下，在我们的测试里，选举过程往往都需要花费超过 10 秒钟由于太多的选票瓜分的情况。仅仅增加 5 毫秒的随机化时间，就大大的改善了选举过程，现在平均的宕机时间只有 287 毫秒。增加更多的随机化时间可以大大改善最坏情况：通过增加 50 毫秒的随机化时间，最坏的完成情况（1000 次尝试）只要 513 毫秒。\n\n图 16 中下面的图显示，通过减少选举超时时间可以减少系统的宕机时间。在选举超时时间为 12-24 毫秒的情况下，只需要平均 35 毫秒就可以选举出新的领导人（最长的一次花费了 152 毫秒）。然而，进一步降低选举超时时间的话就会违反 Raft 的时间不等式需求：在选举新领导人之前，领导人就很难发送完心跳包。这会导致没有意义的领导人改变并降低了系统整体的可用性。我们建议使用更为保守的选举超时时间，比如 150-300 毫秒；这样的时间不大可能导致没有意义的领导人改变，而且依然提供不错的可用性。\n\n## 10 相关工作\n\n已经有很多关于一致性算法的工作被发表出来，其中很多都可以归到下面的类别中：\n\n* Lamport 关于 Paxos 的原始描述，和尝试描述的更清晰。\n* 关于 Paxos 的更详尽的描述，补充遗漏的细节并修改算法，使得可以提供更加容易的实现基础。\n* 实现一致性算法的系统，例如 Chubby，ZooKeeper 和 Spanner。对于 Chubby 和 Spanner 的算法并没有公开发表其技术细节，尽管他们都声称是基于 Paxos 的。ZooKeeper 的算法细节已经发表，但是和 Paxos 着实有着很大的差别。\n* Paxos 可以应用的性能优化。\n* Oki 和 Liskov 的 Viewstamped Replication（VR），一种和 Paxos 差不多的替代算法。原始的算法描述和分布式传输协议耦合在了一起，但是核心的一致性算法在最近的更新里被分离了出来。VR 使用了一种基于领导人的方法，和 Raft 有很多相似之处。\n\nRaft 和 Paxos 最大的不同之处就在于 Raft 的强领导特性：Raft 使用领导人选举作为一致性协议里必不可少的部分，并且将尽可能多的功能集中到了领导人身上。这样就可以使得算法更加容易理解。例如，在 Paxos 中，领导人选举和基本的一致性协议是正交的：领导人选举仅仅是性能优化的手段，而且不是一致性所必须要求的。但是，这样就增加了多余的机制：Paxos 同时包含了针对基本一致性要求的两阶段提交协议和针对领导人选举的独立的机制。相比较而言，Raft 就直接将领导人选举纳入到一致性算法中，并作为两阶段一致性的第一步。这样就减少了很多机制。\n\n像 Raft 一样，VR 和 ZooKeeper 也是基于领导人的，因此他们也拥有一些 Raft 的优点。但是，Raft 比 VR 和 ZooKeeper 拥有更少的机制因为 Raft 尽可能的减少了非领导人的功能。例如，Raft 中日志条目都遵循着从领导人发送给其他人这一个方向：附加条目 RPC 是向外发送的。在 VR 中，日志条目的流动是双向的（领导人可以在选举过程中接收日志）；这就导致了额外的机制和复杂性。根据 ZooKeeper 公开的资料看，它的日志条目也是双向传输的，但是它的实现更像 Raft。\n\n和上述我们提及的其他基于一致性的日志复制算法中，Raft 的消息类型更少。例如，我们数了一下 VR 和 ZooKeeper 使用的用来基本一致性需要和成员改变的消息数（排除了日志压缩和客户端交互，因为这些都比较独立且和算法关系不大）。VR 和 ZooKeeper 都分别定义了 10 种不同的消息类型，相对的，Raft 只有 4 种消息类型（两种 RPC 请求和对应的响应）。Raft 的消息都稍微比其他算法的要信息量大，但是都很简单。另外，VR 和 ZooKeeper 都在领导人改变时传输了整个日志；所以为了能够实践中使用，额外的消息类型就很必要了。\n\nRaft 的强领导人模型简化了整个算法，但是同时也排斥了一些性能优化的方法。例如，平等主义 Paxos （EPaxos）在某些没有领导人的情况下可以达到很高的性能。平等主义 Paxos 充分发挥了在状态机指令中的交换性。任何服务器都可以在一轮通信下就提交指令，除非其他指令同时被提出了。然而，如果指令都是并发的被提出，并且互相之间不通信沟通，那么 EPaxos 就需要额外的一轮通信。因为任何服务器都可以提交指令，所以 EPaxos 在服务器之间的负载均衡做的很好，并且很容易在 WAN 网络环境下获得很低的延迟。但是，他在 Paxos 上增加了非常明显的复杂性。\n\n一些集群成员变换的方法已经被提出或者在其他的工作中被实现，包括 Lamport 的原始的讨论，VR 和 SMART。我们选择使用共同一致的方法因为他对一致性协议的其他部分影响很小，这样我们只需要很少的一些机制就可以实现成员变换。Lamport 的基于 α 的方法之所以没有被 Raft 选择是因为它假设在没有领导人的情况下也可以达到一致性。和 VR 和 SMART 相比较，Raft 的重新配置算法可以在不限制正常请求处理的情况下进行；相比较的，VR 需要停止所有的处理过程，SMART 引入了一个和 α 类似的方法，限制了请求处理的数量。Raft 的方法同时也需要更少的额外机制来实现，和 VR、SMART 比较而言。\n\n## 11 结论\n\n算法的设计通常会把正确性，效率或者简洁作为主要的目标。尽管这些都是很有意义的目标，但是我们相信，可理解性也是一样的重要。在开发者把算法应用到实际的系统中之前，这些目标没有一个会被实现，这些都会必然的偏离发表时的形式。除非开发人员对这个算法有着很深的理解并且有着直观的感觉，否则将会对他们而言很难在实现的时候保持原有期望的特性。\n\n在这篇论文中，我们尝试解决分布式一致性问题，但是一个广为接受但是十分令人费解的算法 Paxos 已经困扰了无数学生和开发者很多年了。我们创造了一种新的算法 Raft，显而易见的比 Paxos 要容易理解。我们同时也相信，Raft 也可以为实际的实现提供坚实的基础。把可理解性作为设计的目标改变了我们设计 Raft 的方式；随着设计的进展，我们发现自己重复使用了一些技术，比如分解问题和简化状态空间。这些技术不仅提升了 Raft 的可理解性，同时也使我们坚信其正确性。\n\n## 12 感谢\n\n这项研究必须感谢以下人员的支持：Ali Ghodsi，David Mazie\\`res，和伯克利 CS 294-91 课程、斯坦福 CS 240 课程的学生。Scott Klemmer 帮我们设计了用户调查，Nelson Ray 建议我们进行统计学的分析。在用户调查时使用的关于 Paxos 的幻灯片很大一部分是从 Lorenzo Alvisi 的幻灯片上借鉴过来的。特别的，非常感谢 DavidMazieres 和 Ezra Hoch，他们找到了 Raft 中一些难以发现的漏洞。许多人提供了关于这篇论文十分有用的反馈和用户调查材料，包括 Ed Bugnion，Michael Chan，Hugues Evrard，Daniel Giffin，Arjun Gopalan，Jon Howell，Vimalkumar Jeyakumar，Ankita Kejriwal，Aleksandar Kracun，Amit Levy，Joel Martin，Satoshi Matsushita，Oleg Pesok，David Ramos，Robbert van Renesse，Mendel Rosenblum，Nicolas Schiper，Deian Stefan，Andrew Stone，Ryan Stutsman，David Terei，Stephen Yang，Matei Zaharia 以及 24 位匿名的会议审查人员（可能有重复），并且特别感谢我们的领导人 Eddie Kohler。Werner Vogels 发了一条早期草稿链接的推特，给 Raft 带来了极大的关注。我们的工作由 Gigascale 系统研究中心和 Multiscale 系统研究中心给予支持，这两个研究中心由关注中心研究程序资金支持，一个是半导体研究公司的程序，由 STARnet 支持，一个半导体研究公司的程序由 MARCO 和 DARPA 支持，在国家科学基金会的 0963859 号批准，并且获得了来自 Facebook，Google，Mellanox，NEC，NetApp，SAP 和 Samsung 的支持。Diego Ongaro 由 Junglee 公司，斯坦福的毕业团体支持。\n\n## 参考\n\n略\n\n## github 项目\n\nRaft一致性算法论文的中文翻译\n\n<a href=\"https://ramcloud.atlassian.net/wiki/download/attachments/6586375/raft.pdf\">英文论文地址</a>\n\n<a href=\"https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md\">中文翻译地址</a>\n","tags":["Git","论文学习"]},{"title":"Jmeter Address already in use connect 解决方案","url":"/2023/05/08/2023-05-08-jmeter-wen-ti-yi/","content":"\n## 发生缘故\n\nwin10 下，jmeter 高并发压测 scope\n\n## 报错信息\n\n![error_information2](/img/2023-05-08-Jmeter问题（一）/pho2.png)\n\n## 原因\n\nJmeter 里的 http sample 勾选了 keep alive，导致会话一直保持，而 windows 本身的端口有限，导致端口被占用完后，无法分配新的端口，因此会产生 java.net.BindException: Address already in use: connect 报错。\n\n## 解决方案\n\nHTTP SAMPLE 不勾选 keep alive\n\n![solve_plan](/img/2023-05-08-Jmeter问题（一）/pho3.png)\n","tags":["Jmeter"]},{"title":"Git add 问题","url":"/2023/05/08/2023-05-08-git-add-wen-ti/","content":"\n## 问题一：中文路径下，git status 只显示数字串\n\n### 问题现象\n\n![中文路径乱码](/img/2023-05-08-git_add问题/git_add1.png)\n\n### 原因 \n\n在默认设置下，中文文件名在工作区状态输出，中文名不能正确显示，而是显示为八进制的字符编码。\n\n### 解决方案\n\n<ul>\n  <li>在 git bash 的界面中右击空白处，弹出菜单，选择 Options->Text->Locale 改为 zh_CN，Character set 改为 UTF-8</li>\n  <li>git bash 终端输入命令：git config --global core.quotepath false</li>\n</ul>\n\n![解决方案](/img/2023-05-08-git_add问题/git_add2.gif)\n\n![预期结果](/img/2023-05-08-git_add问题/git_add3.png)\n\n## 问题二： 文件名带空格无法 add\n\n### 问题现象\n\n![add失败](/img/2023-05-08-git_add问题/git_add4.png)\n\n### 解决方案\n\n文件名两端加上双引号即可, 比如 ​​git add \"demo copy\"​​\n\n","tags":["Git"]},{"title":"ES6.7 一些有趣的语句","url":"/2023/04/17/2023-04-17-es-you-qu-de-yu-ju/","content":"\n## 1、判断 date 类型是不是 null 值，不是 null 值的加 1 天/月年\n\n```json\ncurl -XGET \"vqa132:19200/script_common/_search?&size=0&pretty\" -H 'Content-Type: application/json' -d'\n{\n  \"aggs\": {\n    \"agg_name\": {\n      \"date_histogram\": {\n        \"script\": {\n          \"lang\": \"painless\",\n          \"source\": \"if (doc[\\u0027class\\u0027].size()==0){return params.date}else {return doc[\\u0027birthday\\u0027].value.plusDays(1)}\",\n          \"params\": {\n            \"date\" : 2208960000000\n          }\n        },\n        \"interval\": \"year\",\n        \"min_doc_count\": 1\n      }\n    }\n  }\n}\n';\n```","tags":["Elasticsearch","那些年遇到的坑"],"categories":["Elasticsearch"]},{"title":"Compressor detection","url":"/2023/04/14/2023-04-14-es-wen-ti-yi/","content":"\n报错信息：\nCompressor detection can only be called on some xcontent bytes or compressed xcontent bytes\n\n## 发生缘故\n\njmeter 压测，写入 elasticsearch 报错\n\n## 运行环境\n\n<ul>\n    <li>elasticsearch 6.7.2</li>\n    <li>jmeter 5.5</li>\n    <li>jdbc 1.8</li>\n</ul>\n\n## 报错信息\n\n![error_information](/img/2023-04-14-ES问题（一）/error_information.png)\n\n## 分析排查\n\n<ul>\n    <li>Compressor detection can only be called on some xcontent bytes or compressed xcontent bytes</li>\n    <li>压缩器检测只能在某些 xcontent 字节或压缩的 xcontent 字节上面调用</li>\n</ul>\n\n根据报错原因可以将错误定位至 io.xwt.BulkDoument.runTest(BulkDoument.java 87)，代码如下：\n\n```json\n// 解析 json\nfor(int i = 0; i < datas.length; ++i) {\n    datas[i] = datas[i].replace(\"{DATET}\", datasdf.format(System.currentTimeMillis()));\n    if (this.threadNum != 0) {\n        String id = \"t\" + this.threadNum + \"_\" + System.currentTimeMillis() + \"_\" + UUID.randomUUID();\n        br.add((new IndexRequest(this.indexName, default_type, id)).source(datas[i], XContentType.JSON));\n    } else {\nbr.add((new IndexRequest()).source(datas[i], XContentType.JSON));\n    }\n}\ntry {\n// 生成 bulk 连接\n    sampleResult.sampleStart();\n    BulkResponse bulkResponse = this.client.bulk(br, RequestOptions.DEFAULT);\n    sampleResult.sampleEnd();\n    sampleResult.setSuccessful(true);\n    sampleResult.setResponseCodeOK();\n    if (bulkResponse.hasFailures()) {\n        sampleResult.setSuccessful(false);\n        sampleResult.setResponseCode(\"500\");\n        sampleResult.setResponseData(bulkResponse.buildFailureMessage(), \"utf-8\");\n    } else {\n        sampleResult.setResponseData(\"all in\", \"utf-8\");\n    }\n// 报错\n} catch (Exception var8) {\n    sampleResult.sampleEnd();\n    sampleResult.setSuccessful(false);\n    sampleResult.setResponseCode(\"500\");\n    sampleResult.setResponseMessage(var8.getMessage());\n    var8.printStackTrace();\n}\n```\n\n那么就可以将报错信息转为人话了：语句的类型不是JSON风格的或者JSON格式化错误了。\n\n定位写入数据，数据如下：\n![eventdate](/img/2023-04-14-ES问题（一）/eventdate.png)\n\n@timestamp 为 date类型，这里用了 string，修改这个值/jmx上替换。\n\n注：\n<ul>\n    <li>有时网络差，也可能会出现这个报错</li>\n</ul>","tags":["Elasticsearch","Jmeter","那些年遇到的坑"]},{"title":"jmeter 常用函数","url":"/2023/04/05/2023-04-05-jmeter-chang-yong-han-shu/","content":"\n## 获取使用时间戳\n\n```bash\n默认时间戳：\n${__time(,)}：精确到毫秒级别，13位\n${__time(/1000,)}：精确到秒级别，10位\n\n设置时间格式：\n${__time(yyyy-MM-dd,)}\n${__time(YMDHMS,)}\n```\n\n## 获取线程相关\n\n```bash\n${__BeanShell(ctx.getThread().getThreadName())}：获取线程名称\n${__BeanShell(ctx.getThread().getThreadNum())}：获取线程号\n```\n\n## 获取属性值\n\n```bash\n${__P(access_token,)}：从属性中取出变量值\n```\n\n## 多节点 htpp 请求\n\n```bash\n${__RandomFromMultipleVars(adapterHost-single|adapterHost-single2|adapterHost-single3,schost)}\n```","tags":["Jmeter"]},{"title":"为什么我们需要 Pod","url":"/2023/02/24/2023-02-24-wei-shi-me-wo-men-xu-yao-pod/","content":"\n## 前言\n\nPod，是 K8s 项目中最小的 API 对象，换句更专业的话，Pod，是 K8s 项目的原子调度单位。\n\n为了更好的理解，我们为什么需要 pod，这里抛出一个场景：\n\n已知 rsyslogd 由三个进程组成：一个 imklog 模块，一个 imuxsock 模块，一个 rsyslogd 自己的 main 函数主进程。**这三个进程一定要运行在同一台机器上，否则，它们之间基于 Socket 的通信和文件交换，都会出现问题。**\n\n>注意：容器的“单进程模型”，并不是指容器里只能运行“一个”进程，而是指容器没有管理多个进程的能力。这是因为容器里 PID=1 的进程就是应用本身，其他的进程都是这个 PID=1 进程的子进程。可是，用户编写的应用，并不能够像正常操作系统里的 init 进程或者 systemd 那样拥有进程管理的功能。比如，你的应用是一个 Java Web 程序（PID=1），然后你执行 docker exec 在后台启动了一个 Nginx 进程（PID=3）。可是，当这个 Nginx 进程异常退出的时候，你该怎么知道呢？这个进程退出后的垃圾收集工作，又应该由谁去做呢？\n\n假设我们的 K8s 集群上有两个节点：node-1 上有 3 GB 可用内存，node-2 有 2.5 GB 可用内存。\n\n这时，假设我要用 Docker Swarm 来运行这个 rsyslogd 程序。为了能够让这三个容器都运行在同一台机器上，我就必须在另外两个容器上设置一个 affinity=main（与 main 容器有亲密性）的约束，即：它们俩必须和 main 容器运行在同一台机器上。\n\n然后，我顺序执行：\"docker run main\"、\"docker run imklog\" 和 \"docker run imuxsock\"，创建这三个容器。\n\n这样，这三个容器都会进入 Swarm 的待调度队列。然后，main 容器和 imklog 容器都先后出队并被调度到了 node-2 上（这个情况是完全有可能的）。\n\n可是，当 imuxsock 容器出队开始被调度时，Swarm 就有点懵了：node-2 上的可用资源只有 0.5 GB 了，并不足以运行 imuxsock 容器；可是，根据 affinity=main 的约束，imuxsock 容器又只能运行在 node-2 上。\n\n**这就是一个典型的成组调度（gang scheduling）没有被妥善处理的例子。**\n\n## Pod 的作用\n\n对于上边的场景，在工业界和学术界讨论可谓旷日持久，也产生了很多可供选择的解决方案。\n\n比如，Mesos 中就有一个资源囤积（resource hoarding）的机制，会在所有设置了 Affinity 约束的任务都达到时，才开始对它们统一进行调度。而在 Google Omega 论文中，则提出了使用乐观调度处理冲突的方法，即：先不管这些冲突，而是通过精心设计的回滚机制在出现了冲突之后解决问题。\n\n可是这些方法都谈不上完美。资源囤积带来了不可避免的调度效率损失和死锁的可能性；而乐观调度的复杂程度，则不是常规技术团队所能驾驭的。\n\n但是，到了 K8s 项目里，这样的问题就迎刃而解了：Pod 是 K8s 里的原子调度单位。这就意味着，K8s 项目的调度器，是统一按照 Pod 而非容器的资源需求进行计算的。\n\n所以，像 imklog、imuxsock 和 main 函数主进程这样的三个容器，正是一个典型的由三个容器组成的 Pod。K8s 项目在调度时，自然就会去选择可用内存等于 3 GB 的 node-1 节点进行绑定，而根本不会考虑 node-2。\n\n像这样容器间的紧密协作，我们可以称为“超亲密关系”。这些具有“超亲密关系”容器的典型特征包括但不限于：互相之间会发生直接的文件交换、使用 localhost 或者 Socket 文件进行本地通信、会发生非常频繁的远程调用、需要共享某些 Linux Namespace（比如，一个容器要加入另一个容器的 Network Namespace）等等。\n\n这也就意味着，并不是所有有“关系”的容器都属于同一个 Pod。比如，PHP 应用容器和 MySQL 虽然会发生访问关系，但并没有必要、也不应该部署在同一台机器上，它们更适合做成两个 Pod。\n\n## Pod 容器设计模式\n\n对于初学者来说，一般都是先学会了用 Docker 这种单容器的工具，才会开始接触 Pod。\n\n而如果 Pod 的设计只是出于调度上的考虑，那么 K8s 项目似乎完全没有必要非得把 Pod 作为“一等公民”吧？这不是故意增加用户的学习门槛吗？\n\n没错，如果只是处理“超亲密关系”这样的调度问题，有 Borg 和 Omega 论文珠玉在前，K8s 项目肯定可以在调度器层面给它解决掉。\n\n不过，Pod 在 K8s 项目里还有更重要的意义，那就是：**容器设计模式**。\n\n### Pod 实现原理\n\n**首先，关于 Pod 最重要的一个事实是：它只是一个逻辑概念。**\n\n也就是说，K8s 真正处理的，还是宿主机操作系统上 Linux 容器的 Namespace 和 Cgroups，而并不存在一个所谓的 Pod 的边界或者隔离环境。\n\n那么，Pod 又是怎么被“创建”出来的呢？\n\n答案是：Pod，其实是一组共享了某些资源的容器。\n\n具体的说：**Pod 里的所有容器，共享的是同一个 Network Namespace，并且可以声明共享同一个 Volume（磁盘目录）**。\n\n那这么来看的话，一个有 A、B 两个容器的 Pod，不就是等同于一个容器（容器 A）共享另外一个容器（容器 B）的网络和 Volume 的玩儿法么？\n\n这好像通过 docker run --net --volumes-from 这样的命令就能实现嘛，比如：\n\n```bash\n$ docker run --net=B --volumes-from=B --name=A image-A ...\n```\n\n但是，这样做存在一个问题，那就是容器 B 就必须比容器 A 先启动，这样一个 Pod 里的多个容器就不是对等关系，而是拓扑关系了。\n\n所以，在 Kubernetes 项目里，Pod 的实现需要使用一个中间容器，这个容器叫作 Infra 容器。在这个 Pod 中，Infra 容器永远都是第一个被创建的容器，而其他用户定义的容器，则通过 Join Network Namespace 的方式，与 Infra 容器关联在一起。这样的组织关系，可以用下面这样一个示意图来表达：\n\n![Pod结构图](/img/2023-02-24-为什么我们需要Pod/pod框架.png)\n\n如上图所示，这个 Pod 里有两个用户容器 A 和 B，还有一个 Infra 容器。很容易理解，在 Kubernetes 项目里，Infra 容器一定要占用极少的资源，所以它使用的是一个非常特殊的镜像，叫作：k8s.gcr.io/pause。这个镜像是一个用汇编语言编写的、永远处于“暂停”状态的容器，解压后的大小也只有 100~200 KB 左右。\n\n而在 Infra 容器 “Hold 住” Network Namespace 后，用户容器就可以加入到 Infra 容器的 Network Namespace 当中了。所以，如果你查看这些容器在宿主机上的 Namespace 文件（这个 Namespace 文件的路径，我已经在前面的内容中介绍过），它们指向的值一定是完全一样的。\n\n这也就意味着，对于 Pod 里的容器 A 和容器 B 来说：\n\n它们可以直接使用 localhost 进行通信；\n\n它们看到的网络设备跟 Infra 容器看到的完全一样；\n\n一个 Pod 只有一个 IP 地址，也就是这个 Pod 的 Network Namespace 对应的 IP 地址；当然，其他的所有网络资源，都是一个 Pod 一份，并且被该 Pod 中的所有容器共享；Pod 的生命周期只跟 Infra 容器一致，而与容器 A 和 B 无关。\n\n而对于同一个 Pod 里面的所有用户容器来说，它们的进出流量，也可以认为都是通过 Infra 容器完成的。这一点很重要，因为**将来如果你要为 Kubernetes 开发一个网络插件时，应该重点考虑的是如何配置这个 Pod 的 Network Namespace，而不是每一个用户容器如何使用你的网络配置，这是没有意义的**。\n\n这就意味着，如果你的网络插件需要在容器里安装某些包或者配置才能完成的话，是不可取的：Infra 容器镜像的 rootfs 里几乎什么都没有，没有你随意发挥的空间。当然，这同时也意味着你的网络插件完全不必关心用户容器的启动与否，而只需要关注如何配置 Pod，也就是 Infra 容器的 Network Namespace 即可。\n\n有了这个设计之后，共享 Volume 就简单多了：Kubernetes 项目只要把所有 Volume 的定义都设计在 Pod 层级即可。\n\n这样，一个 Volume 对应的宿主机目录对于 Pod 来说就只有一个，Pod 里的容器只要声明挂载这个 Volume，就一定可以共享这个 Volume 对应的宿主机目录。比如下面这个例子：\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: two-containers\nspec:\n  restartPolicy: Never\n  volumes:\n  - name: shared-data\n    hostPath: \n      path: /data\n  containers:\n  - name: nginx-container\n    image: nginx\n    volumeMounts:\n    - name: shared-data\n      mountPath: /usr/share/nginx/html\n  - name: debian-container\n    image: debian\n    volumeMounts:\n    - name: shared-data\n      mountPath: /pod-data\n    command: [\"/bin/sh\"]\n    args: [\"-c\", \"echo Hello from the debian container > /pod-data/index.html\"]\n```\n\n在这个例子中，debian-container 和 nginx-container 都声明挂载了 shared-data 这个 Volume。而 shared-data 是 hostPath 类型。所以，它对应在宿主机上的目录就是：/data。而这个目录，其实就被同时绑定挂载进了上述两个容器当中。\n\n这就是为什么，nginx-container 可以从它的 /usr/share/nginx/html 目录中，读取到 debian-container 生成的 index.html 文件的原因。\n\n### Pod 设计模式\n\nPod 这种“超亲密关系”容器的设计思想，实际上就是希望，当用户想在一个容器里跑多个功能并不相关的应用时，应该优先考虑它们是不是更应该被描述成一个 Pod 里的多个容器。\n\n为了能够掌握这种思考方式，你就应该尽量尝试使用它来描述一些用单个容器难以解决的问题。\n\n**一个最典型的例子是：WAR 包与 Web 服务器。**\n\n我们现在有一个 Java Web 应用的 WAR 包，它需要被放在 Tomcat 的 webapps 目录下运行起来。\n\n假如，你现在只能用 Docker 来做这件事情，那该如何处理这个组合关系呢？\n\n<ul>\n    <li>\n        一种方法是，把 WAR 包直接放在 Tomcat 镜像的 webapps 目录下，做成一个新的镜像运行起来。可是，这时候，如果你要更新 WAR 包的内容，或者要升级 Tomcat 镜像，就要重新制作一个新的发布镜像，非常麻烦。\n    </li>\n    <li>\n        另一种方法是，你压根儿不管 WAR 包，永远只发布一个 Tomcat 容器。不过，这个容器的 webapps 目录，就必须声明一个 hostPath 类型的 Volume，从而把宿主机上的WAR 包挂载进 Tomcat 容器当中运行起来。不过，这样你就必须要解决一个问题，即：如何让每一台宿主机，都预先准备好这个存储有 WAR 包的目录呢？这样来看，你只能独立维护一套分布式存储系统了。\n    </li>\n</ul>\n\n实际上，有了 Pod 之后，这样的问题就很容易解决了。我们可以把 WAR 包和 Tomcat 分别做成镜像，然后把它们作为一个 Pod 里的两个容器“组合”在一起。这个 Pod 的配置文件如下所示：\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: javaweb-2\nspec:\n  initContainers:\n  - image: geektime/sample:v2\n    name: war\n    command: [\"cp\", \"/sample.war\", \"/app\"]\n    volumeMounts:\n    - mountPath: /app\n        name: app-volume\n  containers:\n  - image: geektime/tomcat:7.0\n    name: tomcat\n    command: [\"sh\",\"-c\",\"/root/apache-tomcat-7.0.42-v2/bin/start.sh\"]\n    volumeMounts:\n    - mountPath: /root/apache-tomcat-7.0.42-v2/webapps\n      name: app-volume\n    ports:\n    - containerPort: 8080\n      hostPort: 8001 \n  volumes:\n  - name: app-volume\n    emptyDir: {}\n```\n\n在这个 Pod 中，我们定义了两个容器，第一个容器使用的镜像是 geektime/sample:v2，这个镜像里只有一个 WAR 包（sample.war）放在根目录下。而第二个容器则使用的是一个标准的 Tomcat 镜像。\n\n不过，你可能已经注意到，WAR 包容器的类型不再是一个普通容器，而是一个 Init Container 类型的容器。\n\n在 Pod 中，所有 Init Container 定义的容器，都会比 spec.containers 定义的用户容器先启动。并且，Init Container 容器会按顺序逐一启动，而直到它们都启动并且退出了，用户容器才会启动。\n\n所以，这个 Init Container 类型的 WAR 包容器启动后，我执行了一句\"cp /sample.war/app\"，把应用的 WAR 包拷贝到 /app 目录下，然后退出。\n\n而后这个 /app 目录，就挂载了一个名叫 app-volume 的 Volume。\n\n接下来就很关键了。Tomcat 容器，同样声明了挂载 app-volume 到自己的 webapps 目录下。\n\n所以，等 Tomcat 容器启动时，它的 webapps 目录下就一定会存在 sample.war 文件：这个文件正是 WAR 包容器启动时拷贝到这个 Volume 里面的，而这个 Volume 是被这两个容器共享的。\n\n像这样，我们就用一种“组合”方式，解决了 WAR 包与 Tomcat 容器之间耦合关系的问题。\n\n实际上，这个所谓的“组合”操作，正是容器设计模式里最常用的一种模式，它的名字叫：sidecar。\n\n顾名思义，sidecar 指的就是我们可以在一个 Pod 中，启动一个辅助容器，来完成一些独立于主进程（主容器）之外的工作。\n\n比如，在我们的这个应用 Pod 中，Tomcat 容器是我们要使用的主容器，而 WAR 包容器的存在，只是为了给它提供一个 WAR 包而已。所以，我们用 Init Container 的方式优先运行 WAR 包容器，扮演了一个 sidecar 的角色。","tags":["K8s","极客时间"]},{"title":"DSL备忘（一）：Constant score query 和 Bool Query","url":"/2023/02/23/2023-02-23-dsl-bei-wang-yi-constant-score-query-he-bool-query/","content":"\n## Constant score query\n\n常量分值查询，目的就是返回指定的 score（默认1），一般都结合 filter 使用，因为 filter context 忽略 score。\n\n### 基本语法\n\n多用于结合bool查询实现自定义得分，其基本语法如下:\n\n```json\nPOST /index_name/_search\n```\n\n```json\n{\n  \"query\": {\n    \"constant_score\": {\n      \"filter\": {\n        \"match\": {\n          \"field_name\": \"query_clause\"\n        }\n      },\n      \"boost\": score\n    }\n  }\n}\n```\n\n<ul>\n    <li>const_score：关键字</li>\n    <li>filter：只能有一个</li>\n    <li>field_name：字段名</li>\n    <li>query_clause：待查询的语句</li>\n    <li>boost：自定义得分</li>\n</ul>\n\n### 实例\n\n```json\nGET /customer/_search\n{\n  \"query\": {\n    \"constant_score\": {\n      \"filter\": {\n        \"range\": {\n          \"age\": {\n            \"gt\": 25\n          }\n        }\n      },\n      \"boost\": 8.8\n    }\n  }\n}\n\nresult:返回结果中score都是被指定的8.8\n{\n  \"took\" : 8,\n  \"timed_out\" : false,\n  \"_shards\" : {\n    \"total\" : 1,\n    \"successful\" : 1,\n    \"skipped\" : 0,\n    \"failed\" : 0\n  },\n   \"hits\": {\n    \"total\": 4,\n    \"max_score\": 8.8,\n    \"hits\": [\n      {\n        \"_index\": \"constant_index\",\n        \"_type\": \"default_type_\",\n        \"_id\": \"1\",\n        \"_score\": 8.8,\n        \"_source\": {\n          \"name\": \"Emma Edgar\"\n        }\n      },\n      {\n        \"_index\": \"constant_index\",\n        \"_type\": \"default_type_\",\n        \"_id\": \"2\",\n        \"_score\": 8.8,\n        \"_source\": {\n          \"name\": \"Underwood Verda\"\n        }\n      },\n      {\n        \"_index\": \"constant_index\",\n        \"_type\": \"default_type_\",\n        \"_id\": \"4\",\n        \"_score\": 8.8,\n        \"_source\": {\n          \"name\": \"Rivera Interpreter\"\n        }\n      },\n      {\n        \"_index\": \"constant_index\",\n        \"_type\": \"default_type_\",\n        \"_id\": \"6\",\n        \"_score\": 8.8,\n        \"_source\": {\n          \"name\": \"Lucy Seaman\"\n        }\n      }\n    ]\n  }\n}\n```\n\n## bool query \n\n布尔查询，由一个或者多个子句组成，每个子句都有特定的类型。\n<ul>\n    <li>\n        must：返回的文档必须满足 must 子句的条件，并且参与计算分值\n    </li>\n    <li>\n        filter：返回的文档必须满足 filter 子句的条件。但不会像 must 一样参与计算分值\n    </li>\n    <li>\n        should：返回的文档可能满足 should 子句的条件。布尔查询在 query context 中，如果某条文档未匹配 should 的条件，但是匹配 must 或 filter 的条件，则文档仍会被返回，此时 should 只影响分数；如果不存在 must 和 filter，则必须匹配 should。这种行为由 minimum_should_match 参与决定。\n    </li>\n    <li>\n        must_not：返回的文档必须不满足 must_not 定义的条件。\n    </li>\n</ul>\n\n### 官网例子\n\n第一步：查询 name 为 \"李云龙\" 的文档\n\n```json\nGET /customer/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"term\":{\"name.keyword\":\"李云龙\"}\n      }\n    }\n  }\n}\n返回三个文档：\n{\n  \"hits\" : {\n    \"total\" : 3,\n    \"max_score\" : 1.4916549,\n    \"hits\" : [\n      {\n        \"_index\" : \"customer\",\n        \"_type\" : \"doc\",\n        \"_id\" : \"4\",\n        \"_score\" : 1.4916549,\n        \"_source\" : {\n          \"name\" : \"李云龙\",\n          \"id\" : \"510221197001013611\",\n          \"addr\" : \"昆明市滇池路阳光时代1栋1单元\",\n          \"tel\" : \"13808712808\"\n        }\n      },\n      {\n        \"_index\" : \"customer\",\n        \"_type\" : \"doc\",\n        \"_id\" : \"224\",\n        \"_score\" : 1.4916549,\n        \"_source\" : {\n          \"name\" : \"李云龙\",\n          \"id\" : \"224\",\n          \"addr\" : \"天津市阳光路2008号\",\n          \"tel\" : \"13908712808\"\n        }\n      },\n      {\n        \"_index\" : \"customer\",\n        \"_type\" : \"doc\",\n        \"_id\" : \"510221197001013611\",\n        \"_score\" : 1.4916549,\n        \"_source\" : {\n          \"name\" : \"李云龙\",\n          \"id\" : \"510221197001013611\",\n          \"addr\" : \"上海市浦东区华北路8号\",\n          \"tel\" : \"13908712808\"\n        }\n      }\n    ]\n  }\n}\n```\n\n第二步：加入过滤条件，只保留 id 为 510221197001013611 的文档\n\n```json\nGET /customer/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"term\":{\n          \"name.keyword\":\"李云龙\"\n        }\n      },\n      \"filter\": {\n        \"term\": {\n          \"id\": \"510221197001013611\"\n        }\n      }\n    }\n  }\n}\n\n返回结果减少到 2 个文档，并且 score 相同：\n{\n  \"hits\" : {\n    \"total\" : 2,\n    \"max_score\" : 1.4916549,\n    \"hits\" : [\n      {\n        \"_index\" : \"customer\",\n        \"_type\" : \"doc\",\n        \"_id\" : \"4\",\n        \"_score\" : 1.4916549,\n        \"_source\" : {\n          \"name\" : \"李云龙\",\n          \"id\" : \"510221197001013611\",\n          \"addr\" : \"昆明市滇池路阳光时代1栋1单元\",\n          \"tel\" : \"13808712808\"\n        }\n      },\n      {\n        \"_index\" : \"customer\",\n        \"_type\" : \"doc\",\n        \"_id\" : \"510221197001013611\",\n        \"_score\" : 1.4916549,\n        \"_source\" : {\n          \"name\" : \"李云龙\",\n          \"id\" : \"510221197001013611\",\n          \"addr\" : \"上海市浦东区华北路8号\",\n          \"tel\" : \"13908712808\"\n        }\n      }\n    ]\n  }\n}\n```\n\n第三步：使用 should，判断 addr 中必须有昆明市，这种情况下 should 子句会影响计分\n\n```json\nGET /customer/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"term\":{\n          \"name.keyword\":\"李云龙\"\\\n        }\n      },\n      \"filter\": {\n        \"term\": {\n          \"id\": \"510221197001013611\"\n        }\n      },\n      \"should\": [\n        {\n          \"match\": {\n            \"addr\": \"昆明市\"\n          }\n        }\n      ]\n    }\n  }\n}\n返回结果中，地址是昆明市的文档 score 加重\n{\n  \"hits\" : {\n    \"total\" : 2,\n    \"max_score\" : 3.408528,\n    \"hits\" : [\n      {\n        \"_index\" : \"customer\",\n        \"_type\" : \"doc\",\n        \"_id\" : \"4\",\n        \"_score\" : 3.408528,\n        \"_source\" : {\n          \"name\" : \"李云龙\",\n          \"id\" : \"510221197001013611\",\n          \"addr\" : \"昆明市滇池路阳光时代1栋1单元\",\n          \"tel\" : \"13808712808\"\n        }\n      },\n      {\n        \"_index\" : \"customer\",\n        \"_type\" : \"doc\",\n        \"_id\" : \"510221197001013611\",\n        \"_score\" : 1.5720221,\n        \"_source\" : {\n          \"name\" : \"李云龙\",\n          \"id\" : \"510221197001013611\",\n          \"addr\" : \"上海市浦东区华北路8号\",\n          \"tel\" : \"13908712808\"\n        }\n      }\n    ]\n  }\n}\n```\n\n第四步：加入 must_not 排除上海\n\n```json\nGET /customer/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"term\":{\n          \"name.keyword\":\"李云龙\"\n        }\n      },\n      \"filter\": {\n        \"term\": {\n          \"id\": \"510221197001013611\"\n        }\n      },\n      \"should\": [\n        {\"match\": {\n          \"addr\": \"昆明市\"\n        }}\n      ],\n      \"must_not\": [\n        {\"match\": {\n          \"addr\": \"上海\"\n        }}\n      ]\n    }\n  }\n}\n\n只返回一个文档：\n{\n  \"hits\" : {\n    \"total\" : 1,\n    \"max_score\" : 3.408528,\n    \"hits\" : [\n      {\n        \"_index\" : \"customer\",\n        \"_type\" : \"doc\",\n        \"_id\" : \"4\",\n        \"_score\" : 3.408528,\n        \"_source\" : {\n          \"name\" : \"李云龙\",\n          \"id\" : \"510221197001013611\",\n          \"addr\" : \"昆明市滇池路阳光时代1栋1单元\",\n          \"tel\" : \"13808712808\"\n        }\n      }\n    ]\n  }\n}\n```","tags":["Elasticsearch"]},{"title":"tokenizer 和 analyzer 的关系","url":"/2023/02/15/2023-02-15-fen-ci-qi-xiang-guan/","content":"\nTokenizer、Token-filter 和 analyzer：\n\n<ul>\n    <li>tokenizer：分词器</li>\n    <li>analyzer：分析器</li>\n    <li>token-filter：分词过滤器</li>\n</ul>\n\n1、Tokenizer（分词器）\n\n分词，就是将一个字符串，按照某种特定规则打散为多个字符串的过程。\n\n2、Token-filter（分词过滤器）\n\n分词过滤器，是对分词器处理后得到的子字符串，进行字符的修改。 （例如：大小写转换、时态、复数……）\n\n3、Analyzer（分析器）\n\n分析器是分词器和分词过滤器的结合。\n\nES 使用分析器（Analyzer）对文档进行分词，ES 中内置了很多分析器供我们使用，我们也可以定制自己的分析器。\n\n一个分析器有 3 个组成部分，分析过程会依次经过这些部分：\n\n<ol>\n    <li>Character Filters：字符过滤，用于删去某些字符。该组件可以有 0 或多个。</li>\n    <li>Tokenizer：分词过程，按照某个规则将文档切分为单词，比如用空格来切分。该组件有且只能有一个。</li>\n    <li>Token Filter：对切分好的单词进一步加工，比如大小写转换，删除停用词等。该组件可以有 0 或多个。</li>\n</ol>\n\n也就是说，分词器就是划分子字符串，分词过滤器就是子字符串的格式转换，分析器是两者结合。\n\n![tokenizer和analyzer的关系图](/img/2023-02-15-分词器相关/pho1.png)\n","tags":["Elasticsearch"]},{"title":"curl 常用命令使用方法","url":"/2023/02/01/2023-02-01-curl-chang-yong-ming-ling-shi-yong-fang-fa/","content":"\n## 什么是 curl\n\n全称 CommandLine Uniform Resource Locator。它在命令行方式下工作，利用 URL 的语法进行数据的传输或者文件的传输；用于在本地计算机与远程服务器之间传输数据的命令行工具。\n\ncurl 的官方网站：<a href='https://curl.se/'>https://curl.se/</a>\n\n从官网中，可以得知 curl 支持各种各样的协议，其中常见的协议有 FILE、FTP、HTTP、HTTPS等\n\ncurl的用法跟一般的linux/Unix命令无异，一般语法如下：\n\n```bash\ncrul -[选项] [URL]\n```\n\n<hr/>\n\n以下是常用的 curl 命令：\n\n1、-v 选项（verbose）：指定该选项后，可以跟踪URL的连接信息；返回端口连接信息，http请求头部信息，网页html信息。\n<ul>\n    <li>-v 参数表示显示一次 http 通信的整个过程，包括端口连接和 http request 头信息 </li>\n    <li>-vv 就表示显示两次 http 通信的过程 </li>\n</ul>\n\n2、-u 选项，带用户验证的连接。可以访问或获取带用户验证的URL。\n\n3、-X 选项，指定请求方式，我们只能URL可以有多种请求方式，最常见的是GET和POST，但请求的方式，包括GET、PUT、POST、DELETE四种方式。\n\n4、-d 选项，带请求参数的连接。\n\n5、-i 选项（include）：把回应的头信息包含在内，也就是返回该网址的html信息和协议头部信息；-I （大写i）选项（head）：只显示返回的头信息；它们跟 -v 大同小异，是 -v 的子集。\n\n\n","tags":["Linux"]},{"title":"从容器到容器云：谈谈 Kubernetes 的本质","url":"/2023/01/23/2023-01-23-cong-rong-qi-dao-rong-qi-yun-tan-tan-kubernetes-de-ben-zhi/","content":"\n通过阅读白话容器基础那几篇文章，不难发现，一个“容器”，实际上是一个由 Linux Namespace、Linux Cgroups 和 rootfs 三种技术构建出来的进程的隔离环境。\n\n从这个结构中我们不难看出，一个正在运行的 Linux 容器，其实可以被“一分为二”地看待：\n\n<ol>\n    <li>一组联合挂载在 /var/lib/docker/aufs/mnt 上的 rootfs，这一部分我们称为“容器镜像”（Container Image），是容器的静态视图</li>\n    <li>一个由 Namespace+Cgroups 构成的隔离环境，这一部分我们称为“容器运行时”（Container Runtime），是容器的动态视图</li>\n</ol>\n\n更进一步说，作为一个开发者，我并不关心容器运行时的差异。因为，在整个“开发 - 测试 - 发布”的流程中，真正承载着容器信息进行传递的，是容器镜像，而不是容器运行时。\n\n从一个开发者和单一的容器镜像，到无数开发者和庞大的容器集群，容器技术实现了从“容器”到“容器云”的飞跃，标志着它真正得到了市场和生态的认可。\n\n这样，**容器就从一个开发者手里的小工具，一跃成为了云计算领域的绝对主角；而能够定义容器组织和管理规范的“容器编排”技术，则当仁不让地坐上了容器技术领域的“头把交椅”。**\n\n这其中，最具代表性的容器编排工具，当属 Docker 公司的 Compose+Swarm 组合，以及 Google 与 RedHat 公司共同主导的 Kubernetes 项目。\n\n跟很多基础设施领域先有工程实践、后有方法论的发展路线不同，Kubernetes 项目的理论基础则要比工程实践走得靠前得多，这当然要归功于 Google 公司在 2015 年 4 月发布的Borg 论文了。\n\nBorg 系统，一直以来都被誉为 Google 公司内部最强大的“秘密武器”。因为，相比于 Spanner、BigTable 等相对上层的项目，Borg 要承担的责任，是承载 Google 公司整个基础设施的核心依赖。在 Google 公司已经公开发表的基础设施体系论文中，Borg 项目当仁不让地位居整个基础设施技术栈的最底层。\n\nBorg 整体架构：可以去看<a href=\"https://zhuanlan.zhihu.com/p/30355957\">《Borg：Google内部的大型集群管理系统》</a>这篇文章。\n\n虽然在 Master 节点的实现细节上，Borg 项目与 Kubernetes 项目不尽相同，但它们的出发点是一致的，即：如何编排、管理、调度用户提交的作业。\n\nK8s架构图：\n\n![K8s架构图](/img/2023-01-23-从容器到容器云：谈谈Kubernetes的本质/pho1.jpg)\n\n控制节点，即 Master 节点，由三个紧密协作的独立组件组合而成，它们分别是：\n\n<ul>\n    <li>kube-apiserver：负责 API 服务</li>\n    <li>kube-scheduler：负责调度</li>\n    <li>kube-controller-manager：负责容器编排</li>\n</ul>\n\n整个集群的持久化数据，则由 kube-apiserver 处理后保存在 Etcd 中。\n\n而计算节点上最核心的部分，则是一个叫作 **kubelet** 的组件。\n\n**在 Kubernetes 项目中，kubelet 主要负责同容器运行时（比如 Docker 项目）打交道。** 而这个交互所依赖的，是一个称作 CRI（Container Runtime Interface）的远程调用接口，这个接口定义了容器运行时的各项核心操作，比如：启动一个容器需要的所有参数。\n\n这也是为何，Kubernetes 项目并不关心你部署的是什么容器运行时、使用的什么技术实现，只要你的这个容器运行时能够运行标准的容器镜像，它就可以通过实现 CRI 接入到 Kubernetes 项目当中。\n\n而具体的容器运行时，比如 Docker 项目，则一般通过 OCI 这个容器运行时规范同底层的 Linux 操作系统进行交互，即：把 CRI 请求翻译成对 Linux 操作系统的调用（操作 Linux Namespace 和 Cgroups 等）。\n\n**此外，kubelet 还通过 gRPC 协议同一个叫作 Device Plugin 的插件进行交互。** 这个插件，是 Kubernetes 项目用来管理 GPU 等宿主机物理设备的主要组件，也是基于 Kubernetes 项目进行机器学习训练、高性能作业支持等工作必须关注的功能。\n\n**而 kubelet 的另一个重要功能，则是调用网络插件和存储插件为容器配置网络和持久化存储。** 这两个插件与 kubelet 进行交互的接口，分别是 CNI（Container Networking Interface）和 CSI（Container Storage Interface）。\n\n但实际上，虽然 kubelet 这个奇怪的名字，来自于 Borg 项目里的同源组件 Borglet。不过，如果你浏览过 Borg 论文的话，就会发现，这个命名方式可能是 kubelet 组件与 Borglet 组件的唯一相似之处。因为 Borg 项目，并不支持我们这里所讲的容器技术，而只是简单地使用了 Linux Cgroups 对进程进行限制。\n\nBorg 对于 Kubernetes 项目的指导作用主要体现在 Master 节点。\n\n虽然在 Master 节点的实现细节上 Borg 项目与 Kubernetes 项目不尽相同，但它们的出发点却高度一致，即：如何编排、管理、调度用户提交的作业？\n\n\n\n","tags":["K8s","极客时间"]},{"title":"chroot、pivot_root 和 switch_root 的区别","url":"/2023/01/12/2023-01-12-chroot-pivot-root-he-switch-root-de-qu-bie/","content":"\n## chroot\n\nchroot : change to root\n\n为了进一步提高系统的安全性，linux 引入了 chroot 机制，chroot 是一个系统调用，可以更改一个进程所能看到的根目录。\n\n类似创建一个沙盒，进程运行在沙盒之内，进程运行正常与否，并不会影响这台虚拟机的其他进程。\n\n```bash\n# 切换到有效的 filesystem bundle 目录\n$ ls\nbin  dev  lib  media  opt  root  sbin  sys  var  boot\netc  home  mnt  proc  run  srv  tmp  usr\n$ cd /mycontainer\n$ chroot rootfs /bin/sh\n# 进入到一个新的shell中\n$ ls /\nbin  dev  lib \n```\n\n可以看出，ls 命令参考的根是不同, 以此来形成简单的隔离.\n\n## pivot_root\n\n改变当前工作目录的所有进程或线程的工作目录. 这个跟chroot的就有很大的区别，chroot是只改变即将运行的某进程的根目录。\n\npviot_root 主要是把整个系统切换到一个新的 root 目录，然后去掉对之前rootfs的依赖，以便于可以 umount 之前的文件系统（pivot_root 需要 root 权限）\n\n用法：pivot_root new_root put_old\n\n例子：\n\n   从 127.0.0.1:/home/puser/nfsroot 挂载新的文件系统并且运行 init\n\n<ul>\n    <li> 拷贝 sh, ls 至 nfsroot/bin，以及相关的共享库至 nfsroot/lib </li>\n    <li> 在 nfsroot 下面建立目录 old_root </li>\n    <li> mount -o ro 127.0.0.1:/home/puser/nfsroot /mnt </li>\n    <li> cd /mnt </li>\n    <li>\n        pivot_root . old_root <br/>\n        这个时候，会发现比如 \"ls /\" 显示的是 nfsroot 下面的文件；\"ls old_root\" 显示的是之前文件系统 root 下面的文件。\n    </li>\n</ul>\n\npivot_root 和 chroot 的主要区别是，pivot_root 主要是把整个系统切换到一个新的 root 目录，而移除对之前 root 文件系统的依赖，这样你就能够 umount 原先的 root 文件系统。而 chroot 是针对某个进程，而系统的其它部分依旧运行于老的 root 目录。\n\n## switch_root\n\n专为 initramfs 设计, 通常 initramfs 都是为了安装最终的根文件系统做准备工作，然后切换到新的根文件系统上去。\n\ninitramfs 是 rootfs， 且不能 umount， 所以不能使用 pivot_root。\n\nswitch_root做的工作：\n\n<ul>\n   <li> 删除早的 rootfs 内的全部内容，目的是为了释放空间，因为用的内存空间</li> \n   <li> 安装新的根文件系统</li> \n   <li> 切换到新的文件系统，并执行新文件系统的 init 程序</li> \n</ul>\n\n（switch_root 必须由 pid=1 的进程调用，否则会错误，例如在 init 脚本: exec switch_root new_rootfs  /init）\n\n## 参考\n\n<ul>\n    <li>\n        <a href='https://blog.csdn.net/u012385733/article/details/102565591'>chroot，pivot_root和switch_root 区别</a>\n    </li>\n    <li>\n        <a href=\"https://waynerv.com/posts/container-fundamentals-filesystem-isolation-and-sharing/#chroot-%E5%91%BD%E4%BB%A4%E7%9A%84%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B\">容器技术原理(五)：文件系统的隔离和共享</a>\n    </li>\n    <li>\n        <a href=\"https://blog.csdn.net/linuxchyu/article/details/21109335\">Linux中chroot与pivot_root的区别</a>\n    </li>\n</ul>","tags":["Linux"]},{"title":"白话容器基础（三）：深入理解容器镜像","url":"/2023/01/04/2023-01-04-bai-hua-rong-qi-ji-chu-san-shen-ru-li-jie-rong-qi-jing-xiang/","content":"\nLinux 容器最基础的两种技术：Namespace 和 Cgroups，其中 Namespace 的作用是“隔离”，它让应用进程只能看到该 Namespace 内的“世界”；而 Cgroups 的作用是“限制”，它给这个“世界”围上了一圈看不见的墙。\n\n这么一折腾，进程就真的被“装”在了一个与世隔绝的房间里，而这些房间就是 PaaS 项目赖以生存的应用“沙盒”。\n\n可是，现在这个房间四周虽然有了墙，但是如果容器进程低头一看地面，又是怎样一副景象呢？\n\n换句话说，容器里的进程看到的文件系统又是什么样子的呢？\n\n可能你立刻就能想到，这一定是一个关于 Mount Namespace 的问题：容器里的应用进程，理应看到一份完全独立的文件系统。这样，它就可以在自己的容器目录（比如 /tmp）下进行操作，而完全不会受宿主机以及其他容器的影响。\n\n但是，Mount Namespace 修改的是容器进程对文件系统“挂载点”的认知。这也就意味着，只有在“挂载”这个操作发生之后，进程的视图才会被改变。而在此之前，新创建的容器会直接继承宿主机的各个挂载点。\n\n因此，创建新进程时，除了声明要启用 Mount Namespace 之外，我们还应该告诉容器进程，有哪些目录需要重新挂载，就比如这个 /tmp 目录；更重要的是，因为我们创建的新进程启用了 Mount Namespace，所以这次重新挂载的操作，只在容器进程的 Mount Namespace 中有效。这就是 Mount Namespace 跟其他 Namespace 的使用略有不同的地方：它对容器进程视图的改变，一定是伴随着挂载操作（mount）才能生效。\n\n但是，作为一个普通用户，我们希望的是一个更友好的情况：每当创建一个新容器时，我希望容器进程看到的文件系统就是一个独立的隔离环境，而不是继承自宿主机的文件系统。那应该怎么才能做到这一点呢？\n\n不难想到，我们可以在容器进程启动之前重新挂载它的整个根目录“/”。而由于 Mount Namespace 的存在，这个挂载对宿主机不可见，所以容器进程就可以在里面随便折腾了。\n\n在 Linux 操作系统里，有一个名为 chroot 的命令可以帮助你在 shell 中方便地完成这个工作。顾名思义，它的作用就是帮你“change root file system”，即改变进程的根目录到你指定的位置。它的用法也非常简单。\n\n假设，现在有一个 $HOME/test 目录，要让它作为一个 /bin/bash 进程的根目录。\n\n首先，创建一个 test 目录和几个 lib 文件夹：\n\n```bash\n$ mkdir -p $HOME/test\n$ mkdir -p $HOME/test/{bin,lib64,lib}\n$ cd $T\n```\n\n然后，把 bash 命令拷贝到 test 目录对应的 bin 路径下：\n\n```bash\ncp -v /bin/{bash,ls} $HOME/test/bin\n```\n\n接下来，把 bash 命令需要的所有 so 文件，也拷贝到 test 目录对应的 lib 路径下。找到 so 文件可以用 ldd 命令：\n\n```bash\n$ T=$HOME/test\n$ list=\"$(ldd /bin/ls | egrep -o '/lib.*\\.[0-9]')\"\n$ for i in $list; do cp -v \"$i\" \"${T}${i}\"; done\n```\n\n最后，执行 chroot 命令，告诉操作系统，我们将使用 $HOME/test 目录作为 /bin/bash 进程的根目录：\n\n```bash\n$ chroot $HOME/test /bin/bash\n```\n\n这时，你如果执行 \"ls /\"，就会看到，它返回的都是 $HOME/test 目录下面的内容，而不是宿主机的内容。\n\n更重要的是，对于被 chroot 的进程来说，它并不会感受到自己的根目录已经被“修改”成 $HOME/test 了。\n\n这种视图被修改的原理，是不是和 Linux Namespace 很类似呢？\n\n没错！\n\n**实际上，Mount Namespace 正是基于对 chroot 的不断改良才被发明出来的，它也是 Linux 操作系统里的第一个 Namespace。**\n\n当然，为了能够让容器的这个根目录看起来更“真实”，我们一般会在这个容器的根目录下挂载一个完整操作系统的文件系统，比如 Ubuntu16.04 的 ISO。这样，在容器启动之后，我们在容器里通过执行 \"ls /\" 查看根目录下的内容，就是 Ubuntu 16.04 的所有目录和文件。\n\n**而这个挂载在容器根目录上、用来为容器进程提供隔离后执行环境的文件系统，就是所谓的“容器镜像”。它还有一个更为专业的名字，叫作：rootfs（根文件系统）。**\n\n所以，一个最常见的 rootfs，或者说容器镜像，会包括如下所示的一些目录和文件，比如 /bin，/etc，/proc 等等：\n\n```bash\n$ ls /\nbin dev etc home lib lib64 mnt opt proc root run sbin sys tmp usr var\n```\n\n而你进入容器之后执行的 /bin/bash，就是 /bin 目录下的可执行文件，与宿主机的 /bin/bash 完全不同。\n\n现在，你应该可以理解，对 Docker 项目来说，它最核心的原理实际上就是为待创建的用户进程：\n\n<ol>\n    <li> 启用 Linux Namespace 配置 </li>\n    <li> 设置指定的 Cgroups 参数 </li>\n    <li> 切换进程的根目录（Change Root） </li>\n</ol>\n\n这样，一个完整的容器就诞生了。不过，Docker 项目在最后一步的切换上会优先使用 pivot_root 系统调用，如果系统不支持，才会使用 chroot。\n\n另外，**需要明确的是，rootfs 只是一个操作系统所包含的文件、配置和目录，并不包括操作系统内核。在 Linux 操作系统中，这两部分是分开存放的，操作系统只有在开机启动时才会加载指定版本的内核镜像。**\n\n所以说，rootfs 只包括了操作系统的“躯壳”，并没有包括操作系统的“灵魂”。\n\n那么，对于容器来说，这个操作系统的“灵魂”又在哪里呢？\n\n实际上，同一台机器上的所有容器，都共享宿主机操作系统的内核。\n\n这就意味着，如果你的应用程序需要配置内核参数、加载额外的内核模块，以及跟内核进行直接的交互，你就需要注意了：这些操作和依赖的对象，都是宿主机操作系统的内核，它对于该机器上的所有容器来说是一个“全局变量”，牵一发而动全身。\n\n这是容器相较于虚拟机的缺陷之一：毕竟后者不仅有模拟出来的硬件机器当作沙盒，而且每个沙盒里还运行着一个完整的 Guest OS 给应用随便折腾。\n\n不过，**正是由于 rootfs 的存在，容器才有了一个被反复宣传至今的重要特性：一致性。**\n\n什么是容器的“一致性”呢？\n\n## 容器的一致性 \n\n由于云端与本地服务器环境不同，应用的打包过程，一直是使用 PaaS 时最“痛苦”的一个步骤。\n\n但有了容器之后，更准确地说，有了容器镜像（即 rootfs）之后，这个问题被非常优雅地解决了。\n\n**由于 rootfs 里打包的不只是应用，而是整个操作系统的文件和目录，也就意味着，应用以及它运行所需要的所有依赖，都被封装在了一起。**\n\n事实上，对于大多数开发者而言，他们对应用依赖的理解，一直局限在编程语言层面。比如Golang 的 Godeps.json。但实际上，一个一直以来很容易被忽视的事实是，**对一个应用来说，操作系统本身才是它运行所需要的最完整的“依赖库”**。\n\n有了容器镜像“打包操作系统”的能力，这个最基础的依赖环境也终于变成了应用沙盒的一部分。这就赋予了容器所谓的一致性：无论在本地、云端，还是在一台任何地方的机器上，用户只需要解压打包好的容器镜像，那么这个应用运行所需要的完整的执行环境就被重现出\n来了。\n\n**这种深入到操作系统级别的运行环境一致性，打通了应用在本地开发和远端执行环境之间难以逾越的鸿沟。**\n\n不过，这时你可能已经发现了另一个非常棘手的问题：难道我每开发一个应用，或者升级一下现有的应用，都要重复制作一次 rootfs 吗？\n\n比如，我现在用 Ubuntu 操作系统的 ISO 做了一个 rootfs，然后又在里面安装了 Java 环境，用来部署我的 Java 应用。那么，我的另一个同事在发布他的 Java 应用时，显然希望能够直接使用我安装过 Java 环境的 rootfs，而不是重复这个流程。\n\n一种比较直观的解决办法是，我在制作 rootfs 的时候，每做一步“有意义”的操作，就保存一个 rootfs 出来，这样其他同事就可以按需求去用他需要的 rootfs 了。\n\n但是，这个解决办法并不具备推广性。原因在于，一旦你的同事们修改了这个 rootfs，新旧两个 rootfs 之间就没有任何关系了。这样做的结果就是极度的碎片化。\n\n那么，既然这些修改都基于一个旧的 rootfs，我们能不能以增量的方式去做这些修改呢？这样做的好处是，所有人都只需要维护相对于 base rootfs 修改的增量内容，而不是每次修改都制造一个“fork”。\n\n答案当然是肯定的。\n\n这也正是为何，Docker 公司在实现 Docker 镜像时并没有沿用以前制作 rootfs 的标准流程，而是做了一个小小的创新：\n\n>   Docker 在镜像的设计中，引入了层（layer）的概念。也就是说，用户制作镜像的每一步操作，都会生成一个层，也就是一个增量 rootfs。\n\n当然，这个想法不是凭空臆造出来的，而是用到了一种叫作联合文件系统（Union File System）的能力。\n\nUnion File System 也叫 UnionFS，最主要的功能是将多个不同位置的目录联合挂载（union mount）到同一个目录下。比如，我现在有两个目录 A 和 B，它们分别有两个文件：\n\n```bash\n$ tree\n.\n├── A\n│ ├── a\n│ └── x\n└── B\n ├── b\n └── x\n```\n\n然后，我使用联合挂载的方式，将这两个目录挂载到一个公共的目录 C 上：\n\n```bash\n$ mkdir C\n$ mount -t aufs -o dirs=./A:./B none ./C\n```\n\n这时，我再查看目录 C 的内容，就能看到目录 A 和 B 下的文件被合并到了一起：\n\n```bash\n$ tree ./C\n./C\n├── a\n├── b\n└── x\n```\n\n可以看到，在这个合并后的目录 C 里，有 a、b、x 三个文件，并且 x 文件只有一份。这就是“合并”的含义。此外，如果你在目录 C 里对 a、b、x 文件做修改，这些修改也会在对应的目录 A、B 中生效。\n\n那么，在 Docker 项目中，又是如何使用这种 Union File System 的呢？\n\n## Union File System\n\n如果你的环境是 Ubuntu 16.04 和 Docker CE 18.05，这对组合默认使用的是 AuFS 这个联合文件系统的实现。你可以通过 docker info 命令，查看到这个信息。\n\n对于 AuFS 来说，它最关键的目录结构在 /var/lib/docker 路径下的 diff 目录：\n\n```bash\n/var/lib/docker/aufs/diff/<layer_id>\n```\n\n**而这个目录的作用，我们不妨通过一个具体例子来看一下。**\n\n现在，我们启动一个容器，比如：\n\n```bash\n$ docker run -d ubuntu:latest sleep 3600\n```\n\n这时候，Docker 就会从 Docker Hub 上拉取一个 Ubuntu 镜像到本地。\n\n这个所谓的“镜像”，实际上就是一个 Ubuntu 操作系统的 rootfs，它的内容是 Ubuntu 操作系统的所有文件和目录。不过，与之前我们讲述的 rootfs 稍微不同的是，Docker 镜像使用的 rootfs，往往由多个“层”组成：\n\n```bash\n$ docker image inspect ubuntu:latest\n...\n    \"RootFS\": {\n        \"Type\": \"layers\",\n        \"Layers\": [\n            \"sha256:f49017d4d5ce9c0f544c...\",\n            \"sha256:8f2b771487e9d6354080...\",\n            \"sha256:ccd4d61916aaa2159429...\",\n            \"sha256:c01d74f99de40e097c73...\",\n            \"sha256:268a067217b5fe78e000...\"\n        ]\n    }\n```\n\n可以看到，这个 Ubuntu 镜像，实际上由五个层组成。这五个层就是五个增量 rootfs，每一层都是 Ubuntu 操作系统文件与目录的一部分；而在使用镜像时，Docker 会把这些增量联合挂载在一个统一的挂载点上（等价于前面例子里的“/C”目录）。\n\n这个挂载点就是 /var/lib/docker/aufs/mnt/，比如：\n\n```bash\n/var/lib/docker/aufs/mnt/6e3be5d2ecccae7cc0fc...\n```\n\n不出意外的话，这个目录里面正是一个完整的 Ubuntu 操作系统：\n\n```bash\n$ ls /var/lib/docker/aufs/mnt/6e3be5d2ecccae7cc0fc...\nbin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var\n```\n\n那么，前面提到的五个镜像层，又是如何被联合挂载成这样一个完整的 Ubuntu 文件系统的呢？\n\n这个信息记录在 AuFS 的系统目录 /sys/fs/aufs 下面。\n\n首先，通过查看 AuFS 的挂载信息，我们可以找到这个目录对应的 AuFS 的内部 ID（也叫：si）：\n\n```bash\n$ cat /proc/mounts| grep aufs\nnone /var/lib/docker/aufs/mnt/6e3be5d2ecccae7cc0fc... aufs rw,relatime,si=972c6d361e6b32ba\n```\n\n然后使用这个 ID，你就可以在 /sys/fs/aufs 下查看被联合挂载在一起的各个层的信息：\n\n```bash\n$ cat /sys/fs/aufs/si_972c6d361e6b32ba/br[0-9]*\n/var/lib/docker/aufs/diff/6e3be5d2ecccae7cc...=rw\n/var/lib/docker/aufs/diff/6e3be5d2ecccae7cc...-init=ro+wh\n/var/lib/docker/aufs/diff/32e8e20064858c0f2...=ro+wh\n/var/lib/docker/aufs/diff/2b8858809bce62e62...=ro+wh\n/var/lib/docker/aufs/diff/20707dce8efc0d267...=ro+wh\n/var/lib/docker/aufs/diff/72b0744e06247c7d0...=ro+wh\n/var/lib/docker/aufs/diff/a524a729adadedb90...=ro+wh\n```\n\n从这些信息里，我们可以看到，镜像的层都放置在 /var/lib/docker/aufs/diff 目录下，然后被联合挂载在 /var/lib/docker/aufs/mnt 里面。\n\n**而且，从这个结构可以看出来，这个容器的 rootfs 由如下图所示的三部分组成：**\n\n![rootfs](/img/2023-01-04-白话容器基础（三）：深入理解容器镜像/pho1.png)\n\n### 第一部分，只读层\n\n它是这个容器的 rootfs 最下面的五层，对应的正是 ubuntu:latest 镜像的五层。可以看到，它们的挂载方式都是只读的（ro+wh，即 readonly+whiteout）。\n\n这时，我们可以分别查看一下这些层的内容：\n\n```bash\n$ ls /var/lib/docker/aufs/diff/72b0744e06247c7d0...\netc sbin usr var\n$ ls /var/lib/docker/aufs/diff/32e8e20064858c0f2...\nrun\n$ ls /var/lib/docker/aufs/diff/a524a729adadedb900...\nbin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var\n```\n\n可以看到，这些层，都以增量的方式分别包含了 Ubuntu 操作系统的一部分。\n\n### 第二部分，可读写层\n\n它是这个容器的 rootfs 最上面的一层（6e3be5d2ecccae7cc），它的挂载方式为：rw，即 read write。在没有写入文件之前，这个目录是空的。而一旦在容器里做了写操作，你修改所产生的内容就会以增量的方式出现在这个层中。\n\n可是，你有没有想到这样一个问题：如果我现在要做的是，删除只读层里的一个文件呢？\n\n<font color='pink'>为了实现这样的删除操作，AuFS 会在可读写层创建一个 whiteout 文件，把只读层里的文件“遮挡”起来。</font>\n\n比如，你要删除只读层里一个名叫 foo 的文件，那么这个删除操作实际上是在可读写层创建了一个名叫 .wh.foo 的文件。这样，当这两个层被联合挂载之后，foo 文件就会被 .wh.foo 文件“遮挡”起来，“消失”了。这个功能，就是“ro+wh”的挂载方式，即只读 +whiteout 的含义。\n\n所以，最上面这个可读写层的作用，就是专门用来存放你修改 rootfs 后产生的增量，无论是增、删、改，都发生在这里。而当我们使用完了这个被修改过的容器之后，还可以使用docker commit 和 push 指令，保存这个被修改过的可读写层，并上传到 Docker Hub 上，供其他人使用；而与此同时，原先的只读层里的内容则不会有任何变化。这，就是增量 rootfs 的好处。\n\n### 第三部分，Init 层\n\n它是一个以“-init”结尾的层，夹在只读层和读写层之间。Init 层是 Docker 项目单独生成的一个内部层，专门用来存放 /etc/hosts、/etc/resolv.conf 等信息。\n\n需要这样一层的原因是，这些文件本来属于只读的 Ubuntu 镜像的一部分，但是用户往往需要在启动容器时写入一些指定的值比如 hostname，所以就需要在可读写层对它们进行修改。\n\n可是，这些修改往往只对当前的容器有效，我们并不希望执行 docker commit 时，把这些信息连同可读写层一起提交掉。\n\n所以，Docker 做法是，在修改了这些文件之后，以一个单独的层挂载了出来。而用户执行docker commit 只会提交可读写层，所以是不包含这些内容的。\n\n最终，这 7 个层都被联合挂载到 /var/lib/docker/aufs/mnt 目录下，表现为一个完整的 Ubuntu 操作系统供容器使用。\n\n## 总结\nLinux 容器文件系统的实现方式机制：rootfs。它只是一个操作系统的所有文件和目录，并不包含内核，最多也就几百兆。而相比之下，传统虚拟机的镜像大多是一个磁盘的“快照”，磁盘有多大，镜像就至少有多大。\n\n通过结合使用 Mount Namespace 和 rootfs，容器就能够为进程构建出一个完善的文件系统隔离环境。当然，这个功能的实现还必须感谢 chroot 和 pivot_root 这两个系统调用切换进程根目录的能力。\n\n而在 rootfs 的基础上，Docker 公司创新性地提出了使用多个增量 rootfs 联合挂载一个完整 rootfs 的方案，这就是容器镜像中“层”的概念。\n\n通过“分层镜像”的设计，以 Docker 镜像为核心，来自不同公司、不同团队的技术人员被紧密地联系在了一起。而且，由于容器镜像的操作是增量式的，这样每次镜像拉取、推送的内容，比原本多个完整的操作系统的大小要小得多；而共享层的存在，可以使得所有这些容器镜像需要的总空间，也比每个镜像的总和要小。这样就使得基于容器镜像的团队协作，要比基于动则几个 GB 的虚拟机磁盘镜像的协作要敏捷得多。\n\n更重要的是，一旦这个镜像被发布，那么你在全世界的任何一个地方下载这个镜像，得到的内容都完全一致，可以完全复现这个镜像制作者当初的完整环境。这，就是容器技术“强一致性”的重要体现。\n\n而这种价值正是支撑 Docker 公司在 2014~2016 年间迅猛发展的核心动力。容器镜像的发明，不仅打通了“开发 - 测试 - 部署”流程的每一个环节，更重要的是：\n\n<center>\n    <font color=\"red\">\n        容器镜像将会成为未来软件的主流发布方式。\n    </font>\n</center>","tags":["Docker","极客时间"]},{"title":"白话容器基础（二）：隔离与限制","url":"/2022/12/19/2022-12-29-bai-hua-rong-qi-ji-chu-er-ge-chi-yu-xian-zhi/","content":"\n## 容器基础 —— 隔离\n\n### 思考\n\n![虚拟机和容器的对比图](/img/2022-12-29-白话容器基础（二）：隔离与限制/pho1.png)\n\n在这个虚拟机与容器技术的对比图里，应不应该把 Docker Engine 或者任何容器管理工具放在跟 Hypervisor 相同的位置？\n\n在<a href=\"../12/白话容器基础-一-从进程说开去.html\">《白话容器基础（一）：从进程说开去》</a>中详细介绍了 Linux 容器中用来实现“隔离”的技术手段：**Namespace**。而通过这些讲解，你应该能够明白，Namespace 技术实际上只是修改了应用进程看待整个计算机“视图”，即它的“视线”被操作系统做了限制，只能“看到”某些指定的内容。但对于宿主机来说，这些被“隔离”了的进程跟其他进程并没有太大区别。\n\n我相信你应该有了思考的答案，那就是不应该。因为它们（Docker Engine 或者任何容器管理工具）并不像 Hypervisor 那样对应用进程的隔离环境负责，也不会创建任何实体的“容器”，真正对隔离环境负责的是宿主机操作系统本身：\n\n![虚拟机和容器的对比图](/img/2022-12-29-白话容器基础（二）：隔离与限制/pho2.png)\n\n所以，在这个对比图里，我们应该把 Docker 画在跟应用同级别并且靠边的位置。这意味着，用户运行在容器里的应用进程，跟宿主机上的其他进程一样，都由宿主机操作系统统一管理，只不过这些被隔离的进程拥有额外设置过的 Namespace 参数。而 Docker 项目在这里扮演的角色，更多的是旁路式的辅助和管理工作，甚至在某些情况下可以被去掉。\n\n**这样的架构也解释了为什么 Docker 项目比虚拟机更受欢迎的原因。**\n\n这是因为，使用虚拟化技术作为应用沙盒，就必须要由 Hypervisor 来负责创建虚拟机，这个虚拟机是真实存在的，并且它里面必须运行一个完整的 Guest OS 才能执行用户的应用进程。这就不可避免地带来了额外的资源消耗和占用。\n\n根据实验，一个运行着 CentOS 的 KVM 虚拟机启动后，在不做优化的情况下，虚拟机自己就需要占用 100~200 MB 内存。此外，用户应用运行在虚拟机里面，它对宿主机操作系统的调用就不可避免地要经过虚拟化软件的拦截和处理，这本身又是一层性能损耗，尤其对计算资源、网络和磁盘 I/O 的损耗非常大。\n\n而相比之下，容器化后的用户应用，却依然还是一个宿主机上的普通进程，这就意味着这些因为虚拟化而带来的性能损耗都是不存在的；而另一方面，使用 Namespace 作为隔离手段的容器并不需要单独的 Guest OS，这就使得容器额外的资源占用几乎可以忽略不计。\n\n所以说，**相较于虚拟机，容器最大的优势是“敏捷”和“高性能”，也是它能够在 PaaS 这种更细粒度的资源管理平台上蔚然成风的重要原因。**\n\n不过，有利就有弊，基于 Linux Namespace 的隔离机制相比于虚拟化技术也有很多不足之处，其中最主要的问题就是：**隔离得不彻底**。\n\n<font color='pink'>首先，既然容器只是运行在宿主机上的一种特殊的进程，那么多个容器之间使用的就还是同一个宿主机的操作系统内核。</font>\n\n尽管你可以在容器里通过 Mount Namespace 单独挂载其他不同版本的操作系统文件，比如 CentOS 或者 Ubuntu，但这并不能改变共享宿主机内核的事实。这意味着，如果你要在 Windows 宿主机上运行 Linux 容器，或者在低版本的 Linux 宿主机上运行高版本的 \nLinux 容器，都是行不通的。\n\n而相比之下，拥有硬件虚拟化技术和独立 Guest OS 的虚拟机就要方便得多了。最极端的例子是，Microsoft 的云计算平台 Azure，实际上就是运行在 Windows 服务器集群上的，但这并不妨碍你在它上面创建各种 Linux 虚拟机出来。\n\n<font color='pink'>其次，在 Linux 内核中，有很多资源和对象是不能被 Namespace 化的，最典型的例子就是：时间。</font>\n\n这就意味着，如果你的容器中的程序使用 settimeofday(2) 系统调用修改了时间，整个宿主机的时间都会被随之修改，这显然不符合用户的预期。相比于在虚拟机里面可以随便折腾的自由度，在容器里部署应用的时候，“什么能做，什么不能做”，就是用户必须考虑的一个问题。\n\n此外，由于上述问题，尤其是共享宿主机内核的事实，容器给应用暴露出来的攻击面是相当大的，应用“越狱”的难度自然也比虚拟机低得多。\n\n更为棘手的是，尽管在实践中我们确实可以使用 Seccomp 等技术，对容器内部发起的所有系统调用进行过滤和甄别来进行安全加固，但这种方法因为多了一层对系统调用的过滤，一定会拖累容器的性能。何况，默认情况下，谁也不知道到底该开启哪些系统调用，禁止哪些系统调用。\n\n所以，在生产环境中，没有人敢把运行在物理机上的 Linux 容器直接暴露到公网上。\n\n## 容器基础 —— 限制\n\n### 思考\n我们不是已经通过 Linux Namespace 创建了一个“容器”吗，为什么还需要对容器做“限制”呢？\n\n以 PID Namespace 为例：\n\n&emsp;&emsp;虽然容器内的第 1 号进程在“障眼法”的干扰下只能看到容器里的情况，但是宿主机上，它作为第 100 号进程与其他所有进程之间依然是平等的竞争关系。这就意味着，虽然第 100 号进程表面上被隔离了起来，但是它所能够使用到的资源（比如 CPU、内存），却是可以随时被宿主机上的其他进程（或者其他容器）占用的。当然，这个 100 号进程自己也可能把所有资源吃光。这些情况，显然都不是一个“沙盒”应该表现出来的合理行为。\n\n而 Linux Cgroups（ Linux Control Group ）就是 Linux 内核中用来为进程设置资源限制的一个重要功能。**它最主要的作用，就是限制一个进程组能够使用的资源上限，包括 CPU、内存、磁盘、网络带宽等等。**\n\n在 Linux 中，Cgroups 给用户暴露出来的操作接口是文件系统，即它以文件和目录的方式组织在操作系统的 /sys/fs/cgroup 路径下。在 Red Hat 4.8.5-36 机器里，我可以用 mount 指令把它们展示出来，这条命令是：\n```bash\n$ mount -t cgroup\ncgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd)\ncgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)\ncgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)\ncgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,net_prio,net_cls)\ncgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpuacct,cpu)\ncgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,freezer)\ncgroup on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,perf_event)\ncgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids)\ncgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb)\ncgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)\ncgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices)\n```\n\n它的输出结果，是一系列文件系统目录。如果你在自己的机器上没有看到这些目录，那你就需要自己去挂载 Cgroups，具体做法可以自行 Google。\n\n可以看到，在 /sys/fs/cgroup 下面有很多诸如 cpuset、cpu、 memory 这样的子目录，也叫子系统。这些都是我这台机器当前可以被 Cgroups 进行限制的资源种类。而在子系统对应的资源种类下，你就可以看到该类资源具体可以被限制的方法。比如，对 CPU 子系统\n来说，我们就可以看到如下几个配置文件，这个指令是：\n\n```bash\n$ ls /sys/fs/cgroup/cpu\ncgroup.clone_children  cpuacct.stat          cpu.cfs_quota_us   cpu.stat       notify_on_release\ncgroup.event_control   cpuacct.usage         cpu.rt_period_us   docker         release_agent\ncgroup.procs           cpuacct.usage_percpu  cpu.rt_runtime_us  kubepods       tasks\ncgroup.sane_behavior   cpu.cfs_period_us     cpu.shares         machine.slice\n```\n\n如果熟悉 Linux CPU 管理的话，你就会在它的输出里注意到 cfs_period 和 cfs_quota 这样的关键词。这两个参数需要组合使用，可以用来限制进程在长度为 cfs_period 的一段时间内，只能被分配到总量为 cfs_quota 的 CPU 时间。\n\n而这样的配置文件又如何使用呢？\n\n你需要在对应的子系统下面创建一个目录，比如，我们现在进入 /sys/fs/cgroup/cpu 目录下：\n\n```bash\n[root@vqa129 cpu]# mkdir container\n[root@vqa129 cpu]# ls container/\ncgroup.clone_children cpu.cfs_period_us cpu.rt_period_us cpu.shares notify_on_release\ncgroup.procs cpu.cfs_quota_us cpu.rt_runtime_us cpu.stat tasks\n```\n\n这个目录就称为一个“控制组”。你会发现，操作系统会在你新创建的 container 目录下，自动生成该子系统对应的资源限制文件。\n\n现在，我们在后台执行这样一条脚本：\n\n```bash\n$ while : ; do : ; done &\n[1] 226\n```\n\n显然，它执行了一个死循环，可以把计算机的 CPU 吃到 100%，根据它的输出，我们可以看到这个脚本在后台运行的进程号（PID）是 226。\n\n这样，我们可以用 top 指令来确认一下 CPU 有没有被打满：\n\n```bash\n$ top\n%Cpu0 :100.0 us, 0.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st\n```\n\n在输出里可以看到，CPU 的使用率已经 100% 了（%Cpu0 :100.0 us）。\n\n而此时，我们可以通过查看 container 目录下的文件，看到 container 控制组里的 CPU quota 还没有任何限制（即：-1），CPU period 则是默认的 100 ms（100000 us）：\n\n```bash\n$ cat /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us \n-1\n$ cat /sys/fs/cgroup/cpu/container/cpu.cfs_period_us \n100000\n```\n\n接下来，我们可以通过修改这些文件的内容来设置限制。\n\n比如，向 container 组里的 cfs_quota 文件写入 20 ms（20000 us）：\n\n```bash\n$ echo 20000 > /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us\n```\n\n结合前面的介绍，你应该能明白这个操作的含义，它意味着在每 100 ms 的时间里，被该控制组限制的进程只能使用 20 ms 的 CPU 时间，也就是说这个进程只能使用到 20% 的\nCPU 带宽。\n\n接下来，我们把被限制的进程的 PID 写入 container 组里的 tasks 文件，上面的设置就会\n对该进程生效了：\n\n```bash\n$ echo 226 > /sys/fs/cgroup/cpu/container/tasks \n```\n\n我们可以用 top 指令查看一下：\n\n```bash\n$ top\n%Cpu0 : 20.3 us, 0.0 sy, 0.0 ni, 79.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st\n```\n\n可以看到，计算机的 CPU 使用率立刻降到了 20%（%Cpu0 : 20.3 us）。\n\n除 CPU 子系统外，Cgroups 的每一项子系统都有其独有的资源限制能力，比如：\n\n<ul>\n    <li>blkio，为 块 设 备 设 定 I/O 限 制，一般用于磁盘等设备</li>\n    <li>cpuset，为进程分配单独的 CPU 核和对应的内存节点</li>\n    <li>memory，为进程设定内存使用的限制</li>\n</ul>\n\n**Linux Cgroups 的设计还是比较易用的，简单粗暴地理解呢，它就是一个子系统目录加上一组资源限制文件的组合。**\n而对于 Docker 等 Linux 容器项目来说，它们只需要在每个子系统下面，为每个容器创建一个控制组（即创建一个新目录），然后在启动容器进程之后，把这个进程的 PID 填写到对应控制组的 tasks 文件中就可以了。\n\n而至于在这些控制组下面的资源文件里填上什么值，就靠用户执行 docker run 时的参数指定了，比如这样一条命令：\n\n```bash\n$ docker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu /bin/bash\n```\n\n在启动这个容器后，我们可以通过查看 Cgroups 文件系统下，CPU 子系统中，“docker”这个控制组里的资源限制文件的内容来确认：\n\n```bash\n$ cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_period_us\n100000\n$ cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_quota_us \n20000\n```\n\n这就意味着这个 Docker 容器，只能使用到 20% 的 CPU 带宽。\n\n## 总结\n<ul>\n    <li>容器是一种“特殊”的进程：用户的应用进程实际上就是容器里 PID=1 的进程，也是其他后续创建的所有进程的父进程</li>\n    <li>容器是一个“单进程”模型：一个正在运行的 Docker 容器，其实就是一个启用了多个 Linux Namespace 的应用进程，而这个进程能够使用的资源量，则受 Cgroups 配置的限制</li>\n</ul>\n","tags":["Docker","极客时间"]},{"title":"阳了个阳","url":"/2022/12/17/2022-12-17-a-yang-liao/","content":"\n上周开始就感觉喉咙不舒服，冲了几包板蓝根和999，无果。<br/>\n周三、周四开始咳嗽，以为是咽炎。<br/>\n周四，跟我一块的小伙伴检测：阴性。<br/>\n周五，喉咙感觉有“一团火”，去检测。<br/>\n**2022-12-17 凌晨2点 单管检测：阳性**\n\n阳性后，未出现发热症状，只是喉咙轻微不舒服。<br/>\n**2022-12-17 喉咙轻微疼痛，没发烧**\n\n考虑到同事都有小孩，再去检测。天很冷，刮大风，排队 1 个多小时。<br/>\n**2022-12-17 晚上8点 单管检测：阳性**\n\n回家后，体温飙升到38~39，四肢酸痛无力、睡觉<br/>\n**2022-12-18 晚上 发烧、浑身酸痛、咽炎**\n\n同事陆陆续续出现发热迹象，团灭，居家办公。<br/>\n**2022-12-19 低烧、咽炎、咳嗽**\n\n全天37~38度，没敢吃布洛芬，请了天假，睡了一天<br/>\n**2022-12-20 低烧、咳嗽、流鼻涕**\n\n看上去好了，轻微咳嗽。<br/>\n**2022-12-21 咳嗽**","tags":["随记"]},{"title":"图解 Paxos 算法","url":"/2022/12/14/2022-12-14-tu-jie-paxos-suan-fa/","content":"\n&emsp;&emsp;Paxos 算法是一个分布式共识算法，由 Leslie Lamport 在 1989 年提出，该算法理解起来有一定的难度，本文尝试图形化解析 Paxos 算法。\n\nLamport 提出的 Paxos 算法包括两个部分：\n<ul>\n    <li>Basic Paxos 算法：多节点如何就某个值（提案Value）达成共识</li>\n    <li>Multi-Paxos 思想：执行多个 Basic Paxos 实例，就一系列的值达成共识</li>\n</ul>\n\n## Basic Paxos\n### 思考题\n&emsp;&emsp;假设现在有一个三节点的分布式集群，提供只读 KV 存储服务。只读 KV 服务，既创建只读变量（key）的时候，必须要对它进行赋值（value），而且这个值后续没办法修改。也就是说，只读变量在创建后就不能被修改了，所以所有节点必须要先对只读变量的值达成共识，然后再去创建这个只读变量。\n\n&emsp;&emsp;那么，当有多个客户端（比如客户端 1、2）访问这个系统，试图创建同一个只读变量（比如 X），客户端 1 试图创建值为 5 的 X，客户端 2 试图创建值为 7 的 X，这样要如何达成共识，实现各节点上 X 值的一致呢？\n\n![如何在多个节点间确定某变量的值](/img/2022-12-14-图解Paxos算法/pho1.png \"图1\")\n\n在解决这个问题之前，先了解一下 Basic Paxos 的几个概念。\n\n### Paxos 涉及的概念\n\n在 Basic Paxos 中，有提议者（Proposer）、接受者（Acceptor）、学习者（Learner）三种角色：\n<ul>\n    <li>提议者：提议一个值，用于投票表决。为了方便演示，你可以把图 1 中的客户端 1 和 2 看作是提议者。但在绝大多数场景中，集群中收到客户端请求的节点，才是提议者（图 1 这个架构，是为了方便演示算法原理）。</li>\n    <li>接受者：每个提议的值进行投票，并存储接受的值，比如 A、B、C 三个节点。</li>\n    <li>学习者：被告知投票的结果，接受达成共识的值，存储保存，不参与投票的过程。</li>\n</ul>\n\n需要指出的是，**一个节点，既可以是提议者，也可以是接受者**；他们之间的关系如下：\n\n![角色之间的关系](/img/2022-12-14-图解Paxos算法/pho2.png \"图2\")\n\n其实，这三种角色，在本质上代表的是三种功能：\n\n<ul>\n    <li>提议者代表的是接入和协调功能，收到客户端请求后，发起二阶段提交，进行共识协商</li>\n    <li>接受者代表投票协商和存储数据，对提议的值进行投票，并接受达成共识的值，存储保存</li>\n    <li>学习者代表存储数据，不参与共识协商，只接受达成共识的值，存储保存</li>\n</ul>\n\n那么接下来，咱们看看如何使用 Basic Paxos 达成共识，解决开篇提到的那道思考题。\n\n### 如何达成共识\n\n&emsp;&emsp;在 Paxos 算法中，使用提案表示一个提议，提案包括提案编号和提议的值。接下来，我们使用 [n, v] 表示一个提案，其中，n 是提案编号，v 是提案的值。\n\n&emsp;&emsp;在 Basic Paxos 中，集群中各个节点为了达成共识，需要进行 2 个阶段的协商，即准备（Prepare）阶段和接受（Accept）阶段。 \n\n### 准备阶段\n\n&emsp;&emsp;假设客户端 1 的提案编号是 1，客户端 2 的提案编号为 5，并假设节点 A, B 先收到来自客户端 1 的准备请求，节点 C 先收到来自客户端 2 的准备请求。\n\n&emsp;&emsp;客户端作为提议者，向所有的接受者发送包含提案编号的准备请求。注意在准备阶段，请求中不需要指定提议的值，只需要包含提案编号即可。\n\n![准备流程1](/img/2022-12-14-图解Paxos算法/pho3.png \"图3\")\n\n&emsp;&emsp;接下来，节点 A，B 接收到客户端 1 的准备请求（提案编号为1），节点 C 接收到客户端 2 的准备请求（提案编号为 5）。\n\n![准备流程2](/img/2022-12-14-图解Paxos算法/pho4.png \"图4\")\n\n集群中各个节点在接收到第一个准备请求的处理：\n<ul>\n    <li>节点 A, B：由于之前没有通过任何提案，所以节点 A，B 将返回“尚无提案”的准备响应，并承诺以后不再响应提案编号小于等于 1 的准备请求，不会通过编号小于 1 的提案\n    </li>\n    <li>节点 C：由于之前没有通过任何提案，所以节点 C 将返回“尚无提案”的准备响应，并承诺以后不再响应提案编号小于等于 5 的准备请求，不会通过编号小于 5 的提案\n    </li>\n</ul>\n\n接下来，当节点 A，B 接收到提案编号为 5 的准备请求，节点 C 接收到提案编号为 1 的准备请求：\n\n![准备流程3](/img/2022-12-14-图解Paxos算法/pho5.png \"图5\")\n\n<ul>\n    <li>节点 A, B：由于提案编号 5 大于之前响应的准备请求的提案编号 1，且节点 A, B 都没有通过任何提案，故均返回“尚无提案”的响应，并承诺以后不再响应提案编号小于等于 5 的准备请求，不会通过编号小于 5 的提案</li>\n    <li>节点 C：由于节点 C 接收到提案编号 1 小于节点 C 之前响应的准备请求的提案编号 5 ，所以丢弃该准备请求，不作响应</li>\n</ul>\n\n### 接受阶段\n&emsp;&emsp;Basic Paxos 算法第二阶段为接受阶段。当客户端 1，2 在收到大多数节点的准备响应之后会开始发送接受请求。\n\n![接受流程1](/img/2022-12-14-图解Paxos算法/pho6.png \"图6\")\n\n<ul>\n    <li>客户端 1：客户端 1 接收到大多数的接受者（节点 A, B）的准备响应后，根据响应中的提案编号最大的提案的值，设置接受请求的值。由于节点 A, B 均返回“尚无提案”，即提案值为空，故客户端 1 把自己的提议值 \"5\" 作为提案的值，发送接受请求 [1, \"5\"]</li>\n    <li>客户端 2：客户端 2 接收到大多数接受者的准备响应后，根据响应中的提案编号最大的提案的值，设置接受请求的值。由于节点 A, B, C 均返回“尚无提案”，即提案值为空，故客户端 2 把自己的提议值 \"7\" 作为提案的值，发送接受请求 [5, \"7\"]</li>\n</ul>\n\n&emsp;&emsp;当节点 A, B, C 接收到客户端 1, 2 的接受请求时，对接受请求进行处理：\n\n![接受流程2](/img/2022-12-14-图解Paxos算法/pho7.png \"图7\")\n\n<ul>\n    <li>节点 A, B, C 接收到接受请求 [1, \"5\"] ，由于提案编号 1 小于三个节点承诺可以通过的最小提案编号 5，所以提案 [1, \"5\"] 被拒绝</li>\n    <li>节点 A, B, C 接收到接受请求 [5, \"7\"]，由于提案编号 5 不小于三个节点承诺可以通过的最小提案编号 5 ，所以通过提案 [5, \"7\"]，即三个节点达成共识，接受 X 的值为 \"7\"</li>\n</ul>\n\n&emsp;&emsp;如果集群中还有学习者，当接受者通过一个提案，就通知学习者，当学习者发现大多数接受者都通过了某个提案，那么学习者也通过该提案，接受提案的值。\n\n### 接受者存在已通过提案的情况\n\n&emsp;&emsp;上面例子中，准备阶段和接受阶段均不存在接受者已经通过提案的情况。这里继续使用上面的例子，不过假设节点 A, B 已通过提案 [5, \"7\"]，节点 C 未通过任何提案；增加一个新的提议者客户端 3，客户端 3 的提案为 [9，\"13\"] 。\n\n&emsp;&emsp;接下来，客户端 3 执行准备阶段和接受阶段；客户端 3 向节点 A, B, C 发送提案编号为 9 的准备请求：\n\n![新准备流程1](/img/2022-12-14-图解Paxos算法/pho8.png \"图8\")\n\n<ul>\n    <li>节点 A, B 接收到客户端 3 的准备请求，由于节点 A, B 已通过提案 [5, \"7\"]，故在准备响应中，包含此提案信息。</li>\n    <li>节点 C 接收到客户端 3 的准备请求，由于节点 C 未通过任何提案，故节点 C 将返回“尚无提案”的准备响应。</li>\n</ul>\n\n![新准备流程2](/img/2022-12-14-图解Paxos算法/pho9.png \"图9\")\n\n<ul>\n    <li>客户端 3 接收到节点 A, B, C 的准备响应后，向节点 A, B, C 发送接受请求。这里需要特点指出，客户端 3 会根据响应中的提案编号最大的提案的值，设置接受请求的值。</li>\n    <li>由于在准备响应中，已包含提案 [5, \"7\"]，故客户端 3 将接受请求的提案编号设置为 9，提案值设置为 \"7\" 即接受请求的提案为 [9, \"7\"]</li>\n</ul>\n\n![新接受流程1](/img/2022-12-14-图解Paxos算法/pho10.png \"图10\")\n\n&emsp;&emsp;节点 A, B, C 接收到客户端 3 的接受请求，由于提案编号 9 不小于三个节点承诺可以通过的最小提案编号，故均通过提案 [9, \"7\"]。\n\n![新接受流程2](/img/2022-12-14-图解Paxos算法/pho11.png \"图11\")\n\n概括来说，Basic Paxos 具有以下特点：\n<ul>\n    <li>Basic Paxos 通过二阶段方式来达成共识，即准备阶段和接受阶段</li>\n    <li>Basic Paxos 除了达成共识功能，还实现了容错，在少于一半节点出现故障时，集群也能工作</li>\n    <li>提案编号大小代表优先级。对于提案编号，接受者提供三个承诺：</li>\n    <ul>\n        <li>如果准备请求的提案编号，小于等于接受者已经响应的准备请求的提案编号，那么接受者承诺不响应这个准备请求</li>\n        <li>如果接受请求中的提案编号，小于接受者已经响应的准备请求的提案编号，那么接受者承诺不通过这个提案</li>\n        <li>如果按受者已通过提案，那些接受者承诺会在准备请求的响应中，包含已经通过的最大编号的提案信息</li>\n    </ul>\n</ul>\n\n>参考：\n>1. <a href=\"https://time.geekbang.org/column/intro/279\">极客时间 — —《分布式协议与算法》</a>\n>2. <a href=\"https://leehao.me/%E5%9B%BE%E8%A7%A3-Paxos-%E7%AE%97%E6%B3%95/\">图解 Paxos 算法</a>\n\n","tags":["极客时间","Paxos","分布式架构"]},{"title":"转正成功","url":"/2022/12/12/2022-12-12-a-zhuan-zheng/","content":"\n**第一份工作，测试开发工程师，转正成功，新的生活开始~~~**","tags":["随记"]},{"title":"白话容器基础（一）：从进程说开去","url":"/2022/12/12/2022-12-12-bai-hua-rong-qi-ji-chu-yi-cong-jin-cheng-shuo-kai-qu/","content":"\n## 前言\ndocker 的来龙去脉：\n<ul>\n    <li>容器技术的兴起源于 PaaS 技术的普及</li>\n    <li>Docker 公司发布的 Docker 项目具有里程碑式的意义</li>\n    <li>Docker 项目通过“容器镜像”，解决了应用打包这个根本性难题</li>\n</ul>\n\n~~大佬真言：~~\n<blockquote>\n&emsp;&emsp;容器本身没有价值，有价值的是“容器编排”。\n</blockquote>\n\n## 容器，到底是怎么一回事儿？\n&emsp;&emsp;容器其实是一种沙盒技术。它能够像集装箱一样，把你的应用“装”起来。这样，应用与应用之间就存在“边界”，而不会相互干扰；并且被“装”起来的应用，也方便被搬来搬去 —— 这不就是 PaaS 最理想的状态嘛。\n\n不过，这两个技术说起来容易，做起来难。\n\n### 技术一：“边界”\n&emsp;&emsp;假如，现在你要写一个计算加法的小程序，其输入来自一个文件但输出到另一个文件。\n\n&emsp;&emsp;由于计算机只认识 0 和 1，所以无论用哪种语言编写这段代码，最后都需要编译成二进制文件，才能在计算机操作系统中运行。\n\n&emsp;&emsp;而为了能够让这些代码正常运行，我们往往还要给它提供数据，比如这个加法程序所需要的输入文件。这些存放在磁盘上的，数据和代码本身的二进制文件，就是我们平常所说的一个“程序”，也叫代码的可执行镜像（executable image）。\n\n然后，我们就可以在计算机上运行这个“程序”了。\n \n&emsp;&emsp;首先，操作系统从“程序”中发现输入来源是文件，然后这些数据被加载到内存中待命。同时，操作系统又读取到了计算加法的指令，这时，它就需要指示 CPU 完成加法操作。而 CPU 与内存协作进行加法计算，又会使用寄存器存放数值、内存堆栈保存执行的命令和变量。同时，计算机里还有被打开的文件，以及各种各样的 I/O 设备在不断地调用中修改自己的状态。\n\n&emsp;&emsp;就这样，一旦“程序”被执行起来，它就从磁盘上的二进制文件，变成了计算机内存中的数据、寄存器里的值、堆栈中的指令、被打开的文件，以及各种设备的状态信息的一个集合。\n\n&emsp;&emsp;像这样一个程序运起来后的计算机执行环境的总和，就是我们今天的主角：**进程**。\n\n&emsp;&emsp;所以，对于进程来说，它的静态表现就是程序，平常都安安静静地待在磁盘上；而一旦运行起来，它就变成了计算机里的数据和状态的总和，这就是它的动态表现。\n\n&emsp;&emsp;而容器技术的核心功能，就是**通过约束和修改进程的动态表现，从而为其创造出一个“边界”。**\n\n&emsp;&emsp;对于 Docker 等大多数 Linux 容器来说，**Cgroups** 技术是用来制造约束的主要手段，而 **Namespace** 技术则是用来修改进程视图的主要方法。\n\n### 那什么是 Cgroups 和 Namespace ？\n\n&emsp;&emsp;假设你已经有了一个 Linux 操作系统上的 Docker 项目在运行，比如我的虚拟机环境是 Ubuntu 16.04 和 Docker CE 18.05。\n\n&emsp;&emsp;接下来，让我们首先创建一个容器来试试。\n\n```bash\ndocker run -it mydocker /bin/sh\n```\n\n&emsp;&emsp;这个命令是 Docker 项目最重要的一个操作，即大名鼎鼎的 docker run。\n\n其中：\n<ul>\n    <li>-it 参数告诉了 Docker 项目在启动容器后，需要给我们分配一个文本输入/输出环境（也就是 TTY），跟容器的标准输入相关联\n    </li>\n    <li>\n    /bin/sh 就是我们要在 Docker 容器里运行的程序\n    </li>\n</ul>\n\n&emsp;&emsp;所以，上面这条指令“说人话”就是：请帮我启动一个容器，在容器里执行/bin/sh，并且给我分配一个命令行终端跟这个容器交互。\n\n&emsp;&emsp;这样，我的虚拟机就变成了一个宿主机，而一个运行着 /bin/sh 的容器，就跑在了这个宿主机里面。\n\n&emsp;&emsp;此时，如果我们在容器里执行一下 ps 指令，就会发现：\n\n```bash\n# ps\nPID USER TIME COMMAND\n 1 root 0:00 /bin/sh\n10 root 0:00 ps\n```\n\n&emsp;&emsp;可以看到，Docker 里只有两个进程在运行。这就意味着，前面执行的 /bin/sh，以及我们刚刚执行的 ps，已经被 Docker 隔离在了一个跟宿主机完全不同的世界当中。\n\n这究竟是怎么做到呢？\n\n&emsp;&emsp;本来，每当我们在宿主机上运行了一个 /bin/sh 程序，操作系统都会给它分配一个进程编号，比如 PID=100。这个编号是进程的唯一标识，就像员工的工牌一样。所以 PID=100，可以粗略地理解为这个 /bin/sh 是我们公司里的第 100 号员工，而第 1 号员工就自然是比尔 · 盖茨这样统领全局的人物。\n\n&emsp;&emsp;而现在，我们要通过 Docker 把这个 /bin/sh 程序运行在一个容器当中。这时候，Docker 就会在这个第 100 号员工入职时给他施一个“障眼法”，让他永远看不到前面的其他 99 个员工，更看不到比尔 · 盖茨。这样，他就会错误地以为自己就是公司里的第 1 号员工。\n\n&emsp;&emsp;这种机制，其实就是对被隔离应用的进程空间做了手脚，使得这些进程只能看到重新计算过的进程编号，比如 PID=1。可实际上，他们在宿主机的操作系统里，还是原来的第 100 号进程。\n\n&emsp;&emsp;这种技术，就是 Linux 里面的 Namespace 机制。而 Namespace 的使用方式也非常有意思：**它其实只是 Linux 创建新进程的一个可选参数**。我们知道，在 Linux 系统中创建线程的系统调用是 clone()，比如：\n\n```java\nint pid = clone(main_function, stack_size, CLONE_NEWPID | SIGCHLD, NULL);\n```\n\n&emsp;&emsp;这时，新创建的这个进程将会“看到”一个全新的进程空间，在这个进程空间里，它的 PID 是 1。之所以说“看到”，是因为这只是一个“障眼法”，在宿主机真实的进程空间里，这个进程的 PID 还是真实的数值，比如 100。\n\n&emsp;&emsp;当然，我们还可以多次执行上面的 clone() 调用，这样就会创建多个 PID Namespace，而每个 Namespace 里的应用进程，都会认为自己是当前容器里的第 1 号进程，它们既看不到宿主机里真正的进程空间，也看不到其他 PID Namespace 里的具体情况。\n\n&emsp;&emsp;而**除了我们刚刚用到的 PID Namespace，Linux 操作系统还提供了 Mount、UTS、IPC、Network 和 User 这些 Namespace，用来对各种不同的进程上下文进行“障眼法”操作。**\n\n比如，\n<ul>\n    <li>Mount Namespace，用于让被隔离进程只看到当 Namespace 里的挂载点信息</li>\n    <li>Network Namespace，用于让被隔离进程看到当前 Namespace 里的网络设备和配置</li>\n</ul>\n\n**这，就是 Linux 容器最基本的实现原理了。**\n\n&emsp;&emsp;所以，Docker 容器这个听起来玄而又玄的概念，实际上是在创建容器进程时，指定了这个进程所需要启用的一组 Namespace 参数。这样，容器就只能“看”到当前 Namespace 所限定的资源、文件、设备、状态，或者配置。而对于宿主机以及其他不相关的程序，它就完全看不到了。\n\n**所以说，容器，其实是一种特殊的进程而已。**\n\n## 总结\n&emsp;&emsp;谈到为“进程划分一个独立空间”的思想，相信你一定会联想到虚拟机。而且，你应该还看过一张虚拟机和容器的对比图。\n\n![虚拟机和容器的对比图](/img/2022-12-12-白话容器基础（一）：从进程说开去/pho1.png)\n\n&emsp;&emsp;这幅图的左边，画出了虚拟机的工作原理。其中，名为 **Hypervisor** 的软件是虚拟机最主要的部分。它通过硬件虚拟化功能，模拟出了运行一个操作系统需要的各种硬件，比如 CPU、内存、I/O 设备等等。然后，它在这些虚拟的硬件上安装了一个新的操作系统，即 Guest OS。\n\n&emsp;&emsp;这样，用户的应用进程就可以运行在这个虚拟的机器中，它能看到的自然也只有 Guest OS 的文件和目录，以及这个机器里的虚拟设备。这就是为什么虚拟机也能起到将不同的应用进程相互隔离的作用。\n\n&emsp;&emsp;而这幅图的右边，则用一个名为 Docker Engine 的软件替换了 Hypervisor。这也是为什么，很多人会把 Docker 项目称为“轻量级”虚拟化技术的原因，实际上就是把虚拟机的概念套在了容器上。\n\n&emsp;&emsp;可是这样的说法，却并不严谨。\n\n&emsp;&emsp;在理解了 Namespace 的工作方式之后，你就会明白，跟真实存在的虚拟机不同，在使用 Docker 的时候，并没有一个真正的“Docker 容器”运行在宿主机里面。Docker 项目帮助用户启动的，还是原来的应用进程，只不过在创建这些进程时，Docker 为它们加上了各种各样的 Namespace 参数。\n\n&emsp;&emsp;这时，这些进程就会觉得自己是各自 PID Namespace 里的第 1 号进程，只能看到各自 Mount Namespace 里挂载的目录和文件，只能访问到各自 Network Namespace 里的网络设备，就仿佛运行在一个个“容器”里面，与世隔绝。\n\n&emsp;&emsp;不过，相信你此刻已经会心一笑：这些不过都是“障眼法”罢了。","tags":["Docker","极客时间"]},{"title":"Docker 和 K8s 到底有啥关系","url":"/2022/12/08/2022-12-08-docker-he-k8s-de-guan-xi/","content":"\n&emsp;&emsp;学了和用了一段时间 Docker 和 K8s，虽然学的不深、用的很浅，但是真真真感觉两者联系紧密。为了满足自己的好奇心，搜集了写资料，汇总一下。<br/>\n&emsp;&emsp;~~感觉自己的初高中时代，计算机领域真的风云突变啊，有点春秋百家争鸣的感觉。~~\n\n## 观点\n<ul>\n    <li><b>Docker 和 K8s 不是“非此即彼”的竞争对手，而是两种相辅相成的技术。</b></li>\n    <li> Docker 是一家提供一系列工具的公司，这些工具用于构建和共享容器镜像，以及运行小规模和大规模的容器。</li>\n    <li> K8s 是一个管理（“协调”）在服务器集群上运行的基于容器的应用程序的工具。</li>\n</ul>\n\n官方定义——简要介绍：\n1. Docker 是一个开源的应用容器引擎，开发者可以打包他们的应用及依赖到一个可移植的容器中，发布到流行的 Linux 机器上，也可实现虚拟化。\n2. K8s 是一个开源的容器集群管理系统，可以实现容器集群的自动化部署、自动扩缩容、维护等功能。\n\n## 什么是 Docker？\n它是一个公司，是一套工具，也是个命令......<br/>\n~~Docker 公司的“枭雄”故事，可自行百度;~~<br/>\n~~后边的内容，把 Docker 看作是开源的技术。~~<br>\n**“分割应用，使之容器化，便于交付”**，这是我对 Docker 的理解。<br/>\n那么，Docker到底做了什么，这里借用 Dirk Merkel 的话：\n\n<blockquote>\n&nbsp;&nbsp;Docker promises the ability to package applications and their dependencies into lightweight containers that move easily between different distros, start up quickly and are isolated from each other.<br>\n（Docker 承诺将应用程序及其依赖性打包到轻量级容器中，轻量级容器可以在不同发行版之间轻松移动、快速启动并彼此隔离。）\n</blockquote>\n\n费话一点来说，使用 Docker：<br/>\n&emsp;&emsp;开发者可以轻松地打包任何应用以及依赖包到一个轻量级的、可移植的、自给自足的容器中。然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。<br/>\n&emsp;&emsp;开发者把编译测试通过的容器可以批量地在生产环境中部署，包括 VMs（虚拟机）、bare metal、OpenStack 集群和其他的基础应用平台。<br/>\n&emsp;&emsp;容器是完全使用沙箱机制，相互之间不会有任何接口。<br/>\n\nDocker 生态流程：\n\n![docker流程](/img/2022-12-08-docker和k8s的关系/pho1.jpg)\n\n**一个完整的Docker有以下几个部分组成：**\n<ul>\n    <li> Docker Client 客户端</li>\n    <li> Docker Daemon 守护进程</li>\n    <li> Docker Image 镜像</li>\n    <li>Docker Container 容器</li>\n</ul>\n\nDocker通常用于如下场景：\n<ul>\n    <li> web应用的自动化打包和发布</li>\n    <li> 自动化测试和持续集成、发布</li>\n    <li> 在服务型环境中部署和调整数据库或其他的后台应用</li>\n    <li> 从头编译或者扩展现有的 OpenShift 或 Cloud Foundry 平台来搭建自己的PaaS环境</li>\n</ul>\n\n&emsp;&emsp;虽然 Docker 提供了一种高效方式来打包和发布容器化应用，但仅依靠 Docker 来实现大规模部署和管理容器仍面临挑战。跨多个服务器/集群协调和调度容器，在零停机的前提下升级或部署应用，以及监控容器的运行状况，这些使用姿势还有待优化。\n\n&emsp;&emsp;为解决这些问题以及其他问题，容器编排解决方案以 Kubernetes、Docker Swarm、Mesos、HashiCorp Nomad 等形式陆续诞生，它们可让组织管理大量容器和用户、高效平衡负载、提供身份验证和安全性，以及开展多平台部署等等。\n\n## 什么是 Kubernetes？\n&emsp;&emsp;如果 docker run 是在笔记本电脑上运行容器的方式，那么 K8s 就像一个机器人，在几十个或几百个服务器上运行 docker run。<br/>\n&emsp;&emsp;Kubernetes（常简称为K8s）是用于自动部署、扩展和管理“容器化应用程序”的开源系统。它目标是让部署容器化应用更简单高效,旨在提供一个“跨主机集群的自动部署、扩展以及运行应用程序容器”的平台。它支持一系列容器类工具，可以跨越网络资源集群来编排容器运行时系统。不论有无 Docker，均可使用 K8s。<br/>\nK8s 架构图：<br/>\n\n![K8s架构](/img/2022-12-08-docker和k8s的关系/pho2.jpg)\n\n&emsp;&emsp;在 K8s 中，我们可以创建多个容器，每个容器里面运行一个应用实例，然后通过内置的负载均衡策略，实现对这一组应用实例的管理、发现、访问，而这些细节都不需要运维人员去进行复杂的手工配置和处理。<br/>\n**K8s 特点**\n<ul>\n    <li> 可移植: 支持公有云，私有云，混合云，多重云（multi-cloud）</li>\n    <li> 可扩展: 模块化, 插件化, 可挂载, 可组合</li>\n    <li> 自动化: 自动部署，自动重启，自动复制，自动伸缩/扩展</li>\n</ul>\n\n## K8s 与 Docker\n![K8s与docker对比图](/img/2022-12-08-docker和k8s的关系/pho3.jpg)\n\n&emsp;&emsp;Docker 是一个容器运行环境，K8s 则是一个运行和管理容器的平台。K8s 支持众多容器运行环境，例如 Docker、containerd、CRI-O 以及 K8s CRI（容器运行时接口）。做个恰当比喻，如果 K8s 是“操作系统”，那么 Docker 容器就是您安装在“操作系统”上的“应用”。<br/>\n&emsp;&emsp;就其本身而言，Docker 对现代应用开发助益良多。它解决了“在我的机器上工作”的典型问题，但并未涉足其他地方。容器编排工具 Docker Swarm 能够应付部署有少许容器的生产容器工作负载。当系统扩大并需要添加许多彼此联网的容器时，单纯使用 Docker 可能会遭遇一些不断加剧的难题，而 K8s 则可帮助解决这些问题。<br/>\n&emsp;&emsp;若要比较二者，最好是将 K8s 与 Docker Swarm 进行比较。Docker Swarm 是一种类似于 K8s 的容器编排工具，这意味着它允许管理在运行 Docker 服务器的多个主机上部署的多个容器。默认情况下，Swarm 模式处于禁用状态，需要由 DevOps 团队进行设置和配置。<br/>\n&emsp;&emsp;K8s 编排计算机集群以协同工作，并根据可用的资源安排容器在这些机器上运行。通过声明式定义，将多个容器组合成容器集 (Pod)，后者是 K8s 的基本单元。K8s 自动管理诸如服务发现、负载平衡、资源分配、隔离以及垂直或水平扩展容器集一类的操作。如今它已被开源社区采纳，成为云原生计算基金会的一部分。Amazon、Microsoft 和 Google 均在自己的云计算平台上提供托管 K8s 服务，从而大大减轻了运行和维护 K8s 集群及其容器化工作负载的运营负担。\n\n>参考：\n>1. <a href=\"https://www.atlassian.com/zh/microservices/microservices-architecture/kubernetes-vs-docker\">Kubernetes 和 Docker 之间的主要区别，以及它们与容器化有何关系</a>\n>2. <a href=\"https://mp.weixin.qq.com/s?__biz=MzI1NzI5NDM4Mw==&mid=2247483724&idx=2&sn=7868943b1a31fc7bc65c97110ecfc97e&chksm=ea18e80cdd6f611acfea08392e87b1cfc79791b4eafa0e88607b53ab67f2e4f80891324b9a06&token=1662552961&lang=zh_CN&scene=21#wechat_redirect\">Kubernetes 和 Docker 到底有啥关系？</a>\n>3. <a href=\"https://www.tutorialworks.com/kubernetes-vs-docker/\">Kubernetes and Docker: What’s the difference?</a>\n>4. <a href=\"https://www.huaweicloud.com/zhishi/suyu-docker.html\">容器应用</a>\n","tags":["Docker","K8s"]},{"title":"入门 Python3 的必备知识","url":"/2022/12/06/2022-12-06-yi-xie-ji-chu-zhi-shi/","content":"## 一、变量\n### 1.1 命名规则\n  - 变量名只能是字母、数字或下划线\n  - 变量名的第 1 个字母不能是数字\n  - 变量名也不能是 Python 的关键字\n  - 变量名区分大小写\n\n## 二、数据类型\n六种：数字、字符串、元组、列表、集合、字典\n\n### 2.1 数字\npy3支持 int、float、bool、complex（复数）   <br/>\n只有一种整数类型 int，表示为长整型  <br/>\n内置的 type() 函数可以用来查询变量所指的对象类型。  <br/>\n```python\n>>> a,b,c,d=5,6.7,true,2+3j\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'true' is not defined\n>>> a,b,c,d=5,6.7,True,2+3j\n>>> print(type(a),type(b),type(c),type(d))\n<class 'int'> <class 'float'> <class 'bool'> <class 'complex'>\n```\n**注意** <br/>\n<ul>\n  <li> py 可以同时为多个变量赋值，如 a,b = 1,2</li>\n  <li> 一个变量可以通过赋值指向不同类型的对象</li>\n  <li> 数值的除法（/）总是返回一个浮点数（print（2/4）输出0.5），要获取整数使用//操作符</li>\n  <li> 在混合计算时，Python会把整型转换成为浮点数</li>\n  <li> 布尔型：Ture和False、1和0</li>\n  <li> del语句可删除定义的对象，如：del a,b</li>\n</ul>\n\n### 2.2 String\npy中的字符串用单引号（''）或双引号（\"\"）括起来，同时使用反斜杠转义特殊字符。<br/>\n字符串的截取的语法格式，如下：\n```python\n变量[头下标:尾下标]\n```\n索引值以 0 为开始值，-1 为末尾的开始值。<br/>\n加号（+）是字符串的连接符，星号（*）表示复制当前字符，紧跟的数字为复制的次数。<br/>\n例子：\n```python\n>>> str='hello,world!'\n>>> print(str)  \nhello,world!\n>>> print(str[0:-1])    # 输出第一个到倒数第二个的所有字符\nhello,world\n>>> print(str[0])\nh\n>>> print(str[-1])\n!\n>>> print(str[2:5])\nllo\n>>> print(str[2:])\nllo,world!\n>>> print(str * 2)\nhello,world!hello,world!\n>>> print(str + 'Hhhh')\nhello,world!Hhhh\n>>> print('hello\\nworld')\nhello\nworld\n>>> print(r'hello\\nworld')  # 在字符串前面添加一个 r，表示原始字符串，不会发生转义\nhello\\nworld\n```\n**注意** <br/>\n<ul>\n  <li> 反斜杠可以用来转义，使用 r 可以让反斜杠不发生转义</li>\n  <li> 字符串可以用 + 运算符连接在一起，用 * 运算符重复</li>\n  <li> py中的字符串有两种索引方式，从左到右以 0 开始，从右往左以 -1 开始</li>\n  <li> py中的字符串不能改变</li>\n  <li> py没有单独的字符类型，一个字符就是长度为 1 的字符串</li>\n</ul>\n\n### 2.3 List（列表）\n列表中元素的类型可以不相同，它支持数字，字符串甚至可以包含列表（所谓嵌套）。<br/>\n列表是写在方括号[]之间、用逗号分隔开的元素列表。<br/>\n和字符串一样，列表同样可以被索引和截取，列表被截取后返回一个包含所需元素的新列表。<br/>\n列表截取的语法格式如下：<br/>\n```python\n变量[头下标:尾下标]\n```\n索引值以 0 为开始值，-1 为从末尾的开始位置。<br/>\n加号（+）是列表连接运算符，星号（*）是重复操作。\n```python\n>>> list=['hello',357,6.6,'world']\n>>> ttlist=[123,'new']\n>>> print(list)\n['hello', 357, 6.6, 'world']\n>>> print(list[0])\nhello\n>>> print(list[1:3])\n[357, 6.6]\n>>> print(list[2:])\n[6.6, 'world']\n>>> print(ttlist * 2)\n[123, 'new', 123, 'new']\n>>> print(list + ttlist)\n['hello', 357, 6.6, 'world', 123, 'new']\n```\n**注意：**  <br/>\n<ul>\n  <li> List写在方括号之间，元素用逗号隔开。</li>\n  <li> 和字符串一样，list可以被索引和切片.</li>\n  <li> List可以使用+操作符进行拼接。</li>\n  <li> List中的元素是可以改变的。</li>\n</ul>\n\n### 2.4 Tuple（元组）\n元组（tuple）与列表类似，不同之处在于元组的元素不能修改。<br/>\n元组写在小括号()里，元素之间用逗号隔开。<br/>\n元组中的元素类型也可以不相同。<br/>\n元组与字符串类似，可以被索引且下标索引从0开始，-1 为从末尾开始的位置。也可以进行截取。<br/>\n其实，可以把字符串看作一种特殊的元组。<br/>\n构造包含 0 个或 1 个元素的元组比较特殊，所以有一些额外的语法规则：<br/>\n```python\ntup1 = ()     # 空元组\ntup2 = (20,)  # 一个元素，需要在元素后添加逗号  \n```\nstring、list和tuple都属于sequence（序列）。<br/>\n**注意：**<br/>\n<ul>\n  <li> 与字符串一样，元组的元素不能修改</li>\n  <li> 元组也可以被索引和切片，方法一样</li>\n  <li> 注意构造包含 0 或 1 个元素的元组的特殊语法规则</li>\n  <li> 元组也可以使用+操作符进行拼接</li>\n</ul>\n\n### 2.5 Sets（集合）\n集合（set）是一个无序不重复元素的序列。<br/>\n基本功能是进行成员关系测试和删除重复元素。<br/>\n可以使用大括号 { } 或者 set() 函数创建集合，注意：创建一个空集合必须用 set() 而不是 { }，因为 { } 是用来创建一个空字典。<br/>\n例子：<br/>\n```python\n>>> student = {'Tom', 'Jim', 'Mary', 'Tom', 'Jack', 'Rose'}\n>>> print(student)\n{'Mary', 'Jim', 'Rose', 'Jack', 'Tom'}\n>>> if ('Rose' in student):\n...     print('Rose 在集合中')\n... else:\n...     print('Rose 不在集合中')\n...\nRose 在集合中\n>>> a = set('abracadabra')\n>>> b = set('alacazam')\n>>> print(a)\n{'c', 'b', 'r', 'a', 'd'}\n>>> print(b)\n{'c', 'z', 'm', 'a', 'l'}\n>>> print(a - b)  # a 和 b 的差集\n{'b', 'r', 'd'}\n>>> print(b - a)  # b 和 a 的差集\n{'l', 'm', 'z'}\n>>> print(a | b)  # a 和 b 的并集\n{'c', 'z', 'b', 'r', 'm', 'a', 'l', 'd'}\n>>> print(a & b)  # a 和 b 的交集\n{'a', 'c'}\n>>> print(a ^ b)  # a 和 b 中不同时存在的元素\n{'l', 'd', 'z', 'b', 'r', 'm'}\n```\n\n### 2.6 Dictionary（字典）\n列表是有序的对象结合，字典是无序的对象集合。<br/>\n两者之间的区别在于：字典当中的元素是通过键来存取的，而不是通过偏移存取。<br/>\n字典是一种映射类型，字典用\"{ }\"标识，它是一个无序的键(key) : 值(value)对集合。<br/>\n键(key)必须使用不可变类型。<br/>\n在同一个字典中，键(key)必须是唯一的。<br/>\n例子：<br/>\n```python\n>>> dict = {}\n>>> dict['one'] = \"1 - hello,world\"\n>>> dict[2] = \"2 - 嘿嘿\"\n>>> tinydict = {'name': 'lucy', 'code': 100, 'class': '5年级6班'}\n>>>\n>>> print(dict['one'])  # 输出键为 'one' 的值\n1 - hello,world\n>>> print(dict[2])  # 输出键为 2 的值\n2 - 嘿嘿\n>>> print(tinydict)  # 输出完整的字典\n{'name': 'lucy', 'code': 100, 'class': '5年级6班'}\n>>> print(tinydict.keys())  # 输出所有键\ndict_keys(['name', 'code', 'class'])\n>>> print(tinydict.values())  # 输出所有值\ndict_values(['lucy', 100, '5年级6班'])\n```\n\n**1、内置函数：**<br>\nget 根据 key 值去取对应的 value，取不到值返回 None，不报错。\n```python\n>>> dic = {'k1':'v1','k2':'v2'}\n>>> v = dic.get('k1')\n>>> n = dic.get('k4')\n>>> print(v)\nv1\n>>> print(n)\nNone\n```\n\n**2、clear 清空**\n```python\n>>> dic = {'k1':'v1','k2':'v2'}\n>>> print(dic)\n{'k1': 'v1', 'k2': 'v2'}\n>>> dic.clear()\n>>> print(dic)\n{}\n```\n\n**2、copy 拷贝（浅拷贝）**\n```python\n>>> dic = {'k1':'v1','k2':'v2'}\n>>> v = dic.copy()\n>>> print(v)\n{'k1': 'v1', 'k2': 'v2'}\n```\n\n**3、pop 删除并获取对应的 value 值**\n```python\n>>> dic = {'k1':'v1','k2':'v2'}\n>>> v = dic.pop('k1')\n>>> print(dic)\n{'k2': 'v2'}\n>>> print(v)\nv1\n```\n\n**4、popitem 随机删除键值对，并获取到删除的键值**\n```python\n>>> dic = {'k1':'v1','k2':'v2'}\n>>> v = dic.popitem()\n>>> print(dic)\n{'k1': 'v1'}\n>>> print(v)\n('k2', 'v2')\n```\n\n**5、setdefault 增加，如果 key 值存在，则不操作**\n```python\n>>> dic = {'k1':'v1','k2':'v2'}\n>>> dic.setdefault('k3','v3')\n'v3'\n>>> print(dic)\n{'k1': 'v1', 'k2': 'v2', 'k3': 'v3'}\n>>> dic.setdefault('k3','v3')\n'v3'\n>>> print(dic)\n{'k1': 'v1', 'k2': 'v2', 'k3': 'v3'}\n```\n\n**6、update 批量增加或修改**\n```python\n>>> dic = {'k1':'v1','k2':'v2'}\n>>> dic.update({'k3':'v3','k4':'v4'})\n>>> print(dic)\n{'k1': 'v1', 'k2': 'v2', 'k3': 'v3', 'k4': 'v4'}\n```\n\n**注意：**<br/>\n<ul>\n  <li> 字典是一种映射类型，它的元素是键值对。</li>\n  <li> 字典的关键字必须为不可变类型，且不能重复。</li>\n  <li> 创建空字典使用 { }。</li>\n</ul>\n\n## 三、数据类型转换\n数据类型的转换，你只需要将数据类型作为函数名即可。<br/>\n以下几个内置的函数可以执行数据类型之间的转换。这些函数返回一个新的对象，表示转换的值。<br/>\n\n|  函数  | 描述  |\n| :---: | :---: |\n| int(x [,base]) | 将x转换为一个整数 |\n| float(x) | 将x转换到一个浮点数 |\n| complex(real [,imag])\t| 创建一个复数 |\n| str(x) | 将对象 x 转换为字符串 |\n| repr(x) | 将对象 x 转换为表达式字符串 |\n| eval(str)\t| 用来计算在字符串中的有效Python表达式,并返回一个对象 |\n| tuple(s) | 将序列 s 转换为一个元组 |\n| list(s) | 将序列 s 转换为一个列表 |\n| set(s) | 转换为可变集合 |\n| dict(d) | 创建一个字典。d 必须是一个序列 (key,value)元组。 |\n| frozenset(s) | 转换为不可变集合 |\n| chr(x) | 将一个整数转换为一个字符 |\n| unichr(x) | 将一个整数转换为Unicode字符 |\n| ord(x) | 将一个字符转换为它的整数值 |\n| hex(x) | 将一个整数转换为一个十六进制字符串 |\n| oct(x) | 将一个整数转换为一个八进制字符串 |\n\n>参考：\nhttps://segmentfault.com/a/1190000009722187","tags":["Python"]},{"title":"Python 直接赋值、浅拷贝和深度拷贝解析","url":"/2022/12/06/2022-12-06-python-zhi-jie-fu-zhi-qian-kao-bei-he-shen-du-kao-bei-jie-xi/","content":"## 直接赋值\n对象的引用（别名） —— 父子共用<br/>\n实例：\n```python\n>>> a = {1:[1,2,3]}\n>>> b = a\n>>> # 修改父对象，给父对象添加元素，同时影响 a 和 b\n>>> b[2] = [4, 5, 6]\n>>> print(\"a=\",a,\",b=\",b)\na= {1: [1, 2, 3], 2: [4, 5, 6]} ,b= {1: [1, 2, 3], 2: [4, 5, 6]}\n>>> # 修改内部子对象，给子对象添加元素，同时影响 a 和 b\n>>> b[1].append(7)\n>>> print(\"a=\",a,\",b=\",b)\na= {1: [1, 2, 3, 7], 2: [4, 5, 6]} ,b= {1: [1, 2, 3, 7], 2: [4, 5, 6]}\n```\n解释分析：\nb = a: 赋值引用，a 和 b 都指向同一个对象。<br/>\n![直接赋值解析](/img/2022-12-06-Python直接赋值、浅拷贝和深度拷贝解析/pho1.png)\n\n## 浅拷贝（copy）\n拷贝父对象，不会拷贝对象的内部子对象 —— 父隔离，子公用<br/>\n实例：\n```python\n>>> import copy\n>>> a = {1: [1, 2, 3]}\n>>> b = copy.copy(a)  # 等同于 b = a.copy()\n>>> # 修改父对象，给父对象添加元素，只影响 b，不影响 a\n... b[2] = [4, 5, 6]\n>>> print(\"a=\",a,\",b=\",b)\na= {1: [1, 2, 3]} ,b= {1: [1, 2, 3], 2: [4, 5, 6]}\n>>> # 修改对象内部子对象，给子对象添加元素，同时影响 a 和 b\n... b[1].append(7)\n>>> print(\"a=\",a,\",b=\",b)\na= {1: [1, 2, 3, 7]} ,b= {1: [1, 2, 3, 7], 2: [4, 5, 6]}\n```\n![浅拷贝解析](/img/2022-12-06-Python直接赋值、浅拷贝和深度拷贝解析/pho2.png)\n\n## 深拷贝（deepcopy）\ncopy模块的 deepcopy 方法，完全拷贝了父对象及其子对象 —— 父子隔离<br/>\n实例：\n```python\n>>> import copy\n>>> a = {1: [1, 2, 3]}\n>>> b = copy.deepcopy(a)\n>>> # 修改父对象，给父对象添加元素，只影响 b，不影响 a\n... b[2] = [4, 5, 6]\n>>> print(\"a=\",a,\",b=\",b)\na= {1: [1, 2, 3]} ,b= {1: [1, 2, 3], 2: [4, 5, 6]}\n>>>\n>>> # 修改对象内部子对象，给子对象添加元素，只影响 b，不影响 a\n... b[1].append(7)\n>>> print(\"a=\",a,\",b=\",b)\na= {1: [1, 2, 3]} ,b= {1: [1, 2, 3, 7], 2: [4, 5, 6]}\n```\n![深拷贝解析](/img/2022-12-06-Python直接赋值、浅拷贝和深度拷贝解析/pho3.png)","tags":["Python"]},{"title":"图解SQL的执行顺序","url":"/2022/12/04/2022-12-04-tu-jie-sql-de-zhi-xing-shun-xu/","content":"\n这是一条标准的查询语句：\n\n![查询语句](/img/2022-12-04-图解SQL的执行顺序/pho1.jpg \"查询语句.jpg\")\n\n这是我们实际上SQL执行的顺序：\n1. 执行 from，join 来确定表之间的连接关系，得到初步的数据。\n2. where 对数据进行普通的初步的筛选\n3. group by 分组\n4. 各组分别执行 having 中的普通筛选或者聚合函数筛选\n5. 进而得到我们要的数据源，再进行 select，可以是普通字段查询也可以是获取聚合函数的查询结果，如果是聚合函数，select 的查询结果会新增一个字段。\n6. 将查询结果去重 distinct\n7. 最后合并各组的查询结果，按照 oder by 的条件进行排序\n\n![查询过程](/img/2022-12-04-图解SQL的执行顺序/pho2.jpg \"查询过程.jpg\")\n\n## 数据关联过程\n数据库中的两张表：\n\n![数据表](/img/2022-12-04-图解SQL的执行顺序/pho3.jpg \"数据表.jpg\")\n\n### from&jion&where\n用于确定我们要查询的表的范围，涉及那些表。\n选择一张表，然后 jion 连接\n```sql\nfrom table1 jion table2 on table1.id=table2.id\n```\n用于多张表，用 where 做关联条件\n```sql\nfrom table1 jion table2 where table1.id=table2.id\n```\n我们会得到满足关联条件的两张表的数据，不加关联条件会出现笛卡尔积。\n\n![关联表](/img/2022-12-04-图解SQL的执行顺序/pho4.jpg \"关联表.jpg\")\n\n### group by\n按照我们的分组条件，将数据进行分组，但不会筛选数据。\n比如按照 id 的奇偶分组：\n\n![id 奇偶分组](/img/2022-12-04-图解SQL的执行顺序/pho5.jpg \"id 奇偶分组.jpg\")\n\n### having&where\nhaving 中可以是普通条件的筛选，也能是聚合函数，而 where 只能是聚合函数，一般情况下，有 having 可以不写 where，把 where 的筛选放在 having 里，SQL 语句看上去更顺滑。\n\n### 使用 where 再 group by\n先把不满足where条件的数据删除，再去分组\n\n### 使用 group by 再 where \n先分组再删除不满足 having 条件的数据，这两种方法有区别吗，几乎没有！\n举个例子：\n100/2=50，此时我们把 100 拆分 (10+10+10+10+10…)/2=5+5+5+…+5=50,只要筛选条件没变，即便是分组了也得满足筛选条件，所以 where后 group by 和 group by 再 having 是不影响结果的！\n\n不同的是，having 语法支持聚合函数,其实 having 的意思就是针对每组的条件进行筛选。我们之前看到了普通的筛选条件是不影响的，但是having 还支持聚合函数，这是 where 无法实现的。\n当前数据分组情况\n\n![当前分组情况](/img/2022-12-04-图解SQL的执行顺序/pho6.jpg \"当前分组情况.jpg\")\n\n执行 having 的筛选条件，可以使用聚合函数。筛选掉工资小于各组平均工资的 having salary<avg(salary)\n\n![分组后的情况](/img/2022-12-04-图解SQL的执行顺序/pho7.jpg \"分组后的情况.jpg\")\n\n### select\n分组结束之后，我们再执行 select 语句，因为聚合函数是依赖于分组的，聚合函数会单独新增一个查询出来的字段，这里用紫色表示，这里我们两个 id 重复了，我们就保留一个 id，重复字段名需要指向来自哪张表，否则会出现唯一性问题。最后按照用户名去重。\n```sql\nselect employee.id,distinct name,salary, avg(salary)\n```\n\n![select示意图](/img/2022-12-04-图解SQL的执行顺序/pho8.jpg \"select示意图.jpg\")\n\n将各组having之后的数据再合并数据。\n\n![having示意图](/img/2022-12-04-图解SQL的执行顺序/pho9.jpg \"having示意图.jpg\")\n\n### order by\n最后我们执行 order by 将数据按照一定顺序排序，比如这里按照 id 排序。如果此时有 limit 那么查询到相应的我们需要的记录数时，就不继续往下查了。\n\n![order示意图](/img/2022-12-04-图解SQL的执行顺序/pho10.jpg \"order示意图.jpg\")\n\n### limit\n记住 limit 是最后查询的，为什么呢？假如我们要查询年级最小的三个数据，如果在排序之前就截取到 3 个数据。实际上查询出来的不是最小的三个数据而是前三个数据了，记住这一点。\n\n我们如果limit 0,3 窃取前三个数据再排序，实际上最少工资的是2000,3000,4000。你这里只能是4000,5000,8000了。\n\n![limit示意图](/img/2022-12-04-图解SQL的执行顺序/pho11.jpg \"limit示意图.jpg\")\n\n>参考\nblog.csdn.net/weixin_44141495/article/details/108744720\n","tags":["sql"]},{"title":"vim 实用技巧（二）","url":"/2022/12/03/2022-12-03-vim-shi-yong-ji-qiao-er/","content":"\n## 基本命令\n\nvim 命令速查<br/>\n![vim 命令速查](/img/2022-12-03-vim实用技巧（二）/vim_orders.png \"vim_orders.png\")\n\n1. yy 复制一行，nyy 复制当前光标之后的 n 行，p 粘贴\n2. dd 删除一行，ndd 删除当前光标之后的 n 行\n3. 显示行号：set number\n4. 从第一行开始全文替换：1,$s/<源字符串>/<目标字符串>/g \n5. 查找某个字符串：/<目标字符串>\n6. 回到文尾：$ 行首：0","tags":["Linux","vim"],"categories":["linux 命令"]},{"title":"vim 实用技巧（一）","url":"/2022/12/02/2022-12-02-vim-shi-yong-ji-qiao-yi/","content":"\n## 导语\n**vim 号称编译之神，唯快不破，可拓展，插件遍天下。学习曲线虽曲折，但是学成之后，基本就成肌肉记忆了，写程序双手不离键盘，上下腾飞，可谓快意编程。**\n<br>\n<p style=\"text-align:right\"><b>--极客时间</b></p>\n\n## 简介\n### 四种模式\n<ul>\n  <li> 普通模式：vim 启动后的默认模式，用来移动光标、删除文本、覆盖输入文本、回复操作、粘贴文本等等。</li> \n  <li> 插入模式：输入 i 或 a 进入插入模式，在这个模式下敲击键盘会往文字缓冲区增加文字，相当于普通编译器的编辑模式。</li> \n  <li> 可视模式：选择文本，可以行选、块选和依次选择，选择后可以进行复制、删除、排序等操作。</li> \n  <li> 命令模式：执行内部和外部命令，通过 \":\" \"/\" \"?\" \":!\" 可以进入命令模式：执行内部命令、向上或向下搜索、执行外部命令。</li> \n</ul>\n\n## 安装\n\n一般是默认安装\n### Linux 下的安装\n\n#### Red Hat 和 CentOS 系列\n\n查看已经安装的 vim 版本：\n\n```bash\nyum list installed | grep vim\n```\n\n如果输出如下，则说明安装的 vim 版本只有基本功能：\n\n```bash\nvim-minimal.x86_64 2:8.0.1763-13.el8 @System\n```\n\n~~推荐~~\n\n```bash\nsudo yum install vim-X11    # 安装图形界面vim\nsudo yum install vim-enhanced   # 安装增强版本vim\n```\n\n#### Debin 和 Ubuntu 系列\n\n查看已经安装的 vim 版本：\n\n```bash\napt list --installed | grep vim\n```\n\n~~推荐~~\n\n```bash\nsudo apt update # 更新环境\nsudo apt install vim-gtk3 \n```\n\n### MacOS 下的安装\n\n安装 MacVim 有两种常见方式：\n<ul>\n  <li> 使用 Homebrew 。（推荐） </li>\n  <li> 使用 MacVim 的独立安装包。</li>\n</ul>\n\n使用 Homebrew 安装 Macvim：\n1. 安装 Homebrew 。<a href='https://brew.sh/index_zh-cn'>~~官网网址~~</a>\n2. 配置 .bash_profile\n\n```bash\nif [[ $PATH != \"$HOME/bin\"* ]]; then\n  PATH=~/bin:/usr/local/bin:/usr/local/sbin:`echo $PATH|sed -e \"s!:$HOME/bin!!\" -e 's!:/usr/local/bin!!'`\nfi\n```\n\n这样，可以确保个人的路径优先于 /usr/local，而 /usr/local 下的路径又优先于系统的路径。\n然后执行：\n\n```bash\nbrew install macvim\nvim -g / gvim # 启动 vim 图形界面\n```\n\n### windows 下的安装\n\nvim 网站下载：<a href='https://www.vim_.org/download.php#pc'>Downloading Vim</a>。安装完后，vim 会缺省打开一个 README 文件。在这个窗口，输入：\n\n```bash\n:e ~\\_vimrc \n```\n\n回车再输入：\n\n```bash\nset enc=utf-8\nset nocompatible\nsource $VIMRUNTIME/vimrc_example.vim\n```\n\n然后在输入\n\n```bash\nZZ\n```\n存盘退出即可。\n\n## vim 手册\n\n<a href='https://github.com/yianwillis/vimcdoc/releases'>大佬网址</a>\n\n有 vim 中文手册和 vim 中文用户手册","tags":["Linux","vim"]},{"title":"新的开始","url":"/2022/12/01/2022-12-01-a-xin-de-kai-shi/","content":"\n## 一个孤独码农的深夜遐想\n<p>大学时代，就一直想自己写个网站。一直推脱，想着明天再写、明天再写</p>\n<p>结果...</p>\n<p>就毕业了</p>\n\n毕业仿佛就在昨天，哎....不知道该说什么\n\n前尘往事，莫再提及\n\n希望我能坚持下去....\n\n2022-12-01 23:39:28\n\n","tags":["随记"]}]
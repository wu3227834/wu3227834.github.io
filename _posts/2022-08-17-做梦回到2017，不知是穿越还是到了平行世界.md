---
layout: mypost
title: 做梦回到2017，不知是穿越还是到了平行世界
categories: [穿越,平行世界,股票,彩票]
---

做梦回到了2017，不知道是穿越了时间，还是到了平行世界。穿越的场景是大巴车，锚点是嘴巴里没有取完的东西。感觉这是最近看《天才基本法》导致的。这么好的翻身机会，我第一时间想到的就是2017年的股市和彩票，要去查一下。

###### 2017年10大牛股：
1、寒锐钴业：年内涨幅近1633%
<br>2、华大基因：年内涨幅1470%
<br>3、至纯科技：年内涨幅1403%
<br>4、江丰电子：年内涨幅1382%
<br>5、药石科技：29个交易日，累计涨幅807.4%
<br>6、贵州燃气：37个交易日累计涨幅536.2%
<br>7、江南嘉捷：18个一字涨停板，复牌累计涨幅502.6%
<br>8、赣锋锂业：年内涨幅240.5%
<br>9、方大炭素：井喷式上涨，29个交易日涨幅达183.6%
<br>10、贵州茅台：年内涨幅近116% ，两市第一高价股

###### 2017年涨幅最高的五支股票：
沪市主板2017年第一牛股江南嘉捷，2017年累计涨幅达到294.21%。
<br>深市主板2017年第一牛股鲁西化工，2017年累计涨幅为84.79%。
<br>中小板2017年的第一牛股弘亚数控于2016年12月28日上市，2017年累计涨幅达到253.32%，
<br>创业板2017年的第一牛股鸿特精密，2017年累计涨幅为329.71%。
<br>次新股中2017年第一牛股寒锐钴业于2017年3月6日上市，该股上市以来股价较发行价上涨1793.73%。

##### 2017年全年的双色球中间号码需要python一下。


```
import re
from bs4 import BeautifulSoup
import ur11ib2
from mylog import MyLog as mylog


class DoubleColorBallItem(object):
    date=None #开奖日期
    order=None #当年的顺序
    red1=None #第一个红球的号码
    red2=None #第二个红球的号码
    red3=None #第三个红球的号码
    red4=None #第四个红球的号码
    red5=None #第五个红球的号码
    red6=None #第六个红球的号码
    blue=None #篮球号码
    mony=None #彩池金额
    firstPrize=None  #一等奖中奖人数
    secondPrize=None #二等奖中奖人数
class GetDoubleColorBallNumber(object):
    '''这个类用于获取双色球中奖号码，返回一个txt文件
    '''
    def _init_(self):
        self.urls=[]
        self.log=mylog()
        self.getUrls()
        self.items=self.spider(self.urls)
        self.pipelines(self.items)


    def getUrls(self):
        '''获取数据来源网页
        '''
        URL=r'http://kaijiang.zhcw.com/zhcw/html/ssq/list_1.html'
        htmlContent=self.getResponseContent(URL)
        soup=BeautifulSoup(htmlContent,'lxml')
        tag=soup.find_all(re.compile('P'))[-1]
        pages=tag.strong.get_text()
        for i in xrang(1,int(pages)+1):
            url=r'http://kaijiang.zhcw.com/zhcw/html/ssq/list_'+str(i) +'.html'
            self.urls.append(url)
            self.log.info('u添加URL:%S到URLS\r\n'%url)
    def getResponseContent(self,url):
        '''这里单独使用一个函数返回页面返回值，是为了后期方便地加入proxy和headers等
        '''
        try:
            respone=urllib2.urlopen(url.encode('utf8'))
        except:
            self.log.error(u'python返回URL：%s数据失败 \r\n'%url)
        else:
            self.log.info(u'python返回URL：%s数据成功 \r\n'%url)
            return response.read()


    def spider(self,urls):
        '''这个函数的作用是从获取的数据中过滤得到中奖信息
        '''
        items=[]
        for url in urls:
            htmlContent=self.getResponseContent(url)
            soup=BeautifulSoup(htmlContent,'lxml')
            tags=soup.find_all('tr',attrs={})
            for tag in tags:
                if tag.find('em'):
                    item=DoubleColorBallItem()
                    TagTd=tag.find_all('td')
                    item.date=TagTd[0].get_text()
                    item.order=TagTd[1].get_text()
                    TagEm=TagTd[2].find_all('em')
                    item.red1=tagEm[0].get_text()
                    item.red2=tagEm[1].get_text()
                    item.red3=tagEm[2].get_text()
                    item.red4=tagEm[3].get_text()
                    item.red5=tagEm[4].get_text()
                    item.red6=tagEm[5].get_text()
                    item.blue=tagEm[6].get_text()
                    item.money=tagTd[3].find('strong').get_text()
                    item.firstPrize=tagTd[4].find('strong').get_text()
                    item.secondPrize=tagTd[5].find('strong').get_text()
                    items.append(item)
                    self.log.info(u'获取日期为：%s的数据成功'%(item.date))
        return items
    def pipelines(self,items):
        fileName=u'双色球.txt'.encode(GBK)
        with open(fileName,'w') as fp:
            for item in items:
                fp.write('%s %s \t %s %s %s %s %s %s %s \t %s \t %s %s \n' %(item.date,item.order,item.red1,item.red2,item.red3,item.red4,item.red5,item.red6,item.blue,item.money,item.firstPrize,item.secondPrize))
                self.log.info(u'将日期为：%s的数据存入"%s"...' %(item.date,fileName.decode('GBK')))

if _name_=='_main_':
    GDCBN=GetDoubleColorBallNumber()
```
